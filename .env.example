# Transmissions Environment Configuration

# ============================================================================
# General Configuration
# ============================================================================
NODE_ENV=development
PORT=3000
LOG_LEVEL=info

# ============================================================================
# Fuseki SPARQL Server
# These override the config/services.json settings
# ============================================================================
FUSEKI_USERNAME=admin
FUSEKI_PASSWORD=your-password-here

# Production Fuseki (uncomment for production deployment)
# NODE_ENV=production
# FUSEKI_USERNAME=admin
# FUSEKI_PASSWORD=your-production-password
# FUSEKI_BASEURL=https://fuseki.hyperdata.it

# ============================================================================
# NewsMonitor Service (Docker)
# ============================================================================
# Note: Port is configured in config/services.json (default: 6010)

# Update interval in milliseconds (default: 3600000 = 1 hour)
UPDATE_INTERVAL=3600000

# HTML render interval in milliseconds (default: 300000 = 5 minutes)
RENDER_INTERVAL=300000

# ============================================================================
# Semem Service Configuration
# ============================================================================
# API Authentication
API_KEY=semem-dev-key

# LLM Provider API Keys
OLLAMA_API_KEY=NO_KEY_REQUIRED
OPENAI_API_KEY=
CLAUDE_API_KEY=your_claude_key
MISTRAL_API_KEY=
GROQ_API_KEY=your_groq_key
PERPLEXITY_API_KEY=your_perplexity_key
HUGGINGFACE_API_KEY=your_huggingface_key

# API Base URLs (endpoints)
CLAUDE_API_BASE=https://api.anthropic.com
CLAUDE_MODEL=claude-3-opus-20240229
OLLAMA_API_BASE=http://localhost:11434
OLLAMA_HOST=http://localhost:11434

# Model Configuration
EMBEDDING_MODEL=nomic-embed-text  # Ollama embedding model
EMBEDDING_DIMENSION=1536          # Default embedding dimension
CHAT_MODEL=qwen2:1.5b             # Default Ollama chat model

# Claude Example Configuration
MEMORY_JSON_PATH=data/memory.json  # Path to memory storage
MAX_TOKENS=8192                    # Max tokens for context window
OPERATION_TIMEOUT=60000            # Timeout in ms (60 seconds)
TEST_PROMPT="What's the current state of AI technology?"  # Test prompt for example
CUSTOM_CONCEPTS=AI,technology,current state  # Custom concepts for memory

# SPARQL Configuration (Semem-specific)
SPARQL_QUERY_ENDPOINT=http://localhost:3030/semem/query
SPARQL_UPDATE_ENDPOINT=http://localhost:3030/semem/update
SPARQL_GRAPH_NAME=http://example.org/semem
SPARQL_USER=admin
SPARQL_PASSWORD=admin123

# Cache Configuration
CACHE_ENABLED=true
CACHE_TTL=3600000  # 1 hour in milliseconds

# Feature Flags
ENABLE_WEBSOCKET=true

# Test settings
TEST_TIMEOUT=10000
