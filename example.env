# Semem Environment Configuration

# Server Configuration
PORT=3000
LOG_LEVEL=info
NODE_ENV=development

# API Authentication
API_KEY=semem-dev-key

# LLM Provider API Keys
OLLAMA_API_KEY=NO_KEY_REQUIRED
OPENAI_API_KEY=
CLAUDE_API_KEY=your_claude_key
MISTRAL_API_KEY=
GROQ_API_KEY=your_groq_key
PERPLEXITY_API_KEY=your_perplexity_key
HUGGINGFACE_API_KEY=your_huggingface_key

# API Base URLs (endpoints)
CLAUDE_API_BASE=https://api.anthropic.com
CLAUDE_MODEL=claude-3-opus-20240229
OLLAMA_API_BASE=http://localhost:11434
OLLAMA_HOST=http://localhost:11434

# Model Configuration
EMBEDDING_MODEL=nomic-embed-text  # Ollama embedding model
EMBEDDING_DIMENSION=1536          # Default embedding dimension
CHAT_MODEL=qwen2:1.5b             # Default Ollama chat model

# Claude Example Configuration
MEMORY_JSON_PATH=data/memory.json  # Path to memory storage
MAX_TOKENS=8192                    # Max tokens for context window
OPERATION_TIMEOUT=60000            # Timeout in ms (60 seconds)
TEST_PROMPT="What's the current state of AI technology?"  # Test prompt for example
CUSTOM_CONCEPTS=AI,technology,current state  # Custom concepts for memory

# SPARQL Configuration
SPARQL_QUERY_ENDPOINT=http://localhost:3030/semem/query
SPARQL_UPDATE_ENDPOINT=http://localhost:3030/semem/update
SPARQL_GRAPH_NAME=http://example.org/semem
SPARQL_USER=admin
SPARQL_PASSWORD=admin123

# Cache Configuration
CACHE_ENABLED=true
CACHE_TTL=3600000  # 1 hour in milliseconds

# Feature Flags
ENABLE_WEBSOCKET=true

# Test settings
TEST_TIMEOUT=10000