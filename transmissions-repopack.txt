================================================================
REPOPACK OUTPUT FILE
================================================================

This file was generated by Repopack on: 2024-07-22T13:12:25.355Z

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This header section
2. Multiple file entries, each consisting of:
   a. A separator line (================)
   b. The file path (File: path/to/file)
   c. Another separator line
   d. The full contents of the file
   e. A blank line

Usage Guidelines:
-----------------
1. This file should be treated as read-only. Any changes should be made to the
   original repository files, not this packed version.
2. When processing this file, use the separators and "File:" markers to
   distinguish between different files in the repository.
3. Be aware that this file may contain sensitive information. Handle it with
   the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repopack's
  configuration.
- Binary files are not included in this packed representation.
- Code comments have been removed.


For more information about Repopack, visit: https://github.com/yamadashy/repopack

Additional User-Provided Header:
--------------------------------
Transmissions repo

================================================================
Repository Files
================================================================

================
File: .babelrc
================
{
  "plugins": ["@babel/syntax-dynamic-import"],
  "presets": [
    [
      "@babel/preset-env",
      {
        "modules": false
      }
    ]
  ]
}

================
File: LICENSE
================
MIT License

Copyright (c) 2024 Danny Ayers

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

================
File: README.md
================
# transmissions

After _No Code_ and _Lo Code_ comes _Marginally Less Code_

**Transmissions** is a micro-framework which will simplify construction of small data processing applications in JavaScript (assuming you are already familiar with JavaScript and RDF).

A bit like `make` or a `package.json` builder.

### Status

The code is in active development, ie. **not stable**, subject to arbitrary changes.

Documentation will be lagging behind code, be incomplete and out of date.

**2024-03-24** : a couple of simple data processing pipelines working and wired up as Jasmine e2e tests in place; started to develop actually useful pipelines for [foaf-archive](https://github.com/danja/foaf-archive) project

## Motivation

This was prompted by something of a ~~perfect storm~~ serendipitous convergence of ideas, requirements and environment.

- I had the realization that much of the software I want to write in the near future has the same basic high level **architecture** : pipeline-like, ie. a series of steps each of which transform data from one form into another ([Wikipedia](<https://en.wikipedia.org/wiki/Pipeline_(software)>)).
- **Pipelines** are approachable using concepts from Design Patterns like [Dependency Injection](https://en.wikipedia.org/wiki/Dependency_injection), [Inversion of control](https://en.wikipedia.org/wiki/Inversion_of_control) etc. A key benefit of such patterns is that, because the components are loosely coupled, they can largely be developed in isolation as small standalone units before integration into a larger application.
- **Large Language Models** currently struggle with large codebases and complex architectures (mostly due to [context window](https://en.wikipedia.org/wiki/Large_language_model#Prompt_engineering,_attention_mechanism,_and_context_window) limitations). But they are very good at building small, simple, self-contained units of code.

reused in different contexts.

_I'm writing this with GitHub Copilot enabled for markdown, which can be helpful, but sometimes it goes off on one... After the first point above it offered :_

```
This is true of a blog engine, a personal knowledge management system, a chatbot, a mail archive miner, a web scraper, a data visualizer, a data importer/exporter, a data transformer, a data validator, a data filter, a data aggregator, a data splitter, a data joiner, a data normalizer, a data summarizer, a data classifier, a data indexer, a data search engine, a data storage system, a data retrieval system, a data synchronization system, a data backup system, a data migration system, a data versioning system, a data sharing system, a data access control system, a data privacy system, a data security system, a data integrity system, a data quality system, a data governance system, a data provenance system, a data lineage system, a data lifecycle system, a data archiving system, a data retention system, a data deletion system, a data recovery system, a data discovery system, a data exploration system, a data analysis system, a data visualization system, a data reporting system, a data monitoring system, a data alerting system, a data forecasting system, a data prediction system, a data recommendation system, a data personalization system, a data optimization system, a data simulation system, a data modeling system, a data inference system, a data learning system, a data reasoning system, a data decision system, a data planning system, a data execution system, a data monitoring system, a data feedback system, a data control system, a data automation system, a data orchestration system, a data integration system, a data federation system, a data interoperability system, a data exchange system, a data transformation system, a data migration system, a data synchronization system, a data replication system, a data federation system, a data virtualization system, a data streaming system, a data batch system, a data real-time system, a data near-real-time system, a data historical system, a data temporal system, a data spatial system, a data geospatial system, a data network system, a data graph system, a data tree system, a data list system, a data set system, a data table system, a data document system, a data record system, a data entity system, a data attribute system, a data value system, a data type system, a data format system, a data encoding system, a data serialization
```

_... which is a little over the top, but it's a fair list of things that might be helped by a micro-framework like this. Remarkably the first 5 are pretty much my immediate intended uses for this._

**Docs below need updating**

for later :

The [Community Solid Server](https://github.com/CommunitySolidServer/CommunitySolidServer) uses [Components.js](https://componentsjs.readthedocs.io/en/latest/) to specify how modules and components need to be wired together at runtime. Components.js is a dependency injection framework for JavaScript applications.

## What it is

A low-level system for data processing pipelines/networks. Wherever convenient functionality will be defined declaratively with JSON-LD configuration files.

Dependency injection is used internally to allow loose coupling of components.

## What it isn't

There are several sophisticated frameworks for building interfaces between software applications and creating data processing networks. NodeRed, NoFlo etc. This is not one of them. This is much more basic and bare bones, down in the details.

See also [David Booth](https://github.com/dbooth-boston)'s [RDF Pipeline Framework](https://github.com/rdf-pipeline)

_I do eventually want to use this with NodeRed or whatever, but the entities created by transmissions will be at the level of nodes in such networks, not the network itself._

## Motivation

I'm in the process of writing yet another blog engine (Postcraft). I've also started working on a playground for interconnecting intelligent agents in an XMPP multiuser chat environment (Kia). I'm also revising a system for managing a personal knowledge base in the world of LLMs (HKMS). These all share functionality around connectivity to external data/messaging systems and internal data transformation. Might as well write this bit once only, and avoid thinking about software architecture more than I have to.

### Goals

To facilate :

- rapid development of small applications
- reuse of components in a loosely-couple environment
- versatility

### Soft Goals

- performance - low on the list
- scalability - ditto
- security - ditto

================
File: docs/TODO.md
================
## transmissions TODO

# Next Steps

- [ ] revise tests for

---

transmissions topology - multiple lists, series/parallel

running a single Halt fails - connect

add self-description to services

## New services/pipelines

### make link list

- [ ] read list of URLs from file
- [ ] fetch URL
- [ ] save content + headers
- [ ] load file
- [ ] extract headers/links in order
- [ ] save as markdown

### filter my bookmarks for FOAF

### self-describing pipeline

### JSDoc RDFDoc template!!

https://jsdoc.app/about-configuring-default-template

worker threads : https://chat.openai.com/share/febba974-98a1-4a98-b8c2-1a20e22cf4bb

- [ ]

## Features

- [ ] add `transmissions` command line tool https://tldp.org/LDP/abs/html/standard-options.html
- [ ] multi-thread
- [ ] generalise pipeline shapes

## Admin

- [ ] JSDoc
- [ ] unit tests
- [ ] make transmissions.d.ts
- [ ] add GitHub CI

- [ ] add command line tool, can list what's available

## command line tool : `transmissions`

- [ ] `transmissions list` - list available pipelines
- [ ] `transmissions run <pipeline>` - run a pipeline

https://tldp.org/LDP/abs/html/standard-options.html

---

docs for grapoi

[ ] - get file-pipeline.js running

[x] - move Reveal to logger

### figure out how to include in other github projects

### use package.json to publish to npm

https://docs.npmjs.com/creating-node-js-modules

https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-npm-registry#publishing-a-package

================
File: docs/ac.html
================
<p>It sounds like you&#39;re encountering a common issue in asynchronous processing pipelines: ensuring that data (in
    your case, the flag signaling the end of the list) is passed along in the correct order, especially after
    asynchronous operations have completed. This issue arises because asynchronous tasks (like reading files) may
    complete in a non-deterministic order, potentially causing the flag to be sent before all tasks have finished.</p>
<p>Here are some strategies to handle this situation:</p>
<h3 id="1-use-promise-all-for-batch-processing">1. Use <code>Promise.all</code> for Batch Processing</h3>
<p>If your pipeline can afford to wait for all files to be processed before moving to the next stage, consider using
    <code>Promise.all</code> to wait for all file-reading (and subsequent processing) promises to resolve before sending
    the flag. This ensures that the flag is only sent after all asynchronous operations have completed.</p>
<pre><code class="lang-javascript"><span class="hljs-keyword">let</span> readFilesPromises = filenames.map(<span class="hljs-function">(<span class="hljs-params">filename</span>) =&gt;</span>
  readFileAndProcess(filename)
);
<span class="hljs-keyword">await</span> <span class="hljs-built_in">Promise</span>.all(readFilesPromises);
<span class="hljs-comment">// After all promises resolve, send the flag</span>
sendFlag();
</code></pre>
<h3 id="2-chain-promises">2. Chain Promises</h3>
<p>For a more sequential approach, especially if subsequent operations depend on the completion of previous ones, you
    might chain your promises. This ensures operations are completed in order.</p>
<pre><code class="lang-javascript"><span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">processFilesSequentially</span>(<span class="hljs-params">filenames</span>) </span>{
  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">let</span> filename <span class="hljs-keyword">of</span> filenames) {
    <span class="hljs-keyword">await</span> readFileAndProcess(filename);
  }
  sendFlag();
}
</code></pre>
<h3 id="3-use-async-iterators">3. Use Async Iterators</h3>
<p>If your pipeline processes a stream of data (like reading lines from a file), async iterators (introduced in ES2018)
    can be helpful. They allow you to work with asynchronous data sources in a synchronous-like manner.</p>
<pre><code class="lang-javascript"><span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">processLineByLine</span>(<span class="hljs-params">fileStream</span>) </span>{
  <span class="hljs-keyword">for</span> <span class="hljs-keyword">await</span> (<span class="hljs-keyword">let</span> line <span class="hljs-keyword">of</span> fileStream) {
    processLine(line);
  }
  sendFlag();
}
</code></pre>
<h3 id="4-monitor-active-tasks">4. Monitor Active Tasks</h3>
<p>Implement a counter or a set to track active tasks. Increment (or add to the set) when a task starts, and decrement
    (or remove from the set) when a task completes. Send the flag only when all tasks are done.</p>
<pre><code class="lang-javascript">let activeTasks = <span class="hljs-keyword">new</span> Set();
filenames.forEach(<span class="hljs-function"><span class="hljs-params">(filename)</span> =&gt;</span> {
  let task = readFileAndProcess(filename).<span class="hljs-keyword">finally</span>(<span class="hljs-function"><span class="hljs-params">()</span> =&gt;</span> {
    activeTasks.<span class="hljs-keyword">delete</span>(task);
    <span class="hljs-keyword">if</span> (activeTasks.size === <span class="hljs-number">0</span>) {
      sendFlag();
    }
  });
  activeTasks.add(task);
});
</code></pre>
<h3 id="5-correct-usage-of-async-await">5. Correct Usage of Async/Await</h3>
<p>Ensure that you&#39;re correctly using <code>async</code> and <code>await</code> within your service implementations.
    Misuse can lead to unexpected execution order. Pay particular attention to asynchronous functions called inside
    loops, making sure they&#39;re awaited correctly to maintain the order of operations.</p>
<h3 id="solution-implementation">Solution Implementation</h3>
<p>Given the pipeline nature of your application, integrating these strategies requires a balance between maintaining
    the order of operations and leveraging asynchronous performance. You may need to adjust based on the specifics of
    your pipeline and the dependencies between tasks. If tasks within a service can execute independently of one
    another, options like <code>Promise.all</code> offer efficient, parallel processing. For strictly ordered tasks,
    sequential processing with explicit <code>await</code> calls ensures correctness at the cost of concurrency.</p>
<p>By carefully structuring your async operations and using JavaScript&#39;s asynchronous programming features, you can
    ensure that your pipeline behaves as expected, processing all data and only sending the termination flag once all
    work is complete.</p>

================
File: docs/async-chat.md
================
It sounds like you're encountering a common issue in asynchronous processing pipelines: ensuring that data (in your case, the flag signaling the end of the list) is passed along in the correct order, especially after asynchronous operations have completed. This issue arises because asynchronous tasks (like reading files) may complete in a non-deterministic order, potentially causing the flag to be sent before all tasks have finished.

Here are some strategies to handle this situation:

### 1. Use `Promise.all` for Batch Processing

If your pipeline can afford to wait for all files to be processed before moving to the next stage, consider using `Promise.all` to wait for all file-reading (and subsequent processing) promises to resolve before sending the flag. This ensures that the flag is only sent after all asynchronous operations have completed.

```javascript
let readFilesPromises = filenames.map((filename) =>
  readFileAndProcess(filename)
);
await Promise.all(readFilesPromises);
// After all promises resolve, send the flag
sendFlag();
```

### 2. Chain Promises

For a more sequential approach, especially if subsequent operations depend on the completion of previous ones, you might chain your promises. This ensures operations are completed in order.

```javascript
async function processFilesSequentially(filenames) {
  for (let filename of filenames) {
    await readFileAndProcess(filename);
  }
  sendFlag();
}
```

### 3. Use Async Iterators

If your pipeline processes a stream of data (like reading lines from a file), async iterators (introduced in ES2018) can be helpful. They allow you to work with asynchronous data sources in a synchronous-like manner.

```javascript
async function processLineByLine(fileStream) {
  for await (let line of fileStream) {
    processLine(line);
  }
  sendFlag();
}
```

### 4. Monitor Active Tasks

Implement a counter or a set to track active tasks. Increment (or add to the set) when a task starts, and decrement (or remove from the set) when a task completes. Send the flag only when all tasks are done.

```javascript
let activeTasks = new Set();
filenames.forEach((filename) => {
  let task = readFileAndProcess(filename).finally(() => {
    activeTasks.delete(task);
    if (activeTasks.size === 0) {
      sendFlag();
    }
  });
  activeTasks.add(task);
});
```

### 5. Correct Usage of Async/Await

Ensure that you're correctly using `async` and `await` within your service implementations. Misuse can lead to unexpected execution order. Pay particular attention to asynchronous functions called inside loops, making sure they're awaited correctly to maintain the order of operations.

### Solution Implementation

Given the pipeline nature of your application, integrating these strategies requires a balance between maintaining the order of operations and leveraging asynchronous performance. You may need to adjust based on the specifics of your pipeline and the dependencies between tasks. If tasks within a service can execute independently of one another, options like `Promise.all` offer efficient, parallel processing. For strictly ordered tasks, sequential processing with explicit `await` calls ensures correctness at the cost of concurrency.

By carefully structuring your async operations and using JavaScript's asynchronous programming features, you can ensure that your pipeline behaves as expected, processing all data and only sending the termination flag once all work is complete.

================
File: docs/build.md
================
---

This project has been created using **webpack-cli**, you can now run

```
npm run build
```

or

```
yarn build
```

to bundle your application

================
File: docs/dev-process.md
================
# Transmissions Dev Process

see also Postcraft Flow : 2024-04-27

For a transmission called `example`

0. create a working directory `transmissions/src/applications/example` (henceforth, `example`)
1. sketch out process steps in `example/about.md`
2. check against existing services
3. create any new services that are needed
4. create `example/transmission.ttl`
5. create `example/services.ttl`

6. if a manifest is appropriate, create `project-dir/manifest.ttl`

Running without manifest :

```
transmissions$ ./run example
```

With manifest :

```
./run example project-dir
```

---

./run postcraft /home/danny/HKMS/postcraft/danny.ayers.name

---

DOcument them!!!

For example-task

create any additional services, eg. SomeService.js

add to ServiceFactory

create example-task_transmission.ttl
create example-task_services.ttl

create a runner, example-task.js

================
File: docs/help-request-mail.md
================
This

================
File: docs/howto.md
================
1. sketch required pipeline

### make link list

- read list of URLs from file
- fetch URL
- save content + headers
- load file
- extract headers/links in order
- save as markdown

2. look for potentially relevant existing services

FileReader - takes `filename | 'internal'` outputs { filename: filename, contents: contents }

### make link list

#### read list of URLs from file

- fetch URL
- save content + headers
- load file
- extract headers/links in order
- save as markdown

look for related transmission.ttl, copy

look for related script, copy, point to new transmission.ttl

new services, add to a factory

danny@danny-desktop:~/HKMS/transmissions$ node src/scripts/link-lister.js

// remarkable

================
File: docs/libs.md
================
# Libraries Used

## Core

## For Services

### Protocol-related

- [Axios](https://axios-http.com/docs/intro)

### Document manipulation

- [cheerio](https://cheerio.js.org/) - parsing and manipulating HTML (and XML)
- [Turndown](https://github.com/mixmark-io/turndown) - Convert HTML into Markdown

### Alternatives

Choices above made on a couple of criteria :

- must be well-known & well-maintained
- rather than any all-in-one dedicated lib, more fine-grained preferred for reusability

For Web crawling, node's own `fetch()` was the simplest option, but [Axios](https://axios-http.com/docs/intro) has a bunch of convenience wrappers - data is passed around as JSON objects.
https://apidog.com/blog/axios-vs-fetch/#:~:text=Axios%20provides%20the%20data%20in,response%20has%20an%20error%20status.

For HTML page parsing options start with various SAX-like streaming alternatives, then move into more DOM-oriented systems, and beyond into to tools that can run headless browsers and work with anything rendered dynamically in a page. The stand-out choices seemed to be [cheerio](https://cheerio.js.org/)

### Maybe later

https://github.com/jessetane/queue/tree/master

================
File: docs/links.md
================
https://github.com/rdf-pipeline

https://github.com/dbooth-boston

http://dbooth.org/2013/dils/pipeline/

https://dini-ag-kim.github.io/service-ontology/service.html

https://www.w3.org/submissions/OWL-S/

https://www.w3.org/2007/OWL/wiki/Punning

https://code.garrettmills.dev/Flitter

https://examples.rdf-ext.org/rdf-elements/

https://docear.org/software/history-changelog/

http://www.ldodds.com/projects/slug/config.html

http://rdfweb.org/topic/ScutterVocab

file:///home/danny/HKMS/hyperdata-static/xmlns/scutter/index.html

# Basic Dependency Injection

## In less than 100 lines of pure, ES6 JavaScript

This is a very bare-bones dependency injector implementation based on the ES6 classes. It's meant to illustrate the feasibility and benefits of using a service-based dependency injector for Node.js/JavaScript applications.

I discuss this project in greater depth in my blog post [here](https://garrettmills.dev/blog/2019/11/16/Dependency-Injection-in-Less-Than-100-Lines-of-Pure-JavaScript/).

================
File: docs/mail-archive-miner.md
================
- [DanC on mail in RDF, Feb 2002](https://www.w3.org/2000/04/maillog2rdf/email)
- [RFC 9264: Linkset: Media Types and a Link Relation Type for Link Sets](https://www.rfc-editor.org/rfc/rfc9264.html) - has JSON-LD version
  Email Fields, an RDF Schema

## Prompts

Please write an nodejs ES6 Javascript function that will take a file path as an argument and crawl directories from that location, obtaining the path of each file it encounters and printing it to the console. It should operate asynchronously. So given an input filesystem tree like this:
.
├── 2002-December
│   ├── 000420.html
│   ├── 000421.html
├── 2002-July
   └── 000185.html

it should output:

./2002-December/000420.html
./2002-December/000421.html
./2002-July/000185.html

---

How can this function be modified to filter specific file types?

---

please modify the source to have an es6 style, using 'import' instead of 'require'

---

================
File: docs/program-flow.md
================
---

services, clients, interfaces and injectors

## /

- run

Entry point.

## /applications

Contains application configuration files.

- simplepipe.json

## /mill

- Transmission

Contains the declared processing system.

Wraps a container into which the services are injected.

- TransmissionBuilder

Includes dependency injector

- Executor

- ServiceFactory

- Injectable

- Injector

## in /services

AppendProcess Connector Process ServiceBase Sink Source StringSink StringSource

================
File: docs/prompts.md
================
#### 2024-07-06

Currently the code is set up around passing messages of the form execute(data, context) where data is a string and context is a dictionary.
I wish to refactor the code under src such that the methods with a signature like this:

```
execute(data, context)
enqueue(data, context)
messageQueue.push({ data, context })
```

are changed to this:

```
execute(context)
enqueue(context)
messageQueue.push({ context })
```

to start I think it will be best to modify the code under src/applications to move the data argument into the context dictionary so: {data: data}
Can you advise how best to proceed methodically, step-by-step?

---

## Cursor

Please create a new jsconfig.json file for this project. Include everything relevant you find in this codebase. The project is in ES6 format. I wish to use intellisense in VSCode. Please add appropriate references to the libraries in use, including the typescript interface definitions in @types/grapoi.d.ts

I wish to make intellisense aware of

## Gemini

The code here successfully extracts a sequence of terms from a turtle rdf file. I would like it to also the class of each term. Here is the code :
https://github.com/danja/transmissions/blob/main/src/mill/TransmissionBuilder.js
here is the RDF :
https://github.com/danja/transmissions/blob/main/src/transmissions/string-pipe.ttl

---

JS Code interpreter on ChatGPT

Please keep your responses to a minimum, only show code listings that include your changes. I will upload an ES6 project as a zip file. Please extract the files and save to /mnt/data/
It is in early stages of development and does not work. We need to fix it and get it to support the following functionality.
The purpose of the code is to apply a processing pipeline to text. Services define the individual nodes which are instantiated by dependency injection. The connections between nodes will given declaratively using Connector.js. Here the code should read a file, apply a process to it and save it again. Please examine the code and write tests that will confirm this behaviour. Then fix the code to operate correctly. I will upload the code again. After creating anything new or modifying code, please save to to /mnt/data/ and provide me with a link and await confirmation that I have downloaded. Give extremely concise status messages only. After every step, stop and ask me for confirmation. I will pay you $20/month.

---

Please keep your responses to a minimum, only show code listings that include your changes. I will upload an ES6 project as a zip file. Please extract the files and save to /mnt/data/ then load it into Deno and execute run.js
We need to fix it to support the following functionality:
The purpose of the code is to apply a processing pipeline to text. Services define the individual nodes which are instantiated by dependency injection. The aim is to make everything very loosely-coupled. Later the pipeline topology will be defined declaratively. For a minimal configuration the code should now use a pipeline to take a string, apply a process to it and print the result. After creating anything new or modifying code, please save to to /mnt/data/ and provide me with a link and await confirmation that I have downloaded. Give extremely concise status messages only. After every step, stop and ask me for confirmation. I will pay you $20/month.

---

Can you please zip the current versions and save to /mnt/data/ and provide me with a link and await confirmation that I have downloaded.

---

Please keep your responses to a minimum, only show code listings that include your changes. I will upload an ES6 project as a zip file. Begin by checking the environment by loading the code into Deno and executing run.js The purpose of the code is to apply a processing pipeline to text. Services define the individual nodes which are instantiated by dependency injection. The aim is to make everything very loosely-coupled. For a minimal configuration the code should now use a pipeline to take a string, apply a process to it and print the result. Right now it works, but the names of the services and the connection topology is hardcoded. This should be done declaratively. The JSON 'simplepipe' in run.js contains a list of the nodes that should be connected and the order of the list gives the sequence. Please modify the code of ServiceContainer to support this. After creating anything new or modifying code, please save to to /mnt/data/ and provide me with a link and await confirmation that I have downloaded. Then load the code into Deno and execute run.js
Give extremely concise status messages only. After every step, stop and ask me for confirmation. I will pay you $20/month.

---

tests broken on Deno

Please keep your responses to a minimum, only show code listings that include your changes. I will upload an ES6 project as a zip file. Begin by loading the code into Deno and executing run.js Fix any bugs then zip all the files and save to /mnt/data/ and give me a download link. The purpose of the code is to apply a processing pipeline to text. Services define the individual nodes which are instantiated by dependency injection. The aim is to make everything very loosely-coupled. For a minimal configuration the code should now use a pipeline to take a string, apply a process to it and print the result. simplepipe.json contains a list of the nodes that should be connected and the order of the list gives the sequence. After creating anything new or modifying code, please save to to /mnt/data/ and provide me with a link and await confirmation that I have downloaded. Then load the code into Deno and execute run.js
Give extremely concise status messages only. After every step, stop and ask me for confirmation. I will pay you $20/month.

---

Can you extract the 'simplepipe' definition into a separate JSON file and modify code appropriately.

---

Please keep your responses to a minimum, only show code listings that include your changes. I will upload an ES6 project as a zip file. Check the environment by loading the code into Deno and executing run.js The purpose of the code is to apply a processing pipeline to text. Services define the individual nodes which are instantiated by dependency injection. The aim is to make everything very loosely-coupled. For a minimal configuration the code should now use a pipeline to take a string, apply a process to it and print the result.

After creating anything new or modifying code, please save to to /mnt/data/ and provide me with a link and await confirmation that I have downloaded. Then load the code into Deno and execute run.js
Give extremely concise status messages only. After every step, stop and ask me for confirmation. I will pay you $20/month.

Please make a test script for each class using vanilla Javascript. Then make a runner to run all the tests and try them individually. Then zip the latest versions of all files, save to /mnt/data/ and provide me with a link and await confirmation that I have downloaded.

---

Can you check for places where the code made be refactored to make it easier to understand and maintain. The aim is for things to be loosely-coupled, where appropriate defined declaratively in a separate json file where and to use dependency injection. Consider higher-level functions and design patterns like factory for the service class creation, but only if they would improve the code.

---

Follow these steps one at a time, executing run.js after each step and checking the output before continuing:

1. Ensure ES6 module syntax is used throughout.
2. Extract the pipeline construction, with definitions based on the pipeline configuration, from ServiceContainer into a seperate class Pipeline.
3. Refactor the service creation parts to use the factory design pattern
   Then zip the latest versions of all files, save to /mnt/data/ and provide me with a link and await confirmation that I have downloaded.

(re-upload)

I will upload a revised version of the code. Please extract the files and save to /mnt/data/ then load it into Deno and execute run.js to check environment.
Then follow these steps one at a time, executing run.js after each step and checking the output before continuing:

1. Integrate the Pipeline class into the ServiceContainer class, replacing redundant constructor code.
2. Incorporate the ServiceFactory class into the ServiceContainer class, replacing redundant constructor code.
3. Integrate Logger.js into the system and add logging at appropriate places.
   Then zip the latest versions of all files, save to /mnt/data/ and provide me with a link and await confirmation that I have downloaded.

   ***

restart

Please keep your responses to a minimum, only show code listings that include your changes. I will upload an ES6 project as a zip file. Check the environment by loading the code into Deno and executing run.js The purpose of the code is to apply a processing pipeline to text. Services define the individual nodes which are instantiated by dependency injection. The aim is to make everything very loosely-coupled. For a minimal configuration the code should now use a pipeline to take a string, apply a process to it and print the result.

Only give me extremely concise status messages. Implement the createService(type, config) factory method in di/ServiceFactory.js to support the Connector class in di/Connector.js. Check the syntax as you go along. After code changes, zip the latest versions of all files, save to /mnt/data/ and provide me with a link and await confirmation that I have downloaded.

---

Now make a list of each of the classes found in the services directory. Examine each and look for commonalities. Then implement support for each in di/ServiceFactory.js

Use synchronous methods. Check the syntax as you go along.
After code changes, zip the latest versions of all files, save to /mnt/data/ and provide me with a link and await confirmation that I have downloaded.

---

RENAMED

The program flow should be as follows:

1. run.js will create an instance of the Transmission class, giving it the name of the configuration file, eg. simplepipe.json
2. the Transmission class will load the configuration from file
3.

DependencyInjector class, Injectable interface, ServiceContainer class, ServiceFactory class

The goal now is to incorporate the ServiceFactory class from di/ServiceFactory.js into the ServiceContainer class from di/ServiceContainer.js, replacing redundant constructor code. Review the relevant code and form a plan of several steps. Divide the code integration plan itself into small steps. Use synchronous methods. Then proceed to carry out the steps. Check the syntax as you go along. After code changes, zip the latest versions of all files, save to /mnt/data/ and provide me with a link and await confirmation that I have downloaded.

RESTART

Please keep your responses to a minimum, only show code listings that include your changes. I will upload an ES6 project as a zip file. Check the environment by loading the code into Deno and executing run.js The purpose of the code is to apply a processing pipeline to text. Services define the individual nodes which are instantiated by dependency injection. The aim is to make everything very loosely-coupled. For a minimal configuration the code should now use a pipeline to take a string, apply a process to it and print the result.

I would like you to modify getService(serviceName) in di/ServiceContainer.js to delegate to the ServiceFactory class in di/ServiceFactory.js to create the services. Check the syntax as you go along. After code changes, zip the latest versions of all files, save to /mnt/data/ and provide me with a link and await confirmation that I have downloaded.

---

Please keep your responses to a minimum, only show code listings that include your changes. I will upload an ES6 project as a zip file. Check the environment by loading the code into Deno and executing run.js

The following task should be approached by first making a list of small, incremental steps.
In the code, getService(serviceName) in di/ServiceContainer.js should delegate to the ServiceFactory class in di/ServiceFactory.js to create the services. Currently getService method in ServiceContainer.js is using the service name to create an instance via the ServiceFactory, but it's not passing any configuration data to the createService method of ServiceFactory. Please modify the getService method to pass the appropriate configuration to the ServiceFactory.

Check the syntax as you go along. After code changes, zip the latest versions of all files, save to /mnt/data/ and provide me with a link and await confirmation that I have downloaded. Don't try running it yet.

Now execute run.js and check the output is 'hello world!'. Fix any problems. After code changes, zip the latest versions of all files, save to /mnt/data/ and provide me with a link and await confirmation that I have downloaded.

STOPPPPPPP need to redo that ^^^^

be silent apart from short status messages

---

aside

Please be silent apart from short status messages. I will upload an ES6 project as a zip file. The purpose of the code is to apply a processing pipeline to text. Services define the individual nodes which are instantiated by dependency injection.
Load the code into Deno and execute run.js
First carefully identify the cause of the errors through analysis. simplepipe.json is correct, so the problem must be in the code. When done, zip the latest versions of all files, save to /mnt/data/ and provide me with a link and await confirmation that I have downloaded. Be silent apart from short status messages.

and take note of the errors. Add logging messages to help identify the cause of the errors. Check the syntax as you go along. After making these changes, zip the latest versions of all files, save to /mnt/data/ and provide me with a link and await confirmation that I have downloaded. Don't try running it again yet. Be silent apart from short status messages.

...
Downloaded, thanks.
I would you to carry out a refactoring that will need a plan of small, incremental steps. It involves the Transmission class in di/Transmission.js, ServiceContainer class in di/ServiceContainer.js and SimplePipe in transmissions/SimplePipe.js The aim is to decouple the components and have the system constructed at run time based on a configuration file such as simplepipe.json
This will involve reimplementing the functionality of SimplePipe in a generic way that will be created at runtime.
The Transmission class will construct an abstract model of the topology derived from a json file such as simplepipe.json.
The ServiceContainer class will be responsible for creating the concrete services, creating the flow described in the Transmission and executing it.
Now create a list of small, incremental steps to carry out this refactoring.

Now work through the steps, be silent apart from short status messages. After code changes, zip the latest versions of all files, save to /mnt/data/ and provide me with a link and await confirmation that I have downloaded.

---

replace SimplePipe with a dynamically created Transmission instance determined by

. , class in di/ServiceContainer.js

creating the services, ServiceContainer class in
The Transmission class in di/Transmission.js will takes responsibility for containing an abstract model of the topology derived from a json file such as simplepipe.json. The ServiceContainer class will also be responsible for creating the services, class in di/ServiceContainer.js

creating the services, ServiceContainer class in

. Check the syntax as you go along. After code changes, zip the latest versions of all files, save to /mnt/data/ and provide me with a link and await confirmation that I have downloaded.

Now execute run.js and check the output is 'hello world!'. Fix any problems.
After code changes, zip the latest versions of all files, save to /mnt/data/ and provide me with a link and await confirmation that I have downloaded.

---

## Proceeding with these adjustments now.

Don't tell me anything until you have completed the following steps.
Integrate the Pipeline class into the ServiceContainer class. Check the syntax as you go along.
Execute run.js and check the output. Fix any problems.
Zip the latest versions of all files, save to /mnt/data/ and provide me with a link and await confirmation that I have downloaded.

Don't tell me anything until you have completed the following steps.
Examine SimplePipe and suggest ways to use the external simplepipe.json file to define the pipeline declaratively and remove the hardcoded names.

Don't tell me anything until you have completed the following steps.
Integrate Logger.js into the system and add logging at appropriate places. Check the syntax as you go along.
Execute run.js and check the output. Fix any problems.
Zip the latest versions of all files, save to /mnt/data/ and provide me with a link and await confirmation that I have downloaded.

---

### Docs

- Introduction
- API
- tutorial
- examples

Please add comments to the code files suitable for JSDoc. Follow best practices. Only add comments where the code isn't self-explanatory.
Execute run.js and check the output. Fix any problems.
Zip the latest versions of all files, save to /mnt/data/ and provide me with a link and await confirmation that I have downloaded.

### bindings

### RDF

Here is a Javascript file, t2j.js. Save it to /mnt/data/
The job is to implement the method convert(), which will take a string in Turtle RDF syntax and convert it to JSON-LD. The code will in ES6 format. This will be achieved by following these steps:

1. initiate Deno with the following libraries: readable-stream, @rdfjs/data-model, @rdfjs/serializer-turtle, @rdfjs/serializer-jsonld
2. run the current t2j.js to check the environment. If there are any errors, make the necessary adjustments to the environment so that it is working without errors.
3. Implement the convert() method in t2j.js
4. Save the latest version of t2j.js to /mnt/data/ and provide me with a link and await confirmation that I have downloaded.

and execute it with Deno. Then check the output. Fix any problems. After code changes, zip the latest versions of all files, save to /mnt/data/ and provide me with a link and await confirmation that I have downloaded.

================
File: docs/queue-chat.md
================
The services in my pipeline have this general shape:

class ProcessService extends Service {
constructor(config) {
super(config)
}

    async execute(data, context) {
        this.emit('message', data, context)
    }

}

These are key parts of how the pipeline is constructed as a Transmission object :

const transmission = new Transmission()
...
for (let i = 0; i < pipenodes.length; i++) {
let node = pipenodes[i]
let serviceName = node.value
...
let service = AbstractServiceFactory.createService(serviceType, servicesConfig)
...
transmission.register(serviceName, service)
...
transmission.connect(previousName, serviceName)
previousName = serviceName
}

How do I incorporate the queue functionality as previously discussed into this?

================
File: docs/rdf-models.md
================
@prefix : <http://example.org/> .

:p a :Pipeline ;
:pipe (:s1 :s2 :s3 :s4 :s5 :s6) .

:s1 a :One .
:s2 a :Two.
:s3 a :Three .
:s4 a :Four .
:s5 a :Five .
:s6 a :Six .

---

generalize!

call it a :Transmission

ChatGPT suggested

@prefix : <http://example.org/> .

:p a :Pipeline ;
:then (:s1 :s2) . # Starting sequence

# Direct connections using :then for the sequence and fork

:s1 :then :s2 .
:s2 :then :s3, :s5 . # Fork after :s2
:s3 :then :s4 . # Path from :s3 to :s4
:s5 :then :s6 . # Parallel path from :s5 to :s6

:s1 a :One .
:s2 a :Two .
:s3 a :Three .
:s4 a :Four .
:s5 a :Five .
:s6 a :Six .

suggested highlighting where paths join :

:s4 :then :s7 .
:s6 :then :s7 .
:s7 a :Step . # Assuming :s7 is the step where paths merge

maybe make fork & join explicit?

# :s2 :fork :s3, :s5 .

:s2 :fork :s3 .
:s2 :fork :s5 .

:s2 :join :s4 .
:s3 :join :s4 .

also explicit start & end?

================
File: docs/rdfext-notes.md
================
file stuff - lots of Promises

typing of the nodes is confusing

testing equivalence/incudes() ref vs identity issues

feels clunky, but this works:

q.object.value == ns.something.value

aah, but this is better:

q.object.equals(ns.trm.Pipeline)

from https://rdf.js.org/dataset-spec/#quad-matching

(some tricks in https://stackoverflow.com/questions/1068834/object-comparison-in-javascript)

reading rdf:List

ref. https://ontola.io/blog/ordered-data-in-rdf

================
File: docs/runners.md
================
# Runners

Application :

./run postcraft /home/danny/HKMS/postcraft/danny.ayers.name

Individual test:

`$npx jasmine --reporter=tests/helpers/reporter.js tests/unit/NOP.spec.js`

================
File: docs/snippets.txt
================
#### __*Input*__
 * **data** : filename
 * **context** : sourceFile (if data is not provided)
#### __*Output*__
 * **data** : file content
 * **context** : as Input

 * #### __*Input*__
 * **data** : any
 * **context** : any
 * #### __*Output*__
 * **data** : as Input
 * **context** : as Input

================
File: docs/t2j.md
================
npm install --save readable-stream
npm install --save @rdfjs/data-model
npm install --save @rdfjs/serializer-turtle
npm install --save @rdfjs/serializer-jsonld

**no!** npm install --save rdf-parser-n3

npm WARN deprecated rdf-parser-n3@1.1.1: This package is deprecated and got replaced by @rdfjs/parser-n3
npm WARN deprecated rdf-sink@1.0.1: This package is deprecated and got replaced by @rdfjs/sink
npm WARN deprecated rdf-data-model@1.0.0: This package is deprecated and got replaced by @rdfjs/data-model

npm install --save @rdfjs/sink
npm install --save @rdfjs/parser-n3

npm install --save rdf-utils-fs

### rdf-utils-fs

fromFile(filename, options)
Returns a quad stream for the given filename.

async toFile(stream, filename, options)
Writes the given quad stream to filename.

================
File: docs/terms.md
================
select distinct ?p WHERE {
?sub ?p ?obj .
}

select distinct ?o WHERE {
?sub a ?o .
}

## farelo/trellis

<http://hyperdata.it/trellis/RootNode>
2
<http://hyperdata.it/trellis/Node>

<http://www.w3.org/1999/02/22-rdf-syntax-ns#type>
2
<http://purl.org/dc/terms/title>
3
<http://purl.org/dc/terms/created>
4
<http://hyperdata.it/trellis/index>
5
<http://hyperdata.it/trellis/parent>

## foowiki

http://purl.org/stuff/wiki#Page
http://rdfs.org/sioc/ns#Post

http://xmlns.com/foaf/0.1/nick
http://www.w3.org/2000/01/rdf-schema#label
http://www.w3.org/1999/02/22-rdf-syntax-ns#type
http://purl.org/dc/terms/created
http://purl.org/dc/terms/format
http://purl.org/dc/terms/modified
http://purl.org/dc/terms/title
http://purl.org/dc/terms/topic
http://rdfs.org/sioc/ns#content
http://xmlns.com/foaf/0.1/maker

## foolicious

@prefix w: <http://hyperdata.it/wiki/> .
@prefix tag: <http://hyperdata.it/tags/> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix dc: <http://purl.org/dc/terms/> .
@prefix foaf: <http://xmlns.com/foaf/0.1/> .
<http:\_\_test> a w:Bookmark ;
w:url <http://test> ;
dc:title "the title";
dc:description """some description""";
foaf:nick "danja";
dc:topic tag:tag1 ;
dc:topic tag:tag2 ;
dc:topic tag:tag3 ;
dc:created "2018-07-24T12:16:57.716Z" .
tag:tag1 rdfs:label "tag1".
tag:tag2 rdfs:label "tag2".
tag:tag3 rdfs:label "tag3".

================
File: docs/toolkit.md
================
Utilities to Include:
Build and Deploy System: Use Webpack or Rollup for bundling, Babel for transpiling (for browser compatibility), and a simple server for local testing (e.g., webpack-dev-server).
Testing Framework: Jest or Mocha for testing.
Documentation Tools: JSDoc for inline documentation, and a tool like Docusaurus or GitBook for user guides and API documentation.
Linter/Formatters: ESLint and Prettier for code quality and consistency.

npx webpack init

npm install --save-dev chai

npm install --save-dev jasmine

npm install --save-dev jasmine-browser-runner jasmine-core

npx jasmine-browser-runner init

HTTP server mocking and expectations library for Node.js

https://github.com/nock/nock
UI - LIt - check bergi's

look at composer.js

CI/CD
https://github.com/kamleshchandnani/rabbit-hole-github-actions

https://kamleshchandnani.com/articles/jumping-down-the-rabbit-hole-of-github-actions

---

https://linkedsoftwaredependencies.org/vocabularies/object-oriented#.
https://linkedsoftwaredependencies.org/vocabularies/object-mapping#.
http://usefulinc.com/ns/doap#.

## Libs

lots of RDF-Ext

https://github.com/rdf-ext/rdf-store-sparql

### Client

PWA

https://developer.mozilla.org/en-US/docs/Web/Progressive_web_apps/How_to/Share_data_between_apps

send & receive

### Server

https://tinyhttp.v1rtl.site/

================
File: docs/use-cases.md
================
Needed by me :

### Site/blog engine : Postcraft

### Link aggregator : Strandz

### Dataset generator : (Datacraft, nope. Churn!)

toki pona corpus generator

================
File: docs/words.md
================
In a graph-shaped data flow transmission system, here are 30 words that could describe a service node:

1. Vertex
2. Hub
3. Gateway
4. Junction
5. Router
6. Processor
7. Handler
8. Intermediary
9. Connector
10. Endpoint
11. Relay
12. Interface
13. Provider
14. Switch
15. Dispatcher
16. Link
17. Coordinator
18. Access Point
19. Mediator
20. Facilitator
21. Translator
22. Broker
23. Manager
24. Director
25. Controller
26. Organizer
27. Emitter
28. Receiver
29. Conduit
30. Aggregator

Q1: How do service nodes manage data flow in a network?
Q2: What is the function of a router as a service node?
Q3: Can you explain the role of a switch in a graph-based network system?

================
File: entries/2023-10-27_hello.md
================
<!-- POST CONTENT TEMPLATE -->
<p class="post-title">
    <a href="https://danny.ayers.name/blog/2023-10-27_hello.html">
        Hello World! (again)
    </a>
</p>
<article class="post-content">
    <h1>Hello World! (again)</h1>
<p>lorem etc.</p>

</article>
<em>2024-05-16</em>

================
File: entries/journal/2024-04-30.md
================
<!-- POST CONTENT TEMPLATE -->
<p class="post-title">
    <a href="https://danny.ayers.name/blog/2024-04-30.html">
        Journal : 2024-04-24
    </a>
</p>
<article class="post-content">
    <h1>Journal : 2024-04-24</h1>
<p>This week I&#39;m having a big push trying to get my <a href="https://github.com/danja/postcraft">Postcraft</a> site builder project to something resembling an <strong>MVP</strong>. Resembling, because it isn&#39;t intended to be a <em>Product</em>. It&#39;s hardly going to be <em>Minimum</em> either, I want it presentable enough that I can use it indefinitely as-is, the keyword is <em>Viable</em>. Within this, I want everything in place : tests, docs etc, such that I can pick it up again whenever and have a good chance of getting back into the flow.</p>
<p>But <a href="https://github.com/danja/postcraft">Postcraft</a> isn&#39;t/won&#39;t be much in itself. It&#39;s an application of a tool I call <a href="https://github.com/danja/transmissions">Transmissions</a> (formerly known as <em>Treadmill</em>).</p>
<p>This is a Node.js library intended to help me build some of the applications lurking in my TODO lists.</p>
<p>general-purpose pipeline runner. The pipeline is defined in a Turtle file, and its services are implemented as Node.js modules.</p>
<p>in itself isn&#39;t the main goal, it&#39;s a means to an end.</p>
<p>The end is to have a site that I can use to present my work, and to have a platform for further work. The site is a <em>Personal Knowledge Management System</em>, a place to collect, organise, and present my thoughts and work. It&#39;s a place to think, to write, to code, to experiment, to learn, to teach. It&#39;s a place to be me.</p>
<p>I probably should special-case files called <code>journal_YYYY-MM-DD.md</code> in <code>PostcraftPrep.js</code> to give a title as above.</p>

</article>
<em>2024-05-16</em>

================
File: entries/journal/2024-05-16.md
================
<!-- POST CONTENT TEMPLATE -->
<p class="post-title">
    <a href="https://danny.ayers.name/blog/2024-05-16.html">
        Journal : 2024-05-16
    </a>
</p>
<article class="post-content">
    
</article>
<em>2024-05-16</em>

================
File: hello.md
================
DUMMY

================
File: index.html
================
<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8" />
        <title>Webpack App</title>
    </head>
    <body>
        <h1>Hello world!</h1>
        <h2>Tip: Check your console</h2>
    </body>
    <script>
        if ("serviceWorker" in navigator) {
            window.addEventListener("load", () => {
                navigator.serviceWorker
                    .register("service-worker.js")
                    .then((registration) => {
                        console.log("Service Worker registered: ", registration);
                    })
                    .catch((registrationError) => {
                        console.error("Service Worker registration failed: ", registrationError);
                    });
            });
        }
    </script>
</html>

================
File: jasmine.json
================
{
    "spec_dir": "tests",
    "spec_files": [
        "**/*[sS]pec.js"
    ],
    "helpers": [
        "helpers/reporter.js"
    ],
    "stopSpecOnExpectationFailure": true,
    "random": false
}

================
File: jsconfig.json
================
{
    "compilerOptions": {
      "target": "ES6",
      "module": "commonjs",
      "allowSyntheticDefaultImports": true,
      "baseUrl": "./",
      "paths": {
        "*": ["node_modules/*", "types/*"]
      }
    },
    "include": ["src/**/*", "run.js"],
    "exclude": ["node_modules", "**/node_modules/*"],
    "typeAcquisition": {
      "include": ["@rdfjs/types", "grapoi"]
    }
  }

================
File: jsdoc.json
================
{
    "source": {
        "include": [
            "src"
        ],
        "exclude": [
            "node_modules"
        ],
        "includePattern": ".+\\.js(doc|x)?$",
        "excludePattern": "(^|\\/|\\\\)_"
    },
    "opts": {
        "verbose": true,
        "recurse": true,
        "destination": "./docs/jsdoc"
    },
    "plugins": [
        "plugins/markdown"
    ]
}

================
File: layouts/mediocre/post-page_template.njk
================
<!DOCTYPE html>
<html lang="en">

<head>
    <title>The Title</title>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">

    <link rel="stylesheet" href="css/fonts.css" type="text/css" />
    <link rel="stylesheet" href="css/grid-columns.css" type="text/css" />
    <link rel="stylesheet" href="css/style.css" type="text/css" />

</head>

<body>
    <header id="main-header">
        <h1>
            
        </h1>
    </header>
    <div class="grid-container">
        <div class="main-grid-item directory">
            <h2>directory</h2>
            <p>i cinque secoli, ma anche al passaggio alla videoimp</p>
        </div>
        <div class="main-grid-item articles">
            <h2>articles</h2>
            <article>
                
            </article>
        </div>
        <div class="main-grid-item about">
            <h2>About</h2>
            
        </div>
    </div>
</body>

</html>

================
File: layouts/mediocre/templates/entry-content_template.njk
================
<!-- POST CONTENT TEMPLATE -->
<p class="post-title">
    <a href="https://danny.ayers.name/blog/2024-05-03_one.html">
        One
    </a>
</p>
<article class="post-content">
    
</article>
<em>2024-05-14</em>

================
File: links.md
================
[Main page](https://en.wikipedia.org/wiki/Main_Page)[Contents](https://en.wikipedia.org/wiki/Wikipedia:Contents)[Current events](https://en.wikipedia.org/wiki/Portal:Current_events)[Random article](https://en.wikipedia.org/wiki/Special:Random)[About Wikipedia](https://en.wikipedia.org/wiki/Wikipedia:About)[Contact us](https://en.wikipedia.org/wiki/Wikipedia:Contact_us)[Donate](https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en)[Help](https://en.wikipedia.org/wiki/Help:Contents)[Learn to edit](https://en.wikipedia.org/wiki/Help:Introduction)[Community portal](https://en.wikipedia.org/wiki/Wikipedia:Community_portal)[Recent changes](https://en.wikipedia.org/wiki/Special:RecentChanges)[Upload file](https://en.wikipedia.org/wiki/Wikipedia:File_upload_wizard)[
	
	
		
		
	
](https://en.wikipedia.org/wiki/Main_Page)[

Search
	](https://en.wikipedia.org/wiki/Special:Search)[Create account](https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=FOAF)[Log in](https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=FOAF)[ Create account](https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=FOAF)[ Log in](https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=FOAF)[learn more](https://en.wikipedia.org/wiki/Help:Introduction)[Contributions](https://en.wikipedia.org/wiki/Special:MyContributions)[Talk](https://en.wikipedia.org/wiki/Special:MyTalk)[Català](https://ca.wikipedia.org/wiki/FOAF)[Deutsch](https://de.wikipedia.org/wiki/FOAF)[Español](https://es.wikipedia.org/wiki/FOAF)[فارسی](https://fa.wikipedia.org/wiki/%D8%A7%D9%81%E2%80%8C%D8%A7%D9%88%D8%A7%DB%8C%E2%80%8C%D8%A7%D9%81_(%D9%87%D8%B3%D8%AA%DB%8C%E2%80%8C%D8%B4%D9%86%D8%A7%D8%B3%DB%8C))[Français](https://fr.wikipedia.org/wiki/FOAF)[Italiano](https://it.wikipedia.org/wiki/FOAF)[Latviešu](https://lv.wikipedia.org/wiki/FOAF)[Nederlands](https://nl.wikipedia.org/wiki/FOAF)[日本語](https://ja.wikipedia.org/wiki/Friend_of_a_Friend)[Norsk bokmål](https://no.wikipedia.org/wiki/FOAF)[Polski](https://pl.wikipedia.org/wiki/FOAF_(format))[Português](https://pt.wikipedia.org/wiki/FOAF)[Русский](https://ru.wikipedia.org/wiki/FOAF)[Українська](https://uk.wikipedia.org/wiki/FOAF)[Edit links](https://www.wikidata.org/wiki/Special:EntityPage/Q1389366#sitelinks-wikipedia)[Article](https://en.wikipedia.org/wiki/FOAF)[Talk](https://en.wikipedia.org/wiki/Talk:FOAF)[Read](https://en.wikipedia.org/wiki/FOAF)[Edit](https://en.wikipedia.org/w/index.php?title=FOAF&action=edit)[View history](https://en.wikipedia.org/w/index.php?title=FOAF&action=history)[Read](https://en.wikipedia.org/wiki/FOAF)[Edit](https://en.wikipedia.org/w/index.php?title=FOAF&action=edit)[View history](https://en.wikipedia.org/w/index.php?title=FOAF&action=history)[What links here](https://en.wikipedia.org/wiki/Special:WhatLinksHere/FOAF)[Related changes](https://en.wikipedia.org/wiki/Special:RecentChangesLinked/FOAF)[Upload file](https://en.wikipedia.org/wiki/Wikipedia:File_Upload_Wizard)[Special pages](https://en.wikipedia.org/wiki/Special:SpecialPages)[Permanent link](https://en.wikipedia.org/w/index.php?title=FOAF&oldid=1165941964)[Page information](https://en.wikipedia.org/w/index.php?title=FOAF&action=info)[Cite this page](https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&page=FOAF&id=1165941964&wpFormIdentifier=titleform)[Get shortened URL](https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FFOAF)[Download QR code](https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FFOAF)[Wikidata item](https://www.wikidata.org/wiki/Special:EntityPage/Q1389366)[Download as PDF](https://en.wikipedia.org/w/index.php?title=Special:DownloadAsPdf&page=FOAF&action=show-download-screen)[Printable version](https://en.wikipedia.org/w/index.php?title=FOAF&printable=yes)[Wikimedia Commons](https://commons.wikimedia.org/wiki/Category:FOAF)[friend of a friend](https://en.wikipedia.org/wiki/Friend_of_a_friend)[Friend of a Friend (disambiguation)](https://en.wikipedia.org/wiki/Friend_of_a_Friend_(disambiguation))[](https://en.wikipedia.org/wiki/File:FoafLogo.svg)[RDF](https://en.wikipedia.org/wiki/Resource_Description_Framework)[OWL](https://en.wikipedia.org/wiki/Web_Ontology_Language)[Semantic Web](https://en.wikipedia.org/wiki/Semantic_Web)[CC BY 1.0](https://en.wikipedia.org/wiki/Creative_Commons_license)[xmlns.com/foaf/spec/](http://xmlns.com/foaf/spec/)[friend of a friend](https://en.wikipedia.org/wiki/Friend_of_a_friend)[machine-readable](https://en.wikipedia.org/wiki/Machine-readable_data)[ontology](https://en.wikipedia.org/wiki/Ontology_(information_science))[persons](https://en.wikipedia.org/wiki/Person)[social networks](https://en.wikipedia.org/wiki/Social_networks)[Resource Description Framework](https://en.wikipedia.org/wiki/Resource_Description_Framework)[Web Ontology Language](https://en.wikipedia.org/wiki/Web_Ontology_Language)[e-mail addresses](https://en.wikipedia.org/wiki/E-mail_address)[telephone number](https://en.wikipedia.org/wiki/Telephone_number)[Facebook](https://en.wikipedia.org/wiki/Facebook)[Jabber ID](https://en.wikipedia.org/wiki/Extensible_Messaging_and_Presence_Protocol)[URI](https://en.wikipedia.org/wiki/Uniform_Resource_Identifier)[Social Semantic Web](https://en.wikipedia.org/wiki/Social_Semantic_Web)[citation needed](https://en.wikipedia.org/wiki/Wikipedia:Citation_needed)[RDF](https://en.wikipedia.org/wiki/Resource_Description_Framework)[social web](https://en.wikipedia.org/wiki/Social_web)[clarification needed](https://en.wikipedia.org/wiki/Wikipedia:Please_clarify)[Tim Berners-Lee](https://en.wikipedia.org/wiki/Tim_Berners-Lee)[semantic web](https://en.wikipedia.org/wiki/Semantic_web)[Giant Global Graph](https://en.wikipedia.org/wiki/Giant_Global_Graph)[Internet](https://en.wikipedia.org/wiki/Internet)[World Wide Web](https://en.wikipedia.org/wiki/World_Wide_Web)[edit](https://en.wikipedia.org/w/index.php?title=FOAF&action=edit&section=1)[WebID](https://en.wikipedia.org/wiki/WebID)[edit](https://en.wikipedia.org/w/index.php?title=FOAF&action=edit&section=2)[Live Journal](https://en.wikipedia.org/wiki/Live_Journal)[DeadJournal](https://en.wikipedia.org/wiki/DeadJournal)[My Opera](https://en.wikipedia.org/wiki/My_Opera)[Identi.ca](https://en.wikipedia.org/wiki/Identi.ca)[FriendFeed](https://en.wikipedia.org/wiki/FriendFeed)[WordPress](https://en.wikipedia.org/wiki/WordPress)[TypePad](https://en.wikipedia.org/wiki/TypePad)[Yandex](https://en.wikipedia.org/wiki/Yandex)[Safari](https://en.wikipedia.org/wiki/Safari_(web_browser))[Firefox](https://en.wikipedia.org/wiki/Firefox_(web_browser))[Semantic MediaWiki](https://en.wikipedia.org/wiki/Semantic_MediaWiki)[semantic annotation](https://en.wikipedia.org/wiki/Semantic_annotation)[linked data](https://en.wikipedia.org/wiki/Linked_data)[MediaWiki](https://en.wikipedia.org/wiki/MediaWiki)[content management systems](https://en.wikipedia.org/wiki/Content_management_systems)[edit](https://en.wikipedia.org/w/index.php?title=FOAF&action=edit&section=3)[Turtle](https://en.wikipedia.org/wiki/Turtle_(syntax))[web resources](https://en.wikipedia.org/wiki/Web_resource)[edit](https://en.wikipedia.org/w/index.php?title=FOAF&action=edit&section=4)[edit](https://en.wikipedia.org/w/index.php?title=FOAF&action=edit&section=5)[http://xmlns.com/foaf/0.1/](http://xmlns.com/foaf/0.1/)[http://xmlns.com/foaf/0.1/](http://xmlns.com/foaf/0.1/)[edit](https://en.wikipedia.org/w/index.php?title=FOAF&action=edit&section=6)[Resource Description Framework](https://en.wikipedia.org/wiki/Resource_Description_Framework)[Web Ontology Language](https://en.wikipedia.org/wiki/Web_Ontology_Language)[Social web](https://en.wikipedia.org/wiki/Social_web)[Semantic Web](https://en.wikipedia.org/wiki/Semantic_Web)[Description of a Career](https://en.wiktionary.org/wiki/DOAC)[Description of a Project](https://en.wikipedia.org/wiki/DOAP)[Semantically-Interlinked Online Communities](https://en.wikipedia.org/wiki/Semantically-Interlinked_Online_Communities)[hCard](https://en.wikipedia.org/wiki/HCard)[vCard](https://en.wikipedia.org/wiki/VCard)[XHTML Friends Network](https://en.wikipedia.org/wiki/XHTML_Friends_Network)[edit](https://en.wikipedia.org/w/index.php?title=FOAF&action=edit&section=7)[XML Watch: Finding friends with XML and RDF](https://web.archive.org/web/20091223003446/http://www.ibm.com/developerworks/xml/library/x-foaf.html)[IBM DeveloperWorks](https://en.wikipedia.org/wiki/IBM_DeveloperWorks)[XML Watch: Support online communities with FOAF](https://web.archive.org/web/20100307223814/http://www.ibm.com/developerworks/xml/library/x-foaf2.html)[IBM DeveloperWorks](https://en.wikipedia.org/wiki/IBM_DeveloperWorks)["Giant Global Graph"](https://web.archive.org/web/20160713021037/http://dig.csail.mit.edu/breadcrumbs/node/215)[the original](http://dig.csail.mit.edu/breadcrumbs/node/215)["LiveJournal FOAF"](https://web.archive.org/web/20100118151037/http://community.livejournal.com/ljfoaf)[the original](http://community.livejournal.com/ljfoaf)["Known FOAF data providers"](https://web.archive.org/web/20100226072731/http://wiki.foaf-project.org/w/DataSources)[the original](http://wiki.foaf-project.org/w/DataSources)["press release on the social networking support"](http://company.yandex.com/press_center/press_releases/2008/2008-08-15.xml)["FOAF Support in Safari RSS"](http://ejohn.org/blog/foaf-support-in-safari-rss/)["Semantic Radar plugin for the Firefox browser"](https://web.archive.org/web/20140108014347/https://addons.mozilla.org/en-US/firefox/addon/semantic-radar/)[the original](https://addons.mozilla.org/en-US/firefox/addon/semantic-radar/)["FOAF support module for Perl"](https://metacpan.org/pod/XML::FOAF)["FOAF+SSL authentication support for Perl"](https://metacpan.org/pod/Web::ID)[http://drupal.org/project/foaf](https://drupal.org/project/foaf)[Drupal](https://en.wikipedia.org/wiki/Drupal)["FOAF Vocabulary Specification 0.99"](http://xmlns.com/foaf/spec/20140114.html)[Archived](https://web.archive.org/web/20220303180551/http://xmlns.com/foaf/spec/20140114.html)[edit](https://en.wikipedia.org/w/index.php?title=FOAF&action=edit&section=8)[Official website](http://www.foaf-project.org)[Archived](https://web.archive.org/web/20211023122305/http://www.foaf-project.org/)[Wayback Machine](https://en.wikipedia.org/wiki/Wayback_Machine)[FOAF dataset](http://ebiquity.umbc.edu/resource/html/id/82/)[FOAF-search - a search engine for FOAF data](https://web.archive.org/web/20181130195340/https://www.foaf-search.net/)[Wayback Machine](https://en.wikipedia.org/wiki/Wayback_Machine)[v](https://en.wikipedia.org/wiki/Template:Semantic_Web)[t](https://en.wikipedia.org/wiki/Template_talk:Semantic_Web)[e](https://en.wikipedia.org/wiki/Special:EditPage/Template:Semantic_Web)[Semantic Web](https://en.wikipedia.org/wiki/Semantic_Web)[Databases](https://en.wikipedia.org/wiki/Database)[Hypertext](https://en.wikipedia.org/wiki/Hypertext)[Internet](https://en.wikipedia.org/wiki/Internet)[Ontologies](https://en.wikipedia.org/wiki/Ontology_(computer_science))[Semantics](https://en.wikipedia.org/wiki/Semantics_(computer_science))[Semantic networks](https://en.wikipedia.org/wiki/Semantic_network)[World Wide Web](https://en.wikipedia.org/wiki/World_Wide_Web)[Dataspaces](https://en.wikipedia.org/wiki/Dataspaces)[Hyperdata](https://en.wikipedia.org/wiki/Hyperdata)[Linked data](https://en.wikipedia.org/wiki/Linked_data)[Rule-based systems](https://en.wikipedia.org/wiki/Rule-based_system)[Semantic analytics](https://en.wikipedia.org/wiki/Semantic_analytics)[Semantic broker](https://en.wikipedia.org/wiki/Semantic_broker)[Semantic computing](https://en.wikipedia.org/wiki/Semantic_computing)[Semantic mapper](https://en.wikipedia.org/wiki/Semantic_mapper)[Semantic matching](https://en.wikipedia.org/wiki/Semantic_matching)[Semantic publishing](https://en.wikipedia.org/wiki/Semantic_publishing)[Semantic reasoner](https://en.wikipedia.org/wiki/Semantic_reasoner)[Semantic search](https://en.wikipedia.org/wiki/Semantic_search)[Semantic service-oriented architecture](https://en.wikipedia.org/wiki/Semantic_service-oriented_architecture)[Semantic wiki](https://en.wikipedia.org/wiki/Semantic_wiki)[Solid](https://en.wikipedia.org/wiki/Solid_(web_decentralization_project))[Collective intelligence](https://en.wikipedia.org/wiki/Collective_intelligence)[Description logic](https://en.wikipedia.org/wiki/Description_logic)[Folksonomy](https://en.wikipedia.org/wiki/Folksonomy)[Geotagging](https://en.wikipedia.org/wiki/Geotagging)[Information architecture](https://en.wikipedia.org/wiki/Information_architecture)[Knowledge extraction](https://en.wikipedia.org/wiki/Knowledge_extraction)[Knowledge management](https://en.wikipedia.org/wiki/Knowledge_management)[Knowledge representation and reasoning](https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning)[Library 2.0](https://en.wikipedia.org/wiki/Library_2.0)[Digital library](https://en.wikipedia.org/wiki/Digital_library)[Digital humanities](https://en.wikipedia.org/wiki/Digital_humanities)[Metadata](https://en.wikipedia.org/wiki/Metadata)[References](https://en.wikipedia.org/wiki/Reference_(computer_science))[Topic map](https://en.wikipedia.org/wiki/Topic_map)[Web 2.0](https://en.wikipedia.org/wiki/Web_2.0)[Web engineering](https://en.wikipedia.org/wiki/Web_engineering)[Web Science Trust](https://en.wikipedia.org/wiki/Web_Science_Trust)[HTTP](https://en.wikipedia.org/wiki/HTTP)[IRI](https://en.wikipedia.org/wiki/Internationalized_Resource_Identifier)[URI](https://en.wikipedia.org/wiki/Uniform_Resource_Identifier)[RDF](https://en.wikipedia.org/wiki/Resource_Description_Framework)[triples](https://en.wikipedia.org/wiki/Semantic_triple)[RDF/XML](https://en.wikipedia.org/wiki/RDF/XML)[JSON-LD](https://en.wikipedia.org/wiki/JSON-LD)[Turtle](https://en.wikipedia.org/wiki/Turtle_(syntax))[TriG](https://en.wikipedia.org/wiki/TriG_(syntax))[Notation3](https://en.wikipedia.org/wiki/Notation3)[N-Triples](https://en.wikipedia.org/wiki/N-Triples)[TriX](https://en.wikipedia.org/wiki/TriX_(serialization_format))[RRID](https://en.wikipedia.org/wiki/Research_Resource_Identifier)[SPARQL](https://en.wikipedia.org/wiki/SPARQL)[XML](https://en.wikipedia.org/wiki/XML)[Semantic HTML](https://en.wikipedia.org/wiki/Semantic_HTML)[Common Logic](https://en.wikipedia.org/wiki/Common_Logic)[OWL](https://en.wikipedia.org/wiki/Web_Ontology_Language)[RDFS](https://en.wikipedia.org/wiki/RDF_Schema)[Rule Interchange Format](https://en.wikipedia.org/wiki/Rule_Interchange_Format)[Semantic Web Rule Language](https://en.wikipedia.org/wiki/Semantic_Web_Rule_Language)[ALPS](https://en.wikipedia.org/w/index.php?title=Application-Level_Profile_Semantics_(ALPS)&action=edit&redlink=1)[SHACL](https://en.wikipedia.org/wiki/SHACL)[eRDF](https://en.wikipedia.org/wiki/Embedded_RDF)[GRDDL](https://en.wikipedia.org/wiki/GRDDL)[Microdata](https://en.wikipedia.org/wiki/Microdata_(HTML))[Microformats](https://en.wikipedia.org/wiki/Microformat)[RDFa](https://en.wikipedia.org/wiki/RDFa)[SAWSDL](https://en.wikipedia.org/wiki/SAWSDL)[Facebook Platform](https://en.wikipedia.org/wiki/Facebook_Platform)[DOAP](https://en.wikipedia.org/wiki/DOAP)[Dublin Core](https://en.wikipedia.org/wiki/Dublin_Core)[Schema.org](https://en.wikipedia.org/wiki/Schema.org)[SIOC](https://en.wikipedia.org/wiki/Semantically_Interlinked_Online_Communities)[SKOS](https://en.wikipedia.org/wiki/Simple_Knowledge_Organization_System)[hAtom](https://en.wikipedia.org/wiki/HAtom)[hCalendar](https://en.wikipedia.org/wiki/HCalendar)[hCard](https://en.wikipedia.org/wiki/HCard)[hProduct](https://en.wikipedia.org/wiki/HProduct)[hRecipe](https://en.wikipedia.org/wiki/HRecipe)[hReview](https://en.wikipedia.org/wiki/HReview)[v](https://en.wikipedia.org/wiki/Template:Social_networking)[t](https://en.wikipedia.org/wiki/Template_talk:Social_networking)[e](https://en.wikipedia.org/wiki/Special:EditPage/Template:Social_networking)[Social networks](https://en.wikipedia.org/wiki/Social_network)[social media](https://en.wikipedia.org/wiki/Social_media)[Personal](https://en.wikipedia.org/wiki/Personal_network)[Professional](https://en.wikipedia.org/wiki/Professional_network_service)[Sexual](https://en.wikipedia.org/wiki/Sexual_network)[Value](https://en.wikipedia.org/wiki/Value_network)[Clique](https://en.wikipedia.org/wiki/Clique)[Adolescent](https://en.wikipedia.org/wiki/Adolescent_clique)[Corporate social media](https://en.wikipedia.org/wiki/Corporate_social_media)[Distributed social network](https://en.wikipedia.org/wiki/Distributed_social_network)[list](https://en.wikipedia.org/wiki/Comparison_of_software_and_protocols_for_distributed_social_networking)[Enterprise social networking](https://en.wikipedia.org/wiki/Enterprise_social_networking)[Enterprise social software](https://en.wikipedia.org/wiki/Enterprise_social_software)[Mobile social network](https://en.wikipedia.org/wiki/Mobile_social_network)[Personal knowledge networking](https://en.wikipedia.org/wiki/Personal_knowledge_networking)[Services](https://en.wikipedia.org/wiki/Social_networking_service)[List of social networking services](https://en.wikipedia.org/wiki/List_of_social_networking_services)[List of virtual communities with more than 1 million users](https://en.wikipedia.org/wiki/List_of_virtual_communities_with_more_than_1_million_users)[Ambient awareness](https://en.wikipedia.org/wiki/Ambient_awareness)[Assortative mixing](https://en.wikipedia.org/wiki/Assortative_mixing)[Attention inequality](https://en.wikipedia.org/wiki/Attention_inequality)[Interpersonal bridge](https://en.wikipedia.org/wiki/Bridge_(interpersonal))[Organizational network analysis](https://en.wikipedia.org/wiki/Organizational_network_analysis)[Small-world experiment](https://en.wikipedia.org/wiki/Small-world_experiment)[Social aspects of television](https://en.wikipedia.org/wiki/Social_aspects_of_television)[Social capital](https://en.wikipedia.org/wiki/Social_capital)[Social data revolution](https://en.wikipedia.org/wiki/Social_data_revolution)[Social exchange theory](https://en.wikipedia.org/wiki/Social_exchange_theory)[Social identity theory](https://en.wikipedia.org/wiki/Social_identity_theory)[Social media and psychology](https://en.wikipedia.org/wiki/Social_media_and_psychology)[Social media intelligence](https://en.wikipedia.org/wiki/Social_media_intelligence)[Social media mining](https://en.wikipedia.org/wiki/Social_media_mining)[Social media optimization](https://en.wikipedia.org/wiki/Social_media_optimization)[Social network analysis](https://en.wikipedia.org/wiki/Social_network_analysis)[Social web](https://en.wikipedia.org/wiki/Social_web)[Structural endogamy](https://en.wikipedia.org/wiki/Structural_endogamy)[Virtual collective consciousness](https://en.wikipedia.org/wiki/Virtual_collective_consciousness)[Account verification](https://en.wikipedia.org/wiki/Account_verification)[Aggregation](https://en.wikipedia.org/wiki/Social_network_aggregation)[Change detection](https://en.wikipedia.org/wiki/Social_network_change_detection)[Blockmodeling](https://en.wikipedia.org/wiki/Blockmodeling)[Collaboration graph](https://en.wikipedia.org/wiki/Collaboration_graph)[Collaborative consumption](https://en.wikipedia.org/wiki/Collaborative_consumption)[Giant Global Graph](https://en.wikipedia.org/wiki/Giant_Global_Graph)[Lateral communication](https://en.wikipedia.org/wiki/Lateral_communication)[Reputation system](https://en.wikipedia.org/wiki/Reputation_system)[Social bot](https://en.wikipedia.org/wiki/Social_bot)[Social graph](https://en.wikipedia.org/wiki/Social_graph)[Social media analytics](https://en.wikipedia.org/wiki/Social_media_analytics)[Social network analysis software](https://en.wikipedia.org/wiki/Social_network_analysis_software)[Social networking potential](https://en.wikipedia.org/wiki/Social_networking_potential)[Social television](https://en.wikipedia.org/wiki/Social_television)[Structural cohesion](https://en.wikipedia.org/wiki/Structural_cohesion)[Affinity fraud](https://en.wikipedia.org/wiki/Affinity_fraud)[Attention economy](https://en.wikipedia.org/wiki/Attention_economy)[Collaborative finance](https://en.wikipedia.org/wiki/Collaborative_finance)[Creator economy](https://en.wikipedia.org/wiki/Creator_economy)[Influencer marketing](https://en.wikipedia.org/wiki/Influencer_marketing)[Narrowcasting](https://en.wikipedia.org/wiki/Narrowcasting)[Sharing economy](https://en.wikipedia.org/wiki/Sharing_economy)[Social commerce](https://en.wikipedia.org/wiki/Social_commerce)[Social sorting](https://en.wikipedia.org/wiki/Social_sorting)[Viral marketing](https://en.wikipedia.org/wiki/Viral_marketing)[Algorithmic radicalization](https://en.wikipedia.org/wiki/Algorithmic_radicalization)[Community recognition](https://en.wikipedia.org/wiki/Community_recognition)[Complex contagion](https://en.wikipedia.org/wiki/Complex_contagion)[Computer addiction](https://en.wikipedia.org/wiki/Computer_addiction)[Consequential strangers](https://en.wikipedia.org/wiki/Consequential_strangers)[Friend of a friend](https://en.wikipedia.org/wiki/Friend_of_a_friend)[Friending and following](https://en.wikipedia.org/wiki/Friending_and_following)[Friendship paradox](https://en.wikipedia.org/wiki/Friendship_paradox)[Influence-for-hire](https://en.wikipedia.org/wiki/Influence-for-hire)[Internet addiction](https://en.wikipedia.org/wiki/Internet_addiction)[Information overload](https://en.wikipedia.org/wiki/Information_overload)[Overchoice](https://en.wikipedia.org/wiki/Overchoice)[Six degrees of separation](https://en.wikipedia.org/wiki/Six_degrees_of_separation)[Social media addiction](https://en.wikipedia.org/wiki/Social_media_addiction)[Social media and suicide](https://en.wikipedia.org/wiki/Social_media_and_suicide)[Social invisibility](https://en.wikipedia.org/wiki/Social_invisibility)[Social network game](https://en.wikipedia.org/wiki/Social_network_game)[Suicide and the Internet](https://en.wikipedia.org/wiki/Suicide_and_the_Internet)[Tribe](https://en.wikipedia.org/wiki/Tribe_(internet))[Viral phenomenon](https://en.wikipedia.org/wiki/Viral_phenomenon)[Friendship recession](https://en.wikipedia.org/wiki/Friendship_recession)[Peer pressure](https://en.wikipedia.org/wiki/Peer_pressure)[Researchers](https://en.wikipedia.org/wiki/List_of_social_network_researchers)[User profile](https://en.wikipedia.org/wiki/User_profile)[Online identity](https://en.wikipedia.org/wiki/Online_identity)[Persona](https://en.wikipedia.org/wiki/Persona_(user_experience))[Social profiling](https://en.wikipedia.org/wiki/Social_profiling)[Viral messages](https://en.wikipedia.org/wiki/Viral_messages)[Virtual community](https://en.wikipedia.org/wiki/Virtual_community)[https://en.wikipedia.org/w/index.php?title=FOAF&oldid=1165941964](https://en.wikipedia.org/w/index.php?title=FOAF&oldid=1165941964)[Categories](https://en.wikipedia.org/wiki/Help:Category)[Ontology (information science)](https://en.wikipedia.org/wiki/Category:Ontology_(information_science))[Semantic Web](https://en.wikipedia.org/wiki/Category:Semantic_Web)[2000 software](https://en.wikipedia.org/wiki/Category:2000_software)[Articles with short description](https://en.wikipedia.org/wiki/Category:Articles_with_short_description)[Short description matches Wikidata](https://en.wikipedia.org/wiki/Category:Short_description_matches_Wikidata)[All articles with unsourced statements](https://en.wikipedia.org/wiki/Category:All_articles_with_unsourced_statements)[Articles with unsourced statements from April 2017](https://en.wikipedia.org/wiki/Category:Articles_with_unsourced_statements_from_April_2017)[Wikipedia articles needing clarification from April 2017](https://en.wikipedia.org/wiki/Category:Wikipedia_articles_needing_clarification_from_April_2017)[Webarchive template wayback links](https://en.wikipedia.org/wiki/Category:Webarchive_template_wayback_links)[Creative Commons Attribution-ShareAlike License 4.0](https://en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License)[](https://en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License)[Terms of Use](https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Terms_of_Use)[Privacy Policy](https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy)[Wikimedia Foundation, Inc.](https://www.wikimediafoundation.org/)[Privacy policy](https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy)[About Wikipedia](https://en.wikipedia.org/wiki/Wikipedia:About)[Disclaimers](https://en.wikipedia.org/wiki/Wikipedia:General_disclaimer)[Contact Wikipedia](https://en.wikipedia.org/wiki/Wikipedia:Contact_us)[Code of Conduct](https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Universal_Code_of_Conduct)[Developers](https://developer.wikimedia.org)[Statistics](https://stats.wikimedia.org/#/en.wikipedia.org)[Cookie statement](https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Cookie_statement)[Mobile view](https://en.m.wikipedia.org/w/index.php?title=FOAF&mobileaction=toggle_view_mobile)[](https://wikimediafoundation.org/)[](https://www.mediawiki.org/)~done~[http://xmlns.com/foaf/spec/20140114.html](http://xmlns.com/foaf/spec/20140114.html)[rdf](http://xmlns.com/foaf/spec/20140114.rdf)[http://xmlns.com/foaf/spec/](http://xmlns.com/foaf/spec/)[rdf](http://xmlns.com/foaf/spec/index.rdf)[http://xmlns.com/foaf/spec/20100809.html](http://xmlns.com/foaf/spec/20100809.html)[rdf](http://xmlns.com/foaf/spec/20100809.rdf)[Dan Brickley](mailto:danbri@danbri.org)[Libby Miller](mailto:libby@nicecupoftea.org)[foaf-dev@lists.foaf-project.org](http://lists.foaf-project.org/)[RDF
    and Semantic Web developer community](http://www.w3.org/2001/sw/interest/)[](http://creativecommons.org/licenses/by/1.0/)[Creative Commons Attribution License](http://creativecommons.org/licenses/by/1.0/)[RDF](http://www.w3.org/RDF/)[FOAF project](http://www.foaf-project.org/)[RDFS/OWL](http://xmlns.com/foaf/spec/index.rdf)[per-term](http://xmlns.com/foaf/doc/)[multilingual translations](http://svn.foaf-project.org/foaftown/foaf18n/)[direct link](http://xmlns.com/foaf/spec/index.rdf)[content negotiation](http://en.wikipedia.org/wiki/Content_negotiation)[namespace URI](http://xmlns.com/foaf/0.1/)[foaf-dev@lists.foaf-project.org](mailto:foaf-dev@lists.foaf-project.org)[public archives](http://lists.foaf-project.org)[FOAF mailing list](mailto:foaf-dev@lists.foaf-project.org)[FOAF website](http://www.foaf-project.org/)[Dublin Core](http://www.dublincore.org/)[SKOS](http://www.w3.org/2004/02/skos/)[DOAP](http://trac.usefulinc.com/doap)[SIOC](http://sioc-project.org/)[Org vocabulary](http://www.epimorphics.com/public/vocabulary/org.html)[Bio vocabulary](http://vocab.org/bio/0.1/.html)[Portable Contacts](http://portablecontacts.net/)[W3C Social Web group](http://www.w3.org/2005/Incubator/socialweb/)[W3 future directions](http://www.w3.org/Talks/WWW94Tim/)[Giant Global Graph](http://dig.csail.mit.edu/breadcrumbs/node/215)[foaf](http://www.w3.org/People/Berners-Lee/card)[Semantic Web](http://www.w3.org/2001/sw/)[SPARQL](http://www.w3.org/TR/rdf-sparql-query/)[SKOS](http://www.w3.org/2004/02/skos/)[GRDDL](http://www.w3.org/2001/sw/grddl-wg/)[RDFa](http://www.w3.org/TR/xhtml-rdfa-primer/)[Linked 
  Data](http://www.w3.org/DesignIssues/LinkedData.html)[FOAF namespace
  document](http://xmlns.com/foaf/0.1/)[XML
  Watch: Finding friends with XML and RDF](http://www-106.ibm.com/developerworks/xml/library/x-foaf.html)[with image metadata](http://rdfweb.org/2002/01/photo/)[co-depiction](http://rdfweb.org/2002/01/photo/)[FOAF-a-matic](http://www.ldodds.com/foaf/foaf-a-matic.html)[FOAF project home page](http://www.foaf-project.org)[alt.folklore.urban archive](http://www.urbanlegends.com/)[snopes.com](http://www.snopes.com/)[ISO
  Standardisation](http://www.iso.ch/iso/en/ISOOnline.openerpage)[W3C](http://www.w3.org/)[Process](http://www.w3.org/Consortium/Process/)[Open Source](http://www.opensource.org/)[Free Software](http://www.gnu.org/philosophy/free-sw.html)[Jabber
  JEPs](http://www.jabber.org/jeps/jep-0001.html)[Resource Description Framework](http://www.w3.org/RDF/)[RDF](http://www.w3.org/RDF/)[Semantic Web](http://www.w3.org/2001/sw/)[Semantic Web](http://www.w3.org/2001/sw/)[Dublin Core](http://dublincore.org/)[foaf-a-matic](http://www.ldodds.com/foaf/foaf-a-matic.html)[FOAF
  autodiscovery](http://web.archive.org/web/20040416181630/rdfweb.org/mt/foaflog/archives/000041.html)[RDF/XML](http://xmlns.com/foaf/spec/index.rdf)[issue tracker](http://wiki.foaf-project.org/w/IssueTracker)[OWL](http://www.w3.org/2001/sw/WebOnt)[GRDDL](http://www.w3.org/2004/01/rdxh/spec)[Jabber](http://www.jabber.org/)[AIM](http://www.aim.com/)[MSN](http://chat.msn.com/)[ICQ](http://web.icq.com/icqchat/)[Yahoo!](http://chat.yahoo.com/)[MSN](http://chat.msn.com/)[Freenode](http://www.freenode.net/)[Amazon](http://www.amazon.com/)[eBay](http://www.ebay.com/)[PayPal](http://www.paypal.com/)[thinkgeek](http://www.thinkgeek.com/)[EverQuest](http://everquest.station.sony.com/)[Xbox live](http://www.xbox.com/live/)[Neverwinter Nights](http://nwn.bioware.com/)[Relationship module](http://www.perceive.net/schemas/20021119/relationship/)[scutters](http://wiki.foaf-project.org/w/ScutterSpec)[UsingDublinCoreCreator](http://wiki.foaf-project.org/w/UsingDublinCoreCreator)[RFC 2368](http://ftp.ics.uci.edu/pub/ietf/uri/rfc2368.txt)[Wikipedia](http://www.wikipedia.org/)[NNDB](http://www.nndb.com/)[AIM](http://www.aim.com/)[iChat](http://www.apple.com/macosx/what-is-macosx/ichat.html)[Apple](http://www.apple.com/)[geo-positioning vocabulary](http://www.w3.org/2003/01/geo/wgs84_pos#)[GeoInfo](http://esw.w3.org/topic/GeoInfo)[GeoOnion vocab](http://esw.w3.org/topic/GeoOnion)[UsingContactNearestAirport](http://wiki.foaf-project.org/w/UsingContactNearestAirport)[Co-Depiction](http://rdfweb.org/2002/01/photo/)['Annotating Images With SVG'](http://www.jibbering.com/svg/AnnotateImage.html)[issue tracker](http://wiki.foaf-project.org/w/NameVocabIssue)[issue tracker](http://wiki.foaf-project.org/w/NameVocabIssue)[SKOS](http://www.w3.org/2004/02/skos/)[In SKOS](http://www.w3.org/TR/2005/WD-swbp-skos-core-guide-20050510/#secmodellingrdf)[2005 discussion](http://www.w3.org/TR/2005/WD-swbp-skos-core-guide-20051102/#secopen)[TDB URI scheme](http://larry.masinter.net/duri.html)[original goals](http://www.foaf-project.org/original-intro)[foaf-dev](http://lists.foaf-project.org/mailman/listinfo/foaf-dev)[issue tracker](http://wiki.foaf-project.org/w/NameVocabIssue)[icq chat](http://web.icq.com/icqchat/)[What is ICQ?](http://www.icq.com/products/whatisicq.html)[About Us](http://company.icq.com/info/)[RDF](http://www.w3.org/RDF/)[CPAN](http://www.cpan.org/)[Jabber](http://www.jabber.org/)[Jabber](http://www.jabber.org/)[issue tracker](http://wiki.foaf-project.org/w/NameVocabIssue)[Edd Dumbill's 
documentation](http://usefulinc.com/foaf/)[FOAF-based whitelists](http://www.w3.org/2001/12/rubyrdf/util/foafwhite/intro.html)[in Sam Ruby's 
weblog entry](http://www.intertwingly.net/blog/1545.html)[Windows Live Messenger](http://en.wikipedia.org/wiki/Windows_Live_Messenger)[Microsoft mesenger](http://download.live.com/messenger)[Windows Live ID](http://en.wikipedia.org/wiki/Windows_Live_ID)[this article](http://www.teamtechnology.co.uk/tt/t-articl/mb-simpl.htm)[Cory Caplinger's summary table](http://webspace.webring.com/people/cl/lifexplore/mbintro.htm)[FOAF Myers Briggs addition](http://web.archive.org/web/20080802184922/http://rdfweb.org/mt/foaflog/archives/000004.html)[issue tracker](http://wiki.foaf-project.org/w/IssueTracker)[indirect identifier](http://www.w3.org/TR/webarch/#indirect-identification)[OpenID](http://openid.net/specs/openid-authentication-1_1.html)[delegation model](http://openid.net/specs/openid-authentication-1_1.html#delegating_authentication)[technique](http://xmlns.com/foaf/spec/#sec-autodesc)[History of the 
Finger Protocol](http://www.rajivshah.com/Case_Studies/Finger/Finger.htm)[discussions](http://rdfweb.org/mt/foaflog/archives/2004/02/12/20.07.32/)[PayPal](http://www.paypal.com/)[FOAF Issue Tracker](http://wiki.foaf-project.org/w/IssueTracker)[Yahoo! Chat](http://chat.yahoo.com/)[Yahoo! Groups](http://www.yahoogroups.com/)[BirthdayIssue](http://wiki.foaf-project.org/w/BirthdayIssue)[Wikipedia entry](http://en.wikipedia.org/wiki/Geek_Code)[issue tracker](http://wiki.foaf-project.org/w/NameVocabIssue)[issue 
tracker](http://wiki.foaf-project.org/w/IssueTracker)[SemWeb Vocab Status Ontology](http://www.w3.org/2003/06/sw-vocab-status/note)[W3CBasic Geo Vocabulary](http://www.w3.org/2003/01/geo/)[W3C's site](http://www.w3.org/2001/sw/)[more background on URIs](http://www.w3.org/TR/webarch/#identification)[linked data](http://www.w3.org/DesignIssues/LinkedData)[SKOS](http://www.w3.org/2004/02/skos/)[Dublin Core terms](http://dublincore.org/documents/dcmi-terms/)[dct:Agent](http://dublincore.org/documents/dcmi-terms/#classes-Agent)[dct:creator](http://dublincore.org/documents/dcmi-terms/#terms-creator)[recent](http://www.w3.org/TR/wordnet-rdf/)[SIOC](http://rdfs.org/sioc/ns#)[SIOC](http://www.sioc-project.org/)[rdfweb-dev](http://rdfweb.org/pipermail/rdfweb-dev/)[#foaf](http://rdfweb.org/irc/)[FoafExplorer](http://xml.mfd-consult.dk/foaf/explorer/)[Web View](http://eikeon.com/foaf/)[foaf-a-matic](http://www.ldodds.com/foaf/foaf-a-matic.html)[Ecademy](http://www.ecademy.com/)[TypePad](http://www.typepad.com/)[many](http://conferences.oreillynet.com/cs/et2003/view/e_sess/3633)[explaining](http://hackdiary.com/)[in Japanese](http://kanzaki.com/docs/sw/foaf.html)[Spanish](http://f14web.com.ar/inkel/2003/01/27/foaf.html)[Chris Schmidt](http://crschmidt.net/)[spec generation](http://xmlns.com/foaf/0.1/specgen.py)[cool hacks](http://crschmidt.net/semweb/)[FOAF Logo](http://iandavis.com/2006/foaf-icons/)[years ago](http://www.w3.org/History/1989/proposal.html)[schema.org](http://schema.org/)[Person](http://schema.org/Person)[ImageObject](http://schema.org/ImageObject)[CreativeWork](http://schema.org/CreativeWork)[Bio vocabulary](http://vocab.org/bio/0.1/.html)[0.97](http://xmlns.com/foaf/spec/20100101.html)[0.96](http://xmlns.com/foaf/spec/20091215.html)[Portable Contacts](http://portablecontacts.net/)

================
File: output.txt
================
Hello world world

================
File: package.json
================
{
  "type": "module",
  "version": "1.0.0",
  "description": "Transmissions",
  "name": "transmissions",
  "scripts": {
    "test": "jasmine --config=jasmine.json --reporter=tests/helpers/reporter.js",
    "docs": "jsdoc -c jsdoc.json",
    "build": "webpack --mode=production --node-env=production",
    "build:dev": "webpack --mode=development",
    "build:prod": "webpack --mode=production --node-env=production",
    "watch": "webpack --watch",
    "serve": "webpack serve"
  },
  "devDependencies": {
    "@babel/core": "^7.23.7",
    "@babel/preset-env": "^7.23.8",
    "autoprefixer": "^10.4.17",
    "babel-loader": "^9.1.3",
    "chai": "^5.0.3",
    "css-loader": "^6.9.1",
    "html-webpack-plugin": "^5.6.0",
    "jasmine": "^5.1.0",
    "jasmine-browser-runner": "^2.3.0",
    "jasmine-core": "^5.1.1",
    "jasmine-spec-reporter": "^7.0.0",
    "jsdoc": "^4.0.2",
    "mini-css-extract-plugin": "^2.7.7",
    "postcss": "^8.4.33",
    "postcss-loader": "^8.0.0",
    "prettier": "^3.2.4",
    "style-loader": "^3.3.4",
    "webpack": "^5.90.0",
    "webpack-cli": "^5.1.4",
    "webpack-dev-server": "^4.15.1",
    "workbox-webpack-plugin": "^7.0.0"
  },
  "dependencies": {
    "@rdfjs/formats": "^4.0.0",
    "axios": "^1.6.8",
    "cheerio": "^1.0.0-rc.12",
    "marked": "^12.0.1",
    "nunjucks": "^3.2.4",
    "queue": "^7.0.0",
    "rdf-utils-fs": "^3.0.0",
    "yargs": "^17.7.2"
  }
}

================
File: postcss.config.js
================
module.exports = {
  plugins: [["autoprefixer"]],
};

================
File: raw-src/README.md
================
The files here are minimal versions of services etc, to try in isolation before integrating into the main codebase.

================
File: raw-src/containsAny.js
================
function containsAny(contentString, matchers) {
    return matchers.some(matcher => contentString.includes(matcher));
}
const contentString = "Hello, world! Welcome to coding.";
const matchers = ["coding", "javascript"];
console.log(containsAny(contentString, matchers));
const matchers2 = ["python", "java"];
console.log(containsAny(contentString, matchers2));

================
File: raw-src/crawl-fs.js
================
import { readdir } from 'fs/promises'
import { join, extname } from 'path'
const desiredExtensions = ['.html', '.txt']
async function crawlDirectory(dirPath) {
    try {
        const entries = await readdir(dirPath, { withFileTypes: true })
        for (const entry of entries) {
            const fullPath = join(dirPath, entry.name)
            if (entry.isDirectory()) {
                await crawlDirectory(fullPath)
            } else {
                if (desiredExtensions.includes(extname(entry.name))) {
                    console.log(fullPath)
                }
            }
        }
    } catch (error) {
        console.error('An error occurred:', error)
    }
}
crawlDirectory('../data/mail-archive-sample')

================
File: raw-src/grapoi-bits.js
================
const poi = this.getMyPoi()
logger.log('POIPOI')
for (const quad of poi.out().quads()) {
    logger.log(`\t${quad.predicate.value}: ${quad.object.value}`)
}

================
File: raw-src/postcraft-transmission.ttl
================
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix trm: <http://purl.org/stuff/transmission/> . # TODO make plural
@prefix : <http://hyperdata.it/transmissions/> . # for custom terms & instances - TODO make one @services s: 

:postcraft a trm:Pipeline ;
    trm:pipe (:s1 :s2 :s3 :s4 :s5 :s6) . #  :s6  :s10 :s11 :s12 :s13

:s1 a :ContextReader . # the manifest
:s2 a :ConfigMap . 

### use services.ttl? - defer to RemapContext as possible

# :s3 a :FileReader . # the template for main page
# :s4 a :RemapContext ;
#    trm:configKey :mainTemplateDirMap .

:s3 a :FileReader . # the template for posts

:s4 a :RemapContext ;
    trm:configKey :postTemplateMap .
# context.content -> context.template ## Remaps should go here????
#
:s5 a :DirWalker ;
    trm:configKey :files .

 #:s6 a :ShowMessage .

# process forks here 

:s6 a :FileReader . # the markdown content

:s7 a :PostcraftPrep . # set up title, filenames etc

:s8 a :MarkdownToHTML .
:s9 a :Templater .

:s10 a :RemapContext ;
   trm:configKey :postSaver .

# :s11 a :NOP .
:s11 a :FileWriter .

:s12 a :NOP .
#:s12 a :Unfork ;
 #   trm:configKey :combinePosts .

:s13 a :ShowMessage .

================
File: raw-src/regex-play.js
================

const mini = 'keep this\n>remove this\n\n keep this'
const replied = 'for this usage.\n> My real intent is to use karma as a type of point system or game/task\n>\n>\n> I am not sure. \n>and another\nfollowed by normal, then \n>one final quoted line'
const first = '> a quote first line\nthen normal'
const regexMini = /\n>.*\n/gi
const regexFirst = /(^|\n)>.*\n/gi
const regexReplied = /((^|\n)>)+.*\n/gi
console.log('[[[\n' + replied.replace(regexReplied, '\n') + '\n]]]\n\n')

================
File: raw-src/structure-play.js
================

let b = 'B'
let a = 'twat'
let c = a => b

================
File: repopack.config.json
================
{
    "output": {
        "filePath": "./misc/transmissions-repopack.txt",
        "headerText": "Transmissions repo",
        "removeComments": true
    },
    "ignore": {
        "useDefaultPatterns": true,
        "customPatterns": [
            "*.log",
            "docs/jsdoc",
            "docs/media",
            "docs/postcraft-site",
            "src/applications/mail-archive-meta"
        ]
    }
}

================
File: run
================
#!/bin/bash

# run
# use 'chmod +x run' to make this executable


# Execute the Node.js script with Node
node run.js "$@"

================
File: run.js
================

import yargs from 'yargs';
import { hideBin } from 'yargs/helpers';
import { promises as fs } from 'fs';
import path from 'path';
import logger from './src/utils/Logger.js'
import TransmissionBuilder from './src/engine/TransmissionBuilder.js'
const applicationsDir = './src/applications'
class CommandUtils {
    static async run(dir, data, context = {}) {
        context.dataString = data
        logger.setLogLevel("info")
        logger.debug("Hello, logger!")
        logger.debug("process.cwd() = " + process.cwd())
        const transmissionConfigFile = path.join(dir, 'transmission.ttl')
        const servicesConfigFile = path.join(dir, 'services.ttl')
        const transmission = await TransmissionBuilder.build(transmissionConfigFile, servicesConfigFile)
        transmission.execute(context)
    }
    static async parseOrLoadContext(contextArg) {
        let context = ''
        try {
            // First, try to parse it directly as JSON
            //   logger.log('contextArg = ' + contextArg)
            context = JSON.parse(contextArg)
            //   logger.log('context from string = ' + context)
        } catch (err) {
            logger.log(err)
            // If it fails, assume it's a filename and try to load the file
            const filePath = path.resolve(contextArg);
            const fileContent = await fs.readFile(filePath, 'utf8');
            context = JSON.parse(fileContent)
            logger.log('context from file = ' + context)
        }
        return context
    }
    static async listSubdirectories(currentDirectory) {
        try {
            const entries = await fs.readdir(currentDirectory, { withFileTypes: true });
            const subdirChecks = entries.filter(dirent => dirent.isDirectory()).map(async (dirent) => {
                const subdirPath = path.join(currentDirectory, dirent.name);
                const files = await fs.readdir(subdirPath);
                return files.includes('about.md') ? dirent.name : null;
            })
            const subdirsContainingAboutMd = (await Promise.all(subdirChecks)).filter(name => name !== null);
            subdirsContainingAboutMd.forEach(dir => console.log(dir));
        } catch (err) {
            console.error('Error listing subdirectories:', err);
        }
    }
}
let context = {}
if (process.argv.length <= 2) {
    console.log('Available applications :');
    CommandUtils.listSubdirectories(applicationsDir)
} else {
    await yargs(hideBin(process.argv))
        .usage('Usage: $0 <command> [options]')
        .option('context', {
            alias: 'c',
            describe: 'Context as a JSON string or a path to a JSON file',
            type: 'string',
        })
        .command('$0 <dirName> [input]', 'Runs the specified transmission with optional input value', (yargs) => {
            return yargs.positional('dirName', {
                describe: 'The transmission to run',
                type: 'string'
            })
                .positional('input', {
                    describe: 'The optional input',
                    type: 'string',
                    default: '' // Default value if the second argument is not provided
                })
        }, async (argv) => {
            const { dirName, input, context: contextArg } = argv // TODO what's that arg for context?
            const transmissionPath = path.join(applicationsDir, dirName)
            const defaultDataDir = path.join(transmissionPath, '/data')
            context = { "dataDir": defaultDataDir }
            context.rootDir = input
            if (contextArg) {
                context = await CommandUtils.parseOrLoadContext(contextArg);
            }
            logger.log('transmissionPath = ' + transmissionPath)
            logger.log('input = ' + input)
            logger.log('context = ')
            logger.reveal(context)
            await CommandUtils.run(transmissionPath, input, context)
        })
        .help('h')
        .alias('h', 'help')
        .fail((msg, err, yargs) => {
            if (err) throw err;
            console.error(msg);
            process.exit(1);
        })
        .argv
}

================
File: run1.txt
================
[api.logger] log level: info
[api.logger] disabling console.debug()

+ ***** Load Config ******
[Transmission : src/applications/postcraft/transmission.ttl]
[Config : src/applications/postcraft/services.ttl]

+ ***** Construct *****
| Create service <http://hyperdata.it/transmissions/s1> of type <http://hyperdata.it/transmissions/ContextReader>
| Create service <http://hyperdata.it/transmissions/s2> of type <http://hyperdata.it/transmissions/ConfigMap>
  > Connect #1 [http://hyperdata.it/transmissions/s1] => [http://hyperdata.it/transmissions/s2]
| Create service <http://hyperdata.it/transmissions/s3> of type <http://hyperdata.it/transmissions/FileReader>
  > Connect #2 [http://hyperdata.it/transmissions/s2] => [http://hyperdata.it/transmissions/s3]
| Create service <http://hyperdata.it/transmissions/s4> of type <http://hyperdata.it/transmissions/RemapContext>
  > Connect #3 [http://hyperdata.it/transmissions/s3] => [http://hyperdata.it/transmissions/s4]
| Create service <http://hyperdata.it/transmissions/s5> of type <http://hyperdata.it/transmissions/DirWalker>
  > Connect #4 [http://hyperdata.it/transmissions/s4] => [http://hyperdata.it/transmissions/s5]
| Create service <http://hyperdata.it/transmissions/s6> of type <http://hyperdata.it/transmissions/FileReader>
  > Connect #5 [http://hyperdata.it/transmissions/s5] => [http://hyperdata.it/transmissions/s6]
| Create service <http://hyperdata.it/transmissions/s7> of type <http://hyperdata.it/transmissions/PostcraftPrep>
  > Connect #6 [http://hyperdata.it/transmissions/s6] => [http://hyperdata.it/transmissions/s7]
| Create service <http://hyperdata.it/transmissions/s8> of type <http://hyperdata.it/transmissions/MarkdownToHTML>
  > Connect #7 [http://hyperdata.it/transmissions/s7] => [http://hyperdata.it/transmissions/s8]
| Create service <http://hyperdata.it/transmissions/s9> of type <http://hyperdata.it/transmissions/Templater>
  > Connect #8 [http://hyperdata.it/transmissions/s8] => [http://hyperdata.it/transmissions/s9]
| Create service <http://hyperdata.it/transmissions/s10> of type <http://hyperdata.it/transmissions/RemapContext>
  > Connect #9 [http://hyperdata.it/transmissions/s9] => [http://hyperdata.it/transmissions/s10]
| Create service <http://hyperdata.it/transmissions/s11> of type <http://hyperdata.it/transmissions/FileWriter>
  > Connect #10 [http://hyperdata.it/transmissions/s10] => [http://hyperdata.it/transmissions/s11]

+ ***** Execute *****
| Running : http://hyperdata.it/transmissions/s1 a ContextReader
| Running : http://hyperdata.it/transmissions/s2 a ConfigMap
--- ConfigMap --- contentGroupID = http://hyperdata.it/transmissions/PostContent
---
Properties of the Grapoi object:
	factory: [object Object]
	ptrs: [object Object]

Path:
	http://www.w3.org/1999/02/22-rdf-syntax-ns#type: http://purl.org/stuff/postcraft/ContentGroup
	http://www.w3.org/1999/02/22-rdf-syntax-ns#type: http://purl.org/stuff/postcraft/ContentGroup
	http://www.w3.org/1999/02/22-rdf-syntax-ns#type: http://purl.org/stuff/postcraft/ContentGroup
	http://www.w3.org/1999/02/22-rdf-syntax-ns#type: http://purl.org/stuff/postcraft/ContentGroup
	http://www.w3.org/1999/02/22-rdf-syntax-ns#type: http://purl.org/stuff/postcraft/Partial
	http://www.w3.org/1999/02/22-rdf-syntax-ns#type: http://purl.org/stuff/postcraft/Partial
	http://purl.org/stuff/filesystem/sourceDirectory: test
	http://purl.org/stuff/filesystem/sourceDirectory: test
	http://purl.org/stuff/filesystem/targetDirectory: site/post-content-cache
	http://purl.org/stuff/filesystem/targetDirectory: site/post-content-cache
	http://purl.org/stuff/filesystem/targetDirectory: site/post-content-cache
	http://purl.org/stuff/filesystem/sourceDirectory: site/post-content-cache
	http://purl.org/stuff/filesystem/targetDirectory: site/post-content-cache
	http://purl.org/stuff/filesystem/sourceDirectory: site/post-content-cache
	http://purl.org/stuff/postcraft/template: layouts/mediocre/post-content_template.njk
	http://purl.org/stuff/postcraft/template: layouts/mediocre/post-content_template.njk
---
| Running : http://hyperdata.it/transmissions/s3 a FileReader
 - FileReader reading : layouts/mediocre/post-content_template.njk
--- ConfigMap --- contentGroupID = http://hyperdata.it/transmissions/PostPages
---
Properties of the Grapoi object:
	factory: [object Object]
	ptrs: [object Object]

Path:
	http://www.w3.org/1999/02/22-rdf-syntax-ns#type: http://purl.org/stuff/postcraft/ContentGroup
	http://www.w3.org/1999/02/22-rdf-syntax-ns#type: http://purl.org/stuff/postcraft/ContentGroup
	http://www.w3.org/1999/02/22-rdf-syntax-ns#type: http://purl.org/stuff/postcraft/ContentGroup
	http://www.w3.org/1999/02/22-rdf-syntax-ns#type: http://purl.org/stuff/postcraft/ContentGroup
	http://purl.org/stuff/filesystem/sourceDirectory: site/post-content-cache
	http://purl.org/stuff/filesystem/targetDirectory: site/post-content-cache
	http://purl.org/stuff/filesystem/sourceDirectory: site/post-content-cache
	http://purl.org/stuff/filesystem/sourceDirectory: site/post-content-cache
	http://purl.org/stuff/filesystem/sourceDirectory: site/post-content-cache
	http://purl.org/stuff/filesystem/sourceDirectory: site/post-content-cache
	http://purl.org/stuff/filesystem/targetDirectory: site/blog
	http://purl.org/stuff/filesystem/targetDirectory: site/blog
	http://purl.org/stuff/postcraft/template: layouts/mediocre/post-page_template.njk
	http://purl.org/stuff/postcraft/template: layouts/mediocre/post-page_template.njk
---
| Running : http://hyperdata.it/transmissions/s3 a FileReader
| Running : http://hyperdata.it/transmissions/s4 a RemapContext
 - Rename : content to template
| Running : http://hyperdata.it/transmissions/s5 a DirWalker
 - FileReader reading : layouts/mediocre/post-page_template.njk
addPropertyToMyConfig predicate = http://purl.org/stuff/transmission/postPath
addPropertyToMyConfig value = test/2024-05-03_one.md
addPropertyToMyConfig  myConfigNode.value = http://hyperdata.it/transmissions/dirWalkerPosts
| Running : http://hyperdata.it/transmissions/s6 a FileReader
 - FileReader reading : test/2024-05-03_one.md
addPropertyToMyConfig predicate = http://purl.org/stuff/transmission/postPath
addPropertyToMyConfig value = test/2024-05-03_two.md
addPropertyToMyConfig  myConfigNode.value = http://hyperdata.it/transmissions/dirWalkerPosts
| Running : http://hyperdata.it/transmissions/s6 a FileReader
| Running : http://hyperdata.it/transmissions/s4 a RemapContext
 - Rename : content to template
| Running : http://hyperdata.it/transmissions/s5 a DirWalker
| Running : http://hyperdata.it/transmissions/s7 a PostcraftPrep
| Running : http://hyperdata.it/transmissions/s8 a MarkdownToHTML
| Running : http://hyperdata.it/transmissions/s9 a Templater
| Running : http://hyperdata.it/transmissions/s10 a RemapContext
 - Rename : targetFilename to filename
| Running : http://hyperdata.it/transmissions/s11 a FileWriter
 - FileReader reading : test/2024-05-03_two.md
| Running : http://hyperdata.it/transmissions/s7 a PostcraftPrep
| Running : http://hyperdata.it/transmissions/s8 a MarkdownToHTML
| Running : http://hyperdata.it/transmissions/s9 a Templater
| Running : http://hyperdata.it/transmissions/s10 a RemapContext
 - Rename : targetFilename to filename
| Running : http://hyperdata.it/transmissions/s11 a FileWriter
0

================
File: run2.txt
================
[api.logger] log level: info
[api.logger] disabling console.debug()

+ ***** Load Config ******
[Transmission : src/applications/postcraft/transmission.ttl]
[Config : src/applications/postcraft/services.ttl]

+ ***** Construct *****
| Create service <http://hyperdata.it/transmissions/s1> of type <http://hyperdata.it/transmissions/ContextReader>
| Create service <http://hyperdata.it/transmissions/s2> of type <http://hyperdata.it/transmissions/ConfigMap>
  > Connect #1 [http://hyperdata.it/transmissions/s1] => [http://hyperdata.it/transmissions/s2]
| Create service <http://hyperdata.it/transmissions/s3> of type <http://hyperdata.it/transmissions/FileReader>
  > Connect #2 [http://hyperdata.it/transmissions/s2] => [http://hyperdata.it/transmissions/s3]
| Create service <http://hyperdata.it/transmissions/s4> of type <http://hyperdata.it/transmissions/RemapContext>
  > Connect #3 [http://hyperdata.it/transmissions/s3] => [http://hyperdata.it/transmissions/s4]

+ ***** Construct *****
| Create service <http://hyperdata.it/transmissions/s4> of type <http://hyperdata.it/transmissions/RemapContext>
| Create service <http://hyperdata.it/transmissions/s5> of type <http://hyperdata.it/transmissions/DirWalker>
  > Connect #1 [http://hyperdata.it/transmissions/s4] => [http://hyperdata.it/transmissions/s5]
| Create service <http://hyperdata.it/transmissions/s6> of type <http://hyperdata.it/transmissions/FileReader>
  > Connect #2 [http://hyperdata.it/transmissions/s5] => [http://hyperdata.it/transmissions/s6]
| Create service <http://hyperdata.it/transmissions/s7> of type <http://hyperdata.it/transmissions/PostcraftPrep>
  > Connect #3 [http://hyperdata.it/transmissions/s6] => [http://hyperdata.it/transmissions/s7]
| Create service <http://hyperdata.it/transmissions/s8> of type <http://hyperdata.it/transmissions/MarkdownToHTML>
  > Connect #4 [http://hyperdata.it/transmissions/s7] => [http://hyperdata.it/transmissions/s8]
| Create service <http://hyperdata.it/transmissions/s9> of type <http://hyperdata.it/transmissions/Templater>
  > Connect #5 [http://hyperdata.it/transmissions/s8] => [http://hyperdata.it/transmissions/s9]
| Create service <http://hyperdata.it/transmissions/s10> of type <http://hyperdata.it/transmissions/RemapContext>
  > Connect #6 [http://hyperdata.it/transmissions/s9] => [http://hyperdata.it/transmissions/s10]
| Create service <http://hyperdata.it/transmissions/s11> of type <http://hyperdata.it/transmissions/FileWriter>
  > Connect #7 [http://hyperdata.it/transmissions/s10] => [http://hyperdata.it/transmissions/s11]

+ ***** Execute *****
| Running : http://hyperdata.it/transmissions/s1 a ContextReader
| Running : http://hyperdata.it/transmissions/s2 a ConfigMap
--- ConfigMap --- contentGroupID = http://hyperdata.it/transmissions/PostContent
---
Properties of the Grapoi object:
	factory: [object Object]
	ptrs: [object Object]

Path:
	http://www.w3.org/1999/02/22-rdf-syntax-ns#type: http://purl.org/stuff/postcraft/ContentGroup
	http://www.w3.org/1999/02/22-rdf-syntax-ns#type: http://purl.org/stuff/postcraft/ContentGroup
	http://www.w3.org/1999/02/22-rdf-syntax-ns#type: http://purl.org/stuff/postcraft/ContentGroup
	http://www.w3.org/1999/02/22-rdf-syntax-ns#type: http://purl.org/stuff/postcraft/ContentGroup
	http://www.w3.org/1999/02/22-rdf-syntax-ns#type: http://purl.org/stuff/postcraft/Partial
	http://www.w3.org/1999/02/22-rdf-syntax-ns#type: http://purl.org/stuff/postcraft/Partial
	http://purl.org/stuff/filesystem/sourceDirectory: test
	http://purl.org/stuff/filesystem/sourceDirectory: test
	http://purl.org/stuff/filesystem/targetDirectory: site/post-content-cache
	http://purl.org/stuff/filesystem/targetDirectory: site/post-content-cache
	http://purl.org/stuff/filesystem/targetDirectory: site/post-content-cache
	http://purl.org/stuff/filesystem/sourceDirectory: site/post-content-cache
	http://purl.org/stuff/filesystem/targetDirectory: site/post-content-cache
	http://purl.org/stuff/filesystem/sourceDirectory: site/post-content-cache
	http://purl.org/stuff/postcraft/template: layouts/mediocre/post-content_template.njk
	http://purl.org/stuff/postcraft/template: layouts/mediocre/post-content_template.njk
---
| Running : http://hyperdata.it/transmissions/s3 a FileReader
 - FileReader reading : layouts/mediocre/post-content_template.njk
--- ConfigMap --- contentGroupID = http://hyperdata.it/transmissions/PostPages
---
Properties of the Grapoi object:
	factory: [object Object]
	ptrs: [object Object]

Path:
	http://www.w3.org/1999/02/22-rdf-syntax-ns#type: http://purl.org/stuff/postcraft/ContentGroup
	http://www.w3.org/1999/02/22-rdf-syntax-ns#type: http://purl.org/stuff/postcraft/ContentGroup
	http://www.w3.org/1999/02/22-rdf-syntax-ns#type: http://purl.org/stuff/postcraft/ContentGroup
	http://www.w3.org/1999/02/22-rdf-syntax-ns#type: http://purl.org/stuff/postcraft/ContentGroup
	http://purl.org/stuff/filesystem/sourceDirectory: site/post-content-cache
	http://purl.org/stuff/filesystem/targetDirectory: site/post-content-cache
	http://purl.org/stuff/filesystem/sourceDirectory: site/post-content-cache
	http://purl.org/stuff/filesystem/sourceDirectory: site/post-content-cache
	http://purl.org/stuff/filesystem/sourceDirectory: site/post-content-cache
	http://purl.org/stuff/filesystem/sourceDirectory: site/post-content-cache
	http://purl.org/stuff/filesystem/targetDirectory: site/blog
	http://purl.org/stuff/filesystem/targetDirectory: site/blog
	http://purl.org/stuff/postcraft/template: layouts/mediocre/post-page_template.njk
	http://purl.org/stuff/postcraft/template: layouts/mediocre/post-page_template.njk
---
| Running : http://hyperdata.it/transmissions/s3 a FileReader
| Running : http://hyperdata.it/transmissions/s4 a RemapContext
 - Rename : content to template
 - FileReader reading : layouts/mediocre/post-page_template.njk
| Running : http://hyperdata.it/transmissions/s4 a RemapContext
 - Rename : content to template
0

================
File: spec/support/jasmine-browser.json
================
{
  "srcDir": "src",
  "srcFiles": [
    "**/*.js"
  ],
  "specDir": "spec",
  "specFiles": [
    "**/*[sS]pec.js"
  ],
  "helpers": [
    "helpers/**/*.js"
  ],
  "env": {
    "stopSpecOnExpectationFailure": false,
    "stopOnSpecFailure": false,
    "random": true
  },
  "browser": {
    "name": "firefox"
  }
}

================
File: src/applications/dirwalker-test/about.md
================
it originally ran from

transmission.execute('../../data/mail-archive-sample')

================
File: src/applications/dirwalker-test/services.ttl
================
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix trm: <http://purl.org/stuff/transmission/> .
# @prefix fs: <http://purl.org/stuff/filesystem/> .
@prefix t: <http://hyperdata.it/transmissions/> . # for custom terms & instances

t:FilePipelineMap a trm:DataMap ;
    trm:sourceFile "input.txt" ;
    trm:destinationFile "output.txt" .

================
File: src/applications/dirwalker-test/transmission.ttl
================
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix trm: <http://purl.org/stuff/transmission/> .
@prefix : <http://hyperdata.it/transmissions/> . # for custom terms & instances

:dirwalkpipe a trm:Pipeline ;
    trm:pipe (:s1 :s2 :s3) .

:s1 a :DirWalker .
:s2 a :AppendProcess .
:s3 a :StringSink .

================
File: src/applications/file-copy-remove-test/about.md
================
# file-copy-remove-test

this should :

- copy `start/one.txt` into `single-empty/`
- copy `single-empty/one.txt` into `single-full/`
- remove `single-empty/one.txt`

- copy everything in `start/` into `several-empty/`
- copy everything in `several-empty/` into `several-full/`
- remove everything in `several-empty/`

Hmm, test services would be helpful to check before and after - or maybe just use regular test runner script from npm?

run with :

```
transmissions$ ./run file-copy-remove-test
```

================
File: src/applications/file-copy-remove-test/data/start/one.txt
================
Hello from One

================
File: src/applications/file-copy-remove-test/data/start/two.txt
================
Hello from Two

================
File: src/applications/file-copy-remove-test/manifest.ttl
================
### manifest.ttl for danny.ayers.name ###

@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix dcterms: <http://purl.org/dc/terms/> .

# SIOC 

@prefix trm: <http://purl.org/stuff/transmission/> .
@prefix fs: <http://purl.org/stuff/filesystem/> .
@prefix pc: <http://purl.org/stuff/postcraft/> .
@prefix t: <http://hyperdata.it/transmissions/> . # for custom terms & instances


t:PostContent a pc:ContentGroup ; 
    pc:site <https://danny.ayers.name> ;
    pc:subdir "home" ; # better property name?
    fs:sourceDirectory "journal" ; 
    fs:targetDirectory "public/entry-content-cache" ;
    pc:template "layouts/mediocre/templates/entry-content_template.njk" .

# POST PAGES
t:PostPages a pc:ContentGroup ;
    pc:site <https://danny.ayers.name> ;
   # fs:sourceDirectory "public/post-content-cache" ;
    fs:targetDirectory "public/home/entries" ;
    pc:template "layouts/mediocre/templates/entry-page_template.njk" .

# MAIN PAGE
t:IndexPage a pc:ContentGroup ; # TODO naming!
    pc:site <https://danny.ayers.name> ;
    fs:filepath "public/home/index.html" ;
    pc:template "layouts/mediocre/templates/index-page_template.njk" .

# STYLES ETC not yet implemented
t:CSS a pc:StaticGroup ;
    pc:site <https://danny.ayers.name> ;
    fs:sourceDirectory "layouts/mediocre/css" ;
    fs:targetDirectory "public/home/css" .

t:fonts a pc:StaticGroup ;
    pc:site <https://danny.ayers.name> ;
    fs:sourceDirectory "layouts/mediocre/fonts" ;
    fs:targetDirectory "public/home/js" .

t:JS a pc:StaticGroup ;
    pc:site <https://danny.ayers.name> ;
    fs:sourceDirectory "layouts/mediocre/js" ;
    fs:targetDirectory "public/home/js" .


# pinned - not yet implemented
<https://danny.ayers.name/index> a pc:SpecialCase ;
    pc:state "pinned" ;
    fs:sourceFile "home/2023-10-27_hello.md" ;
    fs:targetFile "public/home/2023-10-27_hello.html" .
#     pc:template "layouts/mediocre/mediocre-posts_template.html" .

================
File: src/applications/file-copy-remove-test/services.ttl
================
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix trm: <http://purl.org/stuff/transmission/> .
# @prefix fs: <http://purl.org/stuff/filesystem/> .
@prefix t: <http://hyperdata.it/transmissions/> . # for custom terms & instances



t:copySingle1 a trm:FileCopy ;
        trm:key t:copySingle1 ;
        trm:source "data/start/one.txt" ;
        trm:destination "data/single-empty/one.txt" .

================
File: src/applications/file-copy-remove-test/transmission.ttl
================
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix trm: <http://purl.org/stuff/transmission/> .
@prefix : <http://hyperdata.it/transmissions/> . # for custom terms & instances

#############################################################
# insert into pipe for debugging
:DE a :DeadEnd . # ends the current pipe quietly
:H  a :Halt . # kills everything 
:SM a :ShowMessage . # verbose report, continues pipe
:N  a :NOP . # no operation (except for showing stage in pipe)
:UF a :Unfork . # collapses all pipes but one 
#############################################################

# copy `start/one.txt` into `single-empty/`
# copy `single-empty/one.txt` into `single-full/`
# remove `single-empty/one.txt`

# copy everything in `start/` into `several-empty/`
# copy everything in `several-empty/` into `several-full/`
# remove everything in `several-empty/`

:file_remove_test a trm:Pipeline ;
    trm:pipe (:SM :s1 :SM) .

# :s1 a :ContextReader . # read the manifest

:s1 a :RemapContext ;
    trm:configKey :copySingle1 .

================
File: src/applications/file-pipeline/data/input.txt
================
Hello

================
File: src/applications/file-pipeline/data/output.txt
================
Hello world world

================
File: src/applications/file-pipeline/services.ttl
================
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix trm: <http://purl.org/stuff/transmission/> .
# @prefix fs: <http://purl.org/stuff/filesystem/> .
@prefix t: <http://hyperdata.it/transmissions/> . # for custom terms & instances

t:FilePipelineMap a trm:DataMap ;
    trm:sourceFile "input.txt" ;
    trm:destinationFile "output.txt" .

================
File: src/applications/file-pipeline/transmission.ttl
================
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix trm: <http://purl.org/stuff/transmission/> .
@prefix : <http://hyperdata.it/transmissions/> . # for custom terms & instances

:file_pipeline a trm:Pipeline ;
    trm:pipe (:s1 :s2 :s3 :s4) .

:s1 a :FileSource .
:s2 a :AppendProcess .
:s3 a :AppendProcess .
:s4 a :FileSink .

================
File: src/applications/link-lister/about.md
================
run.js had

const here = import.meta.url
const message = { runScript: here }

transmission.execute('', message)

================
File: src/applications/link-lister/data/links.html
================
<p><a href="https://en.wikipedia.org/wiki/Main_Page">Main page</a>
<a href="https://en.wikipedia.org/wiki/Wikipedia:Contents">Contents</a>
<a href="https://en.wikipedia.org/wiki/Portal:Current_events">Current events</a>
<a href="https://en.wikipedia.org/wiki/Special:Random">Random article</a>
<a href="https://en.wikipedia.org/wiki/Wikipedia:About">About Wikipedia</a>
<a href="https://en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact us</a>
<a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en">Donate</a>
<a href="https://en.wikipedia.org/wiki/Help:Contents">Help</a>
<a href="https://en.wikipedia.org/wiki/Help:Introduction">Learn to edit</a>
<a href="https://en.wikipedia.org/wiki/Wikipedia:Community_portal">Community portal</a>
<a href="https://en.wikipedia.org/wiki/Special:RecentChanges">Recent changes</a>
<a href="https://en.wikipedia.org/wiki/Wikipedia:File_upload_wizard">Upload file</a>
[</p>
<p>](<a href="https://en.wikipedia.org/wiki/Main_Page">https://en.wikipedia.org/wiki/Main_Page</a>)
[</p>
<p>Search
    ](<a href="https://en.wikipedia.org/wiki/Special:Search">https://en.wikipedia.org/wiki/Special:Search</a>)
<a href="https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=FOAF">Create account</a>
<a href="https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=FOAF">Log in</a>
<a href="https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=FOAF"> Create account</a>
<a href="https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=FOAF"> Log in</a>
<a href="https://en.wikipedia.org/wiki/Help:Introduction">learn more</a>
<a href="https://en.wikipedia.org/wiki/Special:MyContributions">Contributions</a>
<a href="https://en.wikipedia.org/wiki/Special:MyTalk">Talk</a></p>
<h2>Contents</h2>
<h1>FOAF</h1>
<p><a href="https://ca.wikipedia.org/wiki/FOAF">Català</a>
<a href="https://de.wikipedia.org/wiki/FOAF">Deutsch</a>
<a href="https://es.wikipedia.org/wiki/FOAF">Español</a>
<a href="https://fa.wikipedia.org/wiki/%D8%A7%D9%81%E2%80%8C%D8%A7%D9%88%D8%A7%DB%8C%E2%80%8C%D8%A7%D9%81_(%D9%87%D8%B3%D8%AA%DB%8C%E2%80%8C%D8%B4%D9%86%D8%A7%D8%B3%DB%8C)">فارسی</a>
<a href="https://fr.wikipedia.org/wiki/FOAF">Français</a>
<a href="https://it.wikipedia.org/wiki/FOAF">Italiano</a>
<a href="https://lv.wikipedia.org/wiki/FOAF">Latviešu</a>
<a href="https://nl.wikipedia.org/wiki/FOAF">Nederlands</a>
<a href="https://ja.wikipedia.org/wiki/Friend_of_a_Friend">日本語</a>
<a href="https://no.wikipedia.org/wiki/FOAF">Norsk bokmål</a>
<a href="https://pl.wikipedia.org/wiki/FOAF_(format)">Polski</a>
<a href="https://pt.wikipedia.org/wiki/FOAF">Português</a>
<a href="https://ru.wikipedia.org/wiki/FOAF">Русский</a>
<a href="https://uk.wikipedia.org/wiki/FOAF">Українська</a>
<a href="https://www.wikidata.org/wiki/Special:EntityPage/Q1389366#sitelinks-wikipedia">Edit links</a>
<a href="https://en.wikipedia.org/wiki/FOAF">Article</a>
<a href="https://en.wikipedia.org/wiki/Talk:FOAF">Talk</a>
<a href="https://en.wikipedia.org/wiki/FOAF">Read</a>
<a href="https://en.wikipedia.org/w/index.php?title=FOAF&action=edit">Edit</a>
<a href="https://en.wikipedia.org/w/index.php?title=FOAF&action=history">View history</a>
<a href="https://en.wikipedia.org/wiki/FOAF">Read</a>
<a href="https://en.wikipedia.org/w/index.php?title=FOAF&action=edit">Edit</a>
<a href="https://en.wikipedia.org/w/index.php?title=FOAF&action=history">View history</a>
<a href="https://en.wikipedia.org/wiki/Special:WhatLinksHere/FOAF">What links here</a>
<a href="https://en.wikipedia.org/wiki/Special:RecentChangesLinked/FOAF">Related changes</a>
<a href="https://en.wikipedia.org/wiki/Wikipedia:File_Upload_Wizard">Upload file</a>
<a href="https://en.wikipedia.org/wiki/Special:SpecialPages">Special pages</a>
<a href="https://en.wikipedia.org/w/index.php?title=FOAF&oldid=1165941964">Permanent link</a>
<a href="https://en.wikipedia.org/w/index.php?title=FOAF&action=info">Page information</a>
<a href="https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&page=FOAF&id=1165941964&wpFormIdentifier=titleform">Cite this page</a>
<a href="https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FFOAF">Get shortened URL</a>
<a href="https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FFOAF">Download QR code</a>
<a href="https://www.wikidata.org/wiki/Special:EntityPage/Q1389366">Wikidata item</a>
<a href="https://en.wikipedia.org/w/index.php?title=Special:DownloadAsPdf&page=FOAF&action=show-download-screen">Download as PDF</a>
<a href="https://en.wikipedia.org/w/index.php?title=FOAF&printable=yes">Printable version</a>
<a href="https://commons.wikimedia.org/wiki/Category:FOAF">Wikimedia Commons</a>
<a href="https://en.wikipedia.org/wiki/Friend_of_a_friend">friend of a friend</a>
<a href="https://en.wikipedia.org/wiki/Friend_of_a_Friend_(disambiguation)">Friend of a Friend (disambiguation)</a>
<a href="https://en.wikipedia.org/wiki/File:FoafLogo.svg"></a>
<a href="https://en.wikipedia.org/wiki/Resource_Description_Framework">RDF</a>
<a href="https://en.wikipedia.org/wiki/Web_Ontology_Language">OWL</a>
<a href="https://en.wikipedia.org/wiki/Semantic_Web">Semantic Web</a>
<a href="https://en.wikipedia.org/wiki/Creative_Commons_license">CC BY 1.0</a>
<a href="http://xmlns.com/foaf/spec/">xmlns.com/foaf/spec/</a>
<a href="https://en.wikipedia.org/wiki/Friend_of_a_friend">friend of a friend</a>
<a href="https://en.wikipedia.org/wiki/Machine-readable_data">machine-readable</a>
<a href="https://en.wikipedia.org/wiki/Ontology_(information_science)">ontology</a>
<a href="https://en.wikipedia.org/wiki/Person">persons</a>
<a href="https://en.wikipedia.org/wiki/Social_networks">social networks</a>
<a href="https://en.wikipedia.org/wiki/Resource_Description_Framework">Resource Description Framework</a>
<a href="https://en.wikipedia.org/wiki/Web_Ontology_Language">Web Ontology Language</a>
<a href="https://en.wikipedia.org/wiki/E-mail_address">e-mail addresses</a>
<a href="https://en.wikipedia.org/wiki/Telephone_number">telephone number</a>
<a href="https://en.wikipedia.org/wiki/Facebook">Facebook</a>
<a href="https://en.wikipedia.org/wiki/Extensible_Messaging_and_Presence_Protocol">Jabber ID</a>
<a href="https://en.wikipedia.org/wiki/Uniform_Resource_Identifier">URI</a>
<a href="https://en.wikipedia.org/wiki/Social_Semantic_Web">Social Semantic Web</a>
<a href="https://en.wikipedia.org/wiki/Wikipedia:Citation_needed">citation needed</a>
<a href="https://en.wikipedia.org/wiki/Resource_Description_Framework">RDF</a>
<a href="https://en.wikipedia.org/wiki/Social_web">social web</a>
<a href="https://en.wikipedia.org/wiki/Wikipedia:Please_clarify">clarification needed</a>
<a href="https://en.wikipedia.org/wiki/Tim_Berners-Lee">Tim Berners-Lee</a>
<a href="https://en.wikipedia.org/wiki/Semantic_web">semantic web</a>
<a href="https://en.wikipedia.org/wiki/Giant_Global_Graph">Giant Global Graph</a>
<a href="https://en.wikipedia.org/wiki/Internet">Internet</a>
<a href="https://en.wikipedia.org/wiki/World_Wide_Web">World Wide Web</a></p>
<h2>WebID[edit]</h2>
<p><a href="https://en.wikipedia.org/w/index.php?title=FOAF&action=edit&section=1">edit</a>
<a href="https://en.wikipedia.org/wiki/WebID">WebID</a></p>
<h2>Deployment[edit]</h2>
<p><a href="https://en.wikipedia.org/w/index.php?title=FOAF&action=edit&section=2">edit</a>
<a href="https://en.wikipedia.org/wiki/Live_Journal">Live Journal</a>
<a href="https://en.wikipedia.org/wiki/DeadJournal">DeadJournal</a>
<a href="https://en.wikipedia.org/wiki/My_Opera">My Opera</a>
<a href="https://en.wikipedia.org/wiki/Identi.ca">Identi.ca</a>
<a href="https://en.wikipedia.org/wiki/FriendFeed">FriendFeed</a>
<a href="https://en.wikipedia.org/wiki/WordPress">WordPress</a>
<a href="https://en.wikipedia.org/wiki/TypePad">TypePad</a>
<a href="https://en.wikipedia.org/wiki/Yandex">Yandex</a>
<a href="https://en.wikipedia.org/wiki/Safari_(web_browser)">Safari</a>
<a href="https://en.wikipedia.org/wiki/Firefox_(web_browser)">Firefox</a>
<a href="https://en.wikipedia.org/wiki/Semantic_MediaWiki">Semantic MediaWiki</a>
<a href="https://en.wikipedia.org/wiki/Semantic_annotation">semantic annotation</a>
<a href="https://en.wikipedia.org/wiki/Linked_data">linked data</a>
<a href="https://en.wikipedia.org/wiki/MediaWiki">MediaWiki</a>
<a href="https://en.wikipedia.org/wiki/Content_management_systems">content management systems</a></p>
<h2>Example[edit]</h2>
<p><a href="https://en.wikipedia.org/w/index.php?title=FOAF&action=edit&section=3">edit</a>
<a href="https://en.wikipedia.org/wiki/Turtle_(syntax)">Turtle</a>
<a href="https://en.wikipedia.org/wiki/Web_resource">web resources</a></p>
<h2>History[edit]</h2>
<p><a href="https://en.wikipedia.org/w/index.php?title=FOAF&action=edit&section=4">edit</a></p>
<h3>Versions[edit]</h3>
<p><a href="https://en.wikipedia.org/w/index.php?title=FOAF&action=edit&section=5">edit</a>
<a href="http://xmlns.com/foaf/0.1/">http://xmlns.com/foaf/0.1/</a>
<a href="http://xmlns.com/foaf/0.1/">http://xmlns.com/foaf/0.1/</a></p>
<h2>See also[edit]</h2>
<p><a href="https://en.wikipedia.org/w/index.php?title=FOAF&action=edit&section=6">edit</a>
<a href="https://en.wikipedia.org/wiki/Resource_Description_Framework">Resource Description Framework</a>
<a href="https://en.wikipedia.org/wiki/Web_Ontology_Language">Web Ontology Language</a>
<a href="https://en.wikipedia.org/wiki/Social_web">Social web</a>
<a href="https://en.wikipedia.org/wiki/Semantic_Web">Semantic Web</a>
<a href="https://en.wiktionary.org/wiki/DOAC">Description of a Career</a>
<a href="https://en.wikipedia.org/wiki/DOAP">Description of a Project</a>
<a href="https://en.wikipedia.org/wiki/Semantically-Interlinked_Online_Communities">Semantically-Interlinked Online Communities</a>
<a href="https://en.wikipedia.org/wiki/HCard">hCard</a>
<a href="https://en.wikipedia.org/wiki/VCard">vCard</a>
<a href="https://en.wikipedia.org/wiki/XHTML_Friends_Network">XHTML Friends Network</a></p>
<h2>References[edit]</h2>
<p><a href="https://en.wikipedia.org/w/index.php?title=FOAF&action=edit&section=7">edit</a>
<a href="https://web.archive.org/web/20091223003446/http://www.ibm.com/developerworks/xml/library/x-foaf.html">XML Watch: Finding friends with XML and RDF</a>
<a href="https://en.wikipedia.org/wiki/IBM_DeveloperWorks">IBM DeveloperWorks</a>
<a href="https://web.archive.org/web/20100307223814/http://www.ibm.com/developerworks/xml/library/x-foaf2.html">XML Watch: Support online communities with FOAF</a>
<a href="https://en.wikipedia.org/wiki/IBM_DeveloperWorks">IBM DeveloperWorks</a>
<a href="https://web.archive.org/web/20160713021037/http://dig.csail.mit.edu/breadcrumbs/node/215">&quot;Giant Global Graph&quot;</a>
<a href="http://dig.csail.mit.edu/breadcrumbs/node/215">the original</a>
<a href="https://web.archive.org/web/20100118151037/http://community.livejournal.com/ljfoaf">&quot;LiveJournal FOAF&quot;</a>
<a href="http://community.livejournal.com/ljfoaf">the original</a>
<a href="https://web.archive.org/web/20100226072731/http://wiki.foaf-project.org/w/DataSources">&quot;Known FOAF data providers&quot;</a>
<a href="http://wiki.foaf-project.org/w/DataSources">the original</a>
<a href="http://company.yandex.com/press_center/press_releases/2008/2008-08-15.xml">&quot;press release on the social networking support&quot;</a>
<a href="http://ejohn.org/blog/foaf-support-in-safari-rss/">&quot;FOAF Support in Safari RSS&quot;</a>
<a href="https://web.archive.org/web/20140108014347/https://addons.mozilla.org/en-US/firefox/addon/semantic-radar/">&quot;Semantic Radar plugin for the Firefox browser&quot;</a>
<a href="https://addons.mozilla.org/en-US/firefox/addon/semantic-radar/">the original</a>
<a href="https://metacpan.org/pod/XML::FOAF">&quot;FOAF support module for Perl&quot;</a>
<a href="https://metacpan.org/pod/Web::ID">&quot;FOAF+SSL authentication support for Perl&quot;</a>
<a href="https://drupal.org/project/foaf">http://drupal.org/project/foaf</a>
<a href="https://en.wikipedia.org/wiki/Drupal">Drupal</a>
<a href="http://xmlns.com/foaf/spec/20140114.html">&quot;FOAF Vocabulary Specification 0.99&quot;</a>
<a href="https://web.archive.org/web/20220303180551/http://xmlns.com/foaf/spec/20140114.html">Archived</a></p>
<h2>External links[edit]</h2>
<p><a href="https://en.wikipedia.org/w/index.php?title=FOAF&action=edit&section=8">edit</a>
<a href="http://www.foaf-project.org">Official website</a>
<a href="https://web.archive.org/web/20211023122305/http://www.foaf-project.org/">Archived</a>
<a href="https://en.wikipedia.org/wiki/Wayback_Machine">Wayback Machine</a>
<a href="http://ebiquity.umbc.edu/resource/html/id/82/">FOAF dataset</a>
<a href="https://web.archive.org/web/20181130195340/https://www.foaf-search.net/">FOAF-search - a search engine for FOAF data</a>
<a href="https://en.wikipedia.org/wiki/Wayback_Machine">Wayback Machine</a>
<a href="https://en.wikipedia.org/wiki/Template:Semantic_Web">v</a>
<a href="https://en.wikipedia.org/wiki/Template_talk:Semantic_Web">t</a>
<a href="https://en.wikipedia.org/wiki/Special:EditPage/Template:Semantic_Web">e</a>
<a href="https://en.wikipedia.org/wiki/Semantic_Web">Semantic Web</a>
<a href="https://en.wikipedia.org/wiki/Database">Databases</a>
<a href="https://en.wikipedia.org/wiki/Hypertext">Hypertext</a>
<a href="https://en.wikipedia.org/wiki/Internet">Internet</a>
<a href="https://en.wikipedia.org/wiki/Ontology_(computer_science)">Ontologies</a>
<a href="https://en.wikipedia.org/wiki/Semantics_(computer_science)">Semantics</a>
<a href="https://en.wikipedia.org/wiki/Semantic_network">Semantic networks</a>
<a href="https://en.wikipedia.org/wiki/World_Wide_Web">World Wide Web</a>
<a href="https://en.wikipedia.org/wiki/Dataspaces">Dataspaces</a>
<a href="https://en.wikipedia.org/wiki/Hyperdata">Hyperdata</a>
<a href="https://en.wikipedia.org/wiki/Linked_data">Linked data</a>
<a href="https://en.wikipedia.org/wiki/Rule-based_system">Rule-based systems</a>
<a href="https://en.wikipedia.org/wiki/Semantic_analytics">Semantic analytics</a>
<a href="https://en.wikipedia.org/wiki/Semantic_broker">Semantic broker</a>
<a href="https://en.wikipedia.org/wiki/Semantic_computing">Semantic computing</a>
<a href="https://en.wikipedia.org/wiki/Semantic_mapper">Semantic mapper</a>
<a href="https://en.wikipedia.org/wiki/Semantic_matching">Semantic matching</a>
<a href="https://en.wikipedia.org/wiki/Semantic_publishing">Semantic publishing</a>
<a href="https://en.wikipedia.org/wiki/Semantic_reasoner">Semantic reasoner</a>
<a href="https://en.wikipedia.org/wiki/Semantic_search">Semantic search</a>
<a href="https://en.wikipedia.org/wiki/Semantic_service-oriented_architecture">Semantic service-oriented architecture</a>
<a href="https://en.wikipedia.org/wiki/Semantic_wiki">Semantic wiki</a>
<a href="https://en.wikipedia.org/wiki/Solid_(web_decentralization_project)">Solid</a>
<a href="https://en.wikipedia.org/wiki/Collective_intelligence">Collective intelligence</a>
<a href="https://en.wikipedia.org/wiki/Description_logic">Description logic</a>
<a href="https://en.wikipedia.org/wiki/Folksonomy">Folksonomy</a>
<a href="https://en.wikipedia.org/wiki/Geotagging">Geotagging</a>
<a href="https://en.wikipedia.org/wiki/Information_architecture">Information architecture</a>
<a href="https://en.wikipedia.org/wiki/Knowledge_extraction">Knowledge extraction</a>
<a href="https://en.wikipedia.org/wiki/Knowledge_management">Knowledge management</a>
<a href="https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning">Knowledge representation and reasoning</a>
<a href="https://en.wikipedia.org/wiki/Library_2.0">Library 2.0</a>
<a href="https://en.wikipedia.org/wiki/Digital_library">Digital library</a>
<a href="https://en.wikipedia.org/wiki/Digital_humanities">Digital humanities</a>
<a href="https://en.wikipedia.org/wiki/Metadata">Metadata</a>
<a href="https://en.wikipedia.org/wiki/Reference_(computer_science)">References</a>
<a href="https://en.wikipedia.org/wiki/Topic_map">Topic map</a>
<a href="https://en.wikipedia.org/wiki/Web_2.0">Web 2.0</a>
<a href="https://en.wikipedia.org/wiki/Web_engineering">Web engineering</a>
<a href="https://en.wikipedia.org/wiki/Web_Science_Trust">Web Science Trust</a>
<a href="https://en.wikipedia.org/wiki/HTTP">HTTP</a>
<a href="https://en.wikipedia.org/wiki/Internationalized_Resource_Identifier">IRI</a>
<a href="https://en.wikipedia.org/wiki/Uniform_Resource_Identifier">URI</a>
<a href="https://en.wikipedia.org/wiki/Resource_Description_Framework">RDF</a>
<a href="https://en.wikipedia.org/wiki/Semantic_triple">triples</a>
<a href="https://en.wikipedia.org/wiki/RDF/XML">RDF/XML</a>
<a href="https://en.wikipedia.org/wiki/JSON-LD">JSON-LD</a>
<a href="https://en.wikipedia.org/wiki/Turtle_(syntax)">Turtle</a>
<a href="https://en.wikipedia.org/wiki/TriG_(syntax)">TriG</a>
<a href="https://en.wikipedia.org/wiki/Notation3">Notation3</a>
<a href="https://en.wikipedia.org/wiki/N-Triples">N-Triples</a>
<a href="https://en.wikipedia.org/wiki/TriX_(serialization_format)">TriX</a>
<a href="https://en.wikipedia.org/wiki/Research_Resource_Identifier">RRID</a>
<a href="https://en.wikipedia.org/wiki/SPARQL">SPARQL</a>
<a href="https://en.wikipedia.org/wiki/XML">XML</a>
<a href="https://en.wikipedia.org/wiki/Semantic_HTML">Semantic HTML</a>
<a href="https://en.wikipedia.org/wiki/Common_Logic">Common Logic</a>
<a href="https://en.wikipedia.org/wiki/Web_Ontology_Language">OWL</a>
<a href="https://en.wikipedia.org/wiki/RDF_Schema">RDFS</a>
<a href="https://en.wikipedia.org/wiki/Rule_Interchange_Format">Rule Interchange Format</a>
<a href="https://en.wikipedia.org/wiki/Semantic_Web_Rule_Language">Semantic Web Rule Language</a>
<a href="https://en.wikipedia.org/w/index.php?title=Application-Level_Profile_Semantics_(ALPS)&action=edit&redlink=1">ALPS</a>
<a href="https://en.wikipedia.org/wiki/SHACL">SHACL</a>
<a href="https://en.wikipedia.org/wiki/Embedded_RDF">eRDF</a>
<a href="https://en.wikipedia.org/wiki/GRDDL">GRDDL</a>
<a href="https://en.wikipedia.org/wiki/Microdata_(HTML)">Microdata</a>
<a href="https://en.wikipedia.org/wiki/Microformat">Microformats</a>
<a href="https://en.wikipedia.org/wiki/RDFa">RDFa</a>
<a href="https://en.wikipedia.org/wiki/SAWSDL">SAWSDL</a>
<a href="https://en.wikipedia.org/wiki/Facebook_Platform">Facebook Platform</a>
<a href="https://en.wikipedia.org/wiki/DOAP">DOAP</a>
<a href="https://en.wikipedia.org/wiki/Dublin_Core">Dublin Core</a>
<a href="https://en.wikipedia.org/wiki/Schema.org">Schema.org</a>
<a href="https://en.wikipedia.org/wiki/Semantically_Interlinked_Online_Communities">SIOC</a>
<a href="https://en.wikipedia.org/wiki/Simple_Knowledge_Organization_System">SKOS</a>
<a href="https://en.wikipedia.org/wiki/HAtom">hAtom</a>
<a href="https://en.wikipedia.org/wiki/HCalendar">hCalendar</a>
<a href="https://en.wikipedia.org/wiki/HCard">hCard</a>
<a href="https://en.wikipedia.org/wiki/HProduct">hProduct</a>
<a href="https://en.wikipedia.org/wiki/HRecipe">hRecipe</a>
<a href="https://en.wikipedia.org/wiki/HReview">hReview</a>
<a href="https://en.wikipedia.org/wiki/Template:Social_networking">v</a>
<a href="https://en.wikipedia.org/wiki/Template_talk:Social_networking">t</a>
<a href="https://en.wikipedia.org/wiki/Special:EditPage/Template:Social_networking">e</a>
<a href="https://en.wikipedia.org/wiki/Social_network">Social networks</a>
<a href="https://en.wikipedia.org/wiki/Social_media">social media</a>
<a href="https://en.wikipedia.org/wiki/Personal_network">Personal</a>
<a href="https://en.wikipedia.org/wiki/Professional_network_service">Professional</a>
<a href="https://en.wikipedia.org/wiki/Sexual_network">Sexual</a>
<a href="https://en.wikipedia.org/wiki/Value_network">Value</a>
<a href="https://en.wikipedia.org/wiki/Clique">Clique</a>
<a href="https://en.wikipedia.org/wiki/Adolescent_clique">Adolescent</a>
<a href="https://en.wikipedia.org/wiki/Corporate_social_media">Corporate social media</a>
<a href="https://en.wikipedia.org/wiki/Distributed_social_network">Distributed social network</a>
<a href="https://en.wikipedia.org/wiki/Comparison_of_software_and_protocols_for_distributed_social_networking">list</a>
<a href="https://en.wikipedia.org/wiki/Enterprise_social_networking">Enterprise social networking</a>
<a href="https://en.wikipedia.org/wiki/Enterprise_social_software">Enterprise social software</a>
<a href="https://en.wikipedia.org/wiki/Mobile_social_network">Mobile social network</a>
<a href="https://en.wikipedia.org/wiki/Personal_knowledge_networking">Personal knowledge networking</a>
<a href="https://en.wikipedia.org/wiki/Social_networking_service">Services</a>
<a href="https://en.wikipedia.org/wiki/List_of_social_networking_services">List of social networking services</a>
<a href="https://en.wikipedia.org/wiki/List_of_virtual_communities_with_more_than_1_million_users">List of virtual communities with more than 1 million users</a>
<a href="https://en.wikipedia.org/wiki/Ambient_awareness">Ambient awareness</a>
<a href="https://en.wikipedia.org/wiki/Assortative_mixing">Assortative mixing</a>
<a href="https://en.wikipedia.org/wiki/Attention_inequality">Attention inequality</a>
<a href="https://en.wikipedia.org/wiki/Bridge_(interpersonal)">Interpersonal bridge</a>
<a href="https://en.wikipedia.org/wiki/Organizational_network_analysis">Organizational network analysis</a>
<a href="https://en.wikipedia.org/wiki/Small-world_experiment">Small-world experiment</a>
<a href="https://en.wikipedia.org/wiki/Social_aspects_of_television">Social aspects of television</a>
<a href="https://en.wikipedia.org/wiki/Social_capital">Social capital</a>
<a href="https://en.wikipedia.org/wiki/Social_data_revolution">Social data revolution</a>
<a href="https://en.wikipedia.org/wiki/Social_exchange_theory">Social exchange theory</a>
<a href="https://en.wikipedia.org/wiki/Social_identity_theory">Social identity theory</a>
<a href="https://en.wikipedia.org/wiki/Social_media_and_psychology">Social media and psychology</a>
<a href="https://en.wikipedia.org/wiki/Social_media_intelligence">Social media intelligence</a>
<a href="https://en.wikipedia.org/wiki/Social_media_mining">Social media mining</a>
<a href="https://en.wikipedia.org/wiki/Social_media_optimization">Social media optimization</a>
<a href="https://en.wikipedia.org/wiki/Social_network_analysis">Social network analysis</a>
<a href="https://en.wikipedia.org/wiki/Social_web">Social web</a>
<a href="https://en.wikipedia.org/wiki/Structural_endogamy">Structural endogamy</a>
<a href="https://en.wikipedia.org/wiki/Virtual_collective_consciousness">Virtual collective consciousness</a>
<a href="https://en.wikipedia.org/wiki/Account_verification">Account verification</a>
<a href="https://en.wikipedia.org/wiki/Social_network_aggregation">Aggregation</a>
<a href="https://en.wikipedia.org/wiki/Social_network_change_detection">Change detection</a>
<a href="https://en.wikipedia.org/wiki/Blockmodeling">Blockmodeling</a>
<a href="https://en.wikipedia.org/wiki/Collaboration_graph">Collaboration graph</a>
<a href="https://en.wikipedia.org/wiki/Collaborative_consumption">Collaborative consumption</a>
<a href="https://en.wikipedia.org/wiki/Giant_Global_Graph">Giant Global Graph</a>
<a href="https://en.wikipedia.org/wiki/Lateral_communication">Lateral communication</a>
<a href="https://en.wikipedia.org/wiki/Reputation_system">Reputation system</a>
<a href="https://en.wikipedia.org/wiki/Social_bot">Social bot</a>
<a href="https://en.wikipedia.org/wiki/Social_graph">Social graph</a>
<a href="https://en.wikipedia.org/wiki/Social_media_analytics">Social media analytics</a>
<a href="https://en.wikipedia.org/wiki/Social_network_analysis_software">Social network analysis software</a>
<a href="https://en.wikipedia.org/wiki/Social_networking_potential">Social networking potential</a>
<a href="https://en.wikipedia.org/wiki/Social_television">Social television</a>
<a href="https://en.wikipedia.org/wiki/Structural_cohesion">Structural cohesion</a>
<a href="https://en.wikipedia.org/wiki/Affinity_fraud">Affinity fraud</a>
<a href="https://en.wikipedia.org/wiki/Attention_economy">Attention economy</a>
<a href="https://en.wikipedia.org/wiki/Collaborative_finance">Collaborative finance</a>
<a href="https://en.wikipedia.org/wiki/Creator_economy">Creator economy</a>
<a href="https://en.wikipedia.org/wiki/Influencer_marketing">Influencer marketing</a>
<a href="https://en.wikipedia.org/wiki/Narrowcasting">Narrowcasting</a>
<a href="https://en.wikipedia.org/wiki/Sharing_economy">Sharing economy</a>
<a href="https://en.wikipedia.org/wiki/Social_commerce">Social commerce</a>
<a href="https://en.wikipedia.org/wiki/Social_sorting">Social sorting</a>
<a href="https://en.wikipedia.org/wiki/Viral_marketing">Viral marketing</a>
<a href="https://en.wikipedia.org/wiki/Algorithmic_radicalization">Algorithmic radicalization</a>
<a href="https://en.wikipedia.org/wiki/Community_recognition">Community recognition</a>
<a href="https://en.wikipedia.org/wiki/Complex_contagion">Complex contagion</a>
<a href="https://en.wikipedia.org/wiki/Computer_addiction">Computer addiction</a>
<a href="https://en.wikipedia.org/wiki/Consequential_strangers">Consequential strangers</a>
<a href="https://en.wikipedia.org/wiki/Friend_of_a_friend">Friend of a friend</a>
<a href="https://en.wikipedia.org/wiki/Friending_and_following">Friending and following</a>
<a href="https://en.wikipedia.org/wiki/Friendship_paradox">Friendship paradox</a>
<a href="https://en.wikipedia.org/wiki/Influence-for-hire">Influence-for-hire</a>
<a href="https://en.wikipedia.org/wiki/Internet_addiction">Internet addiction</a>
<a href="https://en.wikipedia.org/wiki/Information_overload">Information overload</a>
<a href="https://en.wikipedia.org/wiki/Overchoice">Overchoice</a>
<a href="https://en.wikipedia.org/wiki/Six_degrees_of_separation">Six degrees of separation</a>
<a href="https://en.wikipedia.org/wiki/Social_media_addiction">Social media addiction</a>
<a href="https://en.wikipedia.org/wiki/Social_media_and_suicide">Social media and suicide</a>
<a href="https://en.wikipedia.org/wiki/Social_invisibility">Social invisibility</a>
<a href="https://en.wikipedia.org/wiki/Social_network_game">Social network game</a>
<a href="https://en.wikipedia.org/wiki/Suicide_and_the_Internet">Suicide and the Internet</a>
<a href="https://en.wikipedia.org/wiki/Tribe_(internet)">Tribe</a>
<a href="https://en.wikipedia.org/wiki/Viral_phenomenon">Viral phenomenon</a>
<a href="https://en.wikipedia.org/wiki/Friendship_recession">Friendship recession</a>
<a href="https://en.wikipedia.org/wiki/Peer_pressure">Peer pressure</a>
<a href="https://en.wikipedia.org/wiki/List_of_social_network_researchers">Researchers</a>
<a href="https://en.wikipedia.org/wiki/User_profile">User profile</a>
<a href="https://en.wikipedia.org/wiki/Online_identity">Online identity</a>
<a href="https://en.wikipedia.org/wiki/Persona_(user_experience)">Persona</a>
<a href="https://en.wikipedia.org/wiki/Social_profiling">Social profiling</a>
<a href="https://en.wikipedia.org/wiki/Viral_messages">Viral messages</a>
<a href="https://en.wikipedia.org/wiki/Virtual_community">Virtual community</a>
<a href="https://en.wikipedia.org/w/index.php?title=FOAF&oldid=1165941964">https://en.wikipedia.org/w/index.php?title=FOAF&amp;oldid=1165941964</a>
<a href="https://en.wikipedia.org/wiki/Help:Category">Categories</a>
<a href="https://en.wikipedia.org/wiki/Category:Ontology_(information_science)">Ontology (information science)</a>
<a href="https://en.wikipedia.org/wiki/Category:Semantic_Web">Semantic Web</a>
<a href="https://en.wikipedia.org/wiki/Category:2000_software">2000 software</a>
<a href="https://en.wikipedia.org/wiki/Category:Articles_with_short_description">Articles with short description</a>
<a href="https://en.wikipedia.org/wiki/Category:Short_description_matches_Wikidata">Short description matches Wikidata</a>
<a href="https://en.wikipedia.org/wiki/Category:All_articles_with_unsourced_statements">All articles with unsourced statements</a>
<a href="https://en.wikipedia.org/wiki/Category:Articles_with_unsourced_statements_from_April_2017">Articles with unsourced statements from April 2017</a>
<a href="https://en.wikipedia.org/wiki/Category:Wikipedia_articles_needing_clarification_from_April_2017">Wikipedia articles needing clarification from April 2017</a>
<a href="https://en.wikipedia.org/wiki/Category:Webarchive_template_wayback_links">Webarchive template wayback links</a>
<a href="https://en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License">Creative Commons Attribution-ShareAlike License 4.0</a>
<a href="https://en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License"></a>
<a href="https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Terms_of_Use">Terms of Use</a>
<a href="https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy">Privacy Policy</a>
<a href="https://www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>
<a href="https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy">Privacy policy</a>
<a href="https://en.wikipedia.org/wiki/Wikipedia:About">About Wikipedia</a>
<a href="https://en.wikipedia.org/wiki/Wikipedia:General_disclaimer">Disclaimers</a>
<a href="https://en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a>
<a href="https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Universal_Code_of_Conduct">Code of Conduct</a>
<a href="https://developer.wikimedia.org">Developers</a>
<a href="https://stats.wikimedia.org/#/en.wikipedia.org">Statistics</a>
<a href="https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Cookie_statement">Cookie statement</a>
<a href="https://en.m.wikipedia.org/w/index.php?title=FOAF&mobileaction=toggle_view_mobile">Mobile view</a>
<a href="https://wikimediafoundation.org/"></a>
<a href="https://www.mediawiki.org/"></a></p>
<h1>FOAF Vocabulary Specification 0.99</h1>
<h2>Namespace Document 14 January 2014 - Paddington Edition</h2>
<p><a href="http://xmlns.com/foaf/spec/20140114.html">http://xmlns.com/foaf/spec/20140114.html</a>
<a href="http://xmlns.com/foaf/spec/20140114.rdf">rdf</a>
<a href="http://xmlns.com/foaf/spec/">http://xmlns.com/foaf/spec/</a>
<a href="http://xmlns.com/foaf/spec/index.rdf">rdf</a>
<a href="http://xmlns.com/foaf/spec/20100809.html">http://xmlns.com/foaf/spec/20100809.html</a>
<a href="http://xmlns.com/foaf/spec/20100809.rdf">rdf</a>
<a href="mailto:danbri@danbri.org">Dan Brickley</a>
<a href="mailto:libby@nicecupoftea.org">Libby Miller</a>
<a href="http://lists.foaf-project.org/">foaf-dev@lists.foaf-project.org</a>
<a href="http://www.w3.org/2001/sw/interest/">RDF
    and Semantic Web developer community</a>
<a href="http://creativecommons.org/licenses/by/1.0/"></a>
<a href="http://creativecommons.org/licenses/by/1.0/">Creative Commons Attribution License</a>
<a href="http://www.w3.org/RDF/">RDF</a></p>
<h2>Abstract</h2>
<h2>Status of This Document</h2>
<p><a href="http://www.foaf-project.org/">FOAF project</a>
<a href="http://xmlns.com/foaf/spec/index.rdf">RDFS/OWL</a>
<a href="http://xmlns.com/foaf/doc/">per-term</a>
<a href="http://svn.foaf-project.org/foaftown/foaf18n/">multilingual translations</a>
<a href="http://xmlns.com/foaf/spec/index.rdf">direct link</a>
<a href="http://en.wikipedia.org/wiki/Content_negotiation">content negotiation</a>
<a href="http://xmlns.com/foaf/0.1/">namespace URI</a>
<a href="mailto:foaf-dev@lists.foaf-project.org">foaf-dev@lists.foaf-project.org</a>
<a href="http://lists.foaf-project.org">public archives</a>
<a href="mailto:foaf-dev@lists.foaf-project.org">FOAF mailing list</a>
<a href="http://www.foaf-project.org/">FOAF website</a></p>
<h3>Changes in version 0.99</h3>
<h2>Table of Contents</h2>
<h2>FOAF at a glance</h2>
<p><a href="http://www.dublincore.org/">Dublin Core</a>
<a href="http://www.w3.org/2004/02/skos/">SKOS</a>
<a href="http://trac.usefulinc.com/doap">DOAP</a>
<a href="http://sioc-project.org/">SIOC</a>
<a href="http://www.epimorphics.com/public/vocabulary/org.html">Org vocabulary</a>
<a href="http://vocab.org/bio/0.1/.html">Bio vocabulary</a>
<a href="http://portablecontacts.net/">Portable Contacts</a>
<a href="http://www.w3.org/2005/Incubator/socialweb/">W3C Social Web group</a></p>
<h3>FOAF Core</h3>
<h3>Social Web</h3>
<h3>A-Z of FOAF terms (current and archaic)</h3>
<h2>Example</h2>
<h2>1 Introduction: FOAF Basics</h2>
<h3>The Semantic Web</h3>
<p><a href="http://www.w3.org/Talks/WWW94Tim/">W3 future directions</a>
<a href="http://dig.csail.mit.edu/breadcrumbs/node/215">Giant Global Graph</a>
<a href="http://www.w3.org/People/Berners-Lee/card">foaf</a></p>
<h3>FOAF and the Semantic Web</h3>
<p><a href="http://www.w3.org/2001/sw/">Semantic Web</a>
<a href="http://www.w3.org/TR/rdf-sparql-query/">SPARQL</a>
<a href="http://www.w3.org/2004/02/skos/">SKOS</a>
<a href="http://www.w3.org/2001/sw/grddl-wg/">GRDDL</a>
<a href="http://www.w3.org/TR/xhtml-rdfa-primer/">RDFa</a>
<a href="http://www.w3.org/DesignIssues/LinkedData.html">Linked
  Data</a></p>
<h3>The Basic Idea</h3>
<p><a href="http://xmlns.com/foaf/0.1/">FOAF namespace
  document</a></p>
<h2>What&#39;s FOAF for?</h2>
<p><a href="http://www-106.ibm.com/developerworks/xml/library/x-foaf.html">XML
  Watch: Finding friends with XML and RDF</a>
<a href="http://rdfweb.org/2002/01/photo/">with image metadata</a>
<a href="http://rdfweb.org/2002/01/photo/">co-depiction</a>
<a href="http://www.ldodds.com/foaf/foaf-a-matic.html">FOAF-a-matic</a>
<a href="http://www.foaf-project.org">FOAF project home page</a></p>
<h2>Background</h2>
<p><a href="http://www.urbanlegends.com/">alt.folklore.urban archive</a>
<a href="http://www.snopes.com/">snopes.com</a></p>
<h2>FOAF and Standards</h2>
<p><a href="http://www.iso.ch/iso/en/ISOOnline.openerpage">ISO
  Standardisation</a>
<a href="http://www.w3.org/">W3C</a>
<a href="http://www.w3.org/Consortium/Process/">Process</a>
<a href="http://www.opensource.org/">Open Source</a>
<a href="http://www.gnu.org/philosophy/free-sw.html">Free Software</a>
<a href="http://www.jabber.org/jeps/jep-0001.html">Jabber
  JEPs</a>
<a href="http://www.w3.org/RDF/">Resource Description Framework</a></p>
<h2>The FOAF Vocabulary Description</h2>
<p><a href="http://www.w3.org/RDF/">RDF</a>
<a href="http://www.w3.org/2001/sw/">Semantic Web</a>
<a href="http://www.w3.org/2001/sw/">Semantic Web</a></p>
<h3>Evolution and Extension of FOAF</h3>
<p><a href="http://dublincore.org/">Dublin Core</a></p>
<h2>FOAF Auto-Discovery: Publishing and Linking FOAF files</h2>
<p><a href="http://www.ldodds.com/foaf/foaf-a-matic.html">foaf-a-matic</a>
<a href="http://web.archive.org/web/20040416181630/rdfweb.org/mt/foaflog/archives/000041.html">FOAF
  autodiscovery</a></p>
<h2>FOAF cross-reference: Listing FOAF Classes and</h2>
<p>  Properties</p>
<p><a href="http://xmlns.com/foaf/spec/index.rdf">RDF/XML</a></p>
<h3>Classes and Properties (full detail)</h3>
<h2>Classes</h2>
<h3>Class: foaf:Agent</h3>
<h3>Class: foaf:Document</h3>
<h3>Class: foaf:Group</h3>
<p><a href="http://wiki.foaf-project.org/w/IssueTracker">issue tracker</a>
<a href="http://www.w3.org/2001/sw/WebOnt">OWL</a></p>
<h3>Class: foaf:Image</h3>
<h3>Class: foaf:Organization</h3>
<h3>Class: foaf:Person</h3>
<h3>Class: foaf:OnlineAccount</h3>
<h3>Class: foaf:PersonalProfileDocument</h3>
<p><a href="http://www.w3.org/2004/01/rdxh/spec">GRDDL</a></p>
<h3>Class: foaf:Project</h3>
<h3>Class: foaf:LabelProperty</h3>
<h3>Class: foaf:OnlineChatAccount</h3>
<p><a href="http://www.jabber.org/">Jabber</a>
<a href="http://www.aim.com/">AIM</a>
<a href="http://chat.msn.com/">MSN</a>
<a href="http://web.icq.com/icqchat/">ICQ</a>
<a href="http://chat.yahoo.com/">Yahoo!</a>
<a href="http://chat.msn.com/">MSN</a>
<a href="http://www.freenode.net/">Freenode</a></p>
<h3>Class: foaf:OnlineEcommerceAccount</h3>
<p><a href="http://www.amazon.com/">Amazon</a>
<a href="http://www.ebay.com/">eBay</a>
<a href="http://www.paypal.com/">PayPal</a>
<a href="http://www.thinkgeek.com/">thinkgeek</a></p>
<h3>Class: foaf:OnlineGamingAccount</h3>
<p><a href="http://everquest.station.sony.com/">EverQuest</a>
<a href="http://www.xbox.com/live/">Xbox live</a>
<a href="http://nwn.bioware.com/">Neverwinter Nights</a></p>
<h2>Properties</h2>
<h3>Property: foaf:homepage</h3>
<h3>Property: foaf:isPrimaryTopicOf</h3>
<h3>Property: foaf:knows</h3>
<p><a href="http://www.perceive.net/schemas/20021119/relationship/">Relationship module</a>
<a href="http://wiki.foaf-project.org/w/ScutterSpec">scutters</a></p>
<h3>Property: foaf:made</h3>
<h3>Property: foaf:maker</h3>
<p><a href="http://wiki.foaf-project.org/w/UsingDublinCoreCreator">UsingDublinCoreCreator</a></p>
<h3>Property: foaf:mbox</h3>
<p><a href="http://ftp.ics.uci.edu/pub/ietf/uri/rfc2368.txt">RFC 2368</a></p>
<h3>Property: foaf:member</h3>
<h3>Property: foaf:page</h3>
<h3>Property: foaf:primaryTopic</h3>
<p><a href="http://www.wikipedia.org/">Wikipedia</a>
<a href="http://www.nndb.com/">NNDB</a></p>
<h3>Property: foaf:weblog</h3>
<h3>Property: foaf:account</h3>
<h3>Property: foaf:accountName</h3>
<h3>Property: foaf:accountServiceHomepage</h3>
<h3>Property: foaf:aimChatID</h3>
<p><a href="http://www.aim.com/">AIM</a>
<a href="http://www.apple.com/macosx/what-is-macosx/ichat.html">iChat</a>
<a href="http://www.apple.com/">Apple</a></p>
<h3>Property: foaf:based_near</h3>
<p><a href="http://www.w3.org/2003/01/geo/wgs84_pos#">geo-positioning vocabulary</a>
<a href="http://esw.w3.org/topic/GeoInfo">GeoInfo</a>
<a href="http://esw.w3.org/topic/GeoOnion">GeoOnion vocab</a>
<a href="http://wiki.foaf-project.org/w/UsingContactNearestAirport">UsingContactNearestAirport</a></p>
<h3>Property: foaf:currentProject</h3>
<h3>Property: foaf:depiction</h3>
<p><a href="http://rdfweb.org/2002/01/photo/">Co-Depiction</a>
<a href="http://www.jibbering.com/svg/AnnotateImage.html">&#39;Annotating Images With SVG&#39;</a></p>
<h3>Property: foaf:depicts</h3>
<h3>Property: foaf:familyName</h3>
<p><a href="http://wiki.foaf-project.org/w/NameVocabIssue">issue tracker</a></p>
<h3>Property: foaf:firstName</h3>
<p><a href="http://wiki.foaf-project.org/w/NameVocabIssue">issue tracker</a></p>
<h3>Property: foaf:focus</h3>
<p><a href="http://www.w3.org/2004/02/skos/">SKOS</a>
<a href="http://www.w3.org/TR/2005/WD-swbp-skos-core-guide-20050510/#secmodellingrdf">In SKOS</a>
<a href="http://www.w3.org/TR/2005/WD-swbp-skos-core-guide-20051102/#secopen">2005 discussion</a>
<a href="http://larry.masinter.net/duri.html">TDB URI scheme</a>
<a href="http://www.foaf-project.org/original-intro">original goals</a></p>
<h3>Property: foaf:gender</h3>
<p><a href="http://lists.foaf-project.org/mailman/listinfo/foaf-dev">foaf-dev</a></p>
<h3>Property: foaf:givenName</h3>
<p><a href="http://wiki.foaf-project.org/w/NameVocabIssue">issue tracker</a></p>
<h3>Property: foaf:icqChatID</h3>
<p><a href="http://web.icq.com/icqchat/">icq chat</a>
<a href="http://www.icq.com/products/whatisicq.html">What is ICQ?</a>
<a href="http://company.icq.com/info/">About Us</a></p>
<h3>Property: foaf:img</h3>
<h3>Property: foaf:interest</h3>
<p><a href="http://www.w3.org/RDF/">RDF</a>
<a href="http://www.cpan.org/">CPAN</a></p>
<h3>Property: foaf:jabberID</h3>
<p><a href="http://www.jabber.org/">Jabber</a>
<a href="http://www.jabber.org/">Jabber</a></p>
<h3>Property: foaf:lastName</h3>
<p><a href="http://wiki.foaf-project.org/w/NameVocabIssue">issue tracker</a></p>
<h3>Property: foaf:logo</h3>
<h3>Property: foaf:mbox_sha1sum</h3>
<p><a href="http://usefulinc.com/foaf/">Edd Dumbill&#39;s
documentation</a>
<a href="http://www.w3.org/2001/12/rubyrdf/util/foafwhite/intro.html">FOAF-based whitelists</a>
<a href="http://www.intertwingly.net/blog/1545.html">in Sam Ruby&#39;s
weblog entry</a></p>
<h3>Property: foaf:msnChatID</h3>
<p><a href="http://en.wikipedia.org/wiki/Windows_Live_Messenger">Windows Live Messenger</a>
<a href="http://download.live.com/messenger">Microsoft mesenger</a>
<a href="http://en.wikipedia.org/wiki/Windows_Live_ID">Windows Live ID</a></p>
<h3>Property: foaf:myersBriggs</h3>
<p><a href="http://www.teamtechnology.co.uk/tt/t-articl/mb-simpl.htm">this article</a>
<a href="http://webspace.webring.com/people/cl/lifexplore/mbintro.htm">Cory Caplinger&#39;s summary table</a>
<a href="http://web.archive.org/web/20080802184922/http://rdfweb.org/mt/foaflog/archives/000004.html">FOAF Myers Briggs addition</a></p>
<h3>Property: foaf:name</h3>
<p><a href="http://wiki.foaf-project.org/w/IssueTracker">issue tracker</a></p>
<h3>Property: foaf:nick</h3>
<h3>Property: foaf:openid</h3>
<p><a href="http://www.w3.org/TR/webarch/#indirect-identification">indirect identifier</a>
<a href="http://openid.net/specs/openid-authentication-1_1.html">OpenID</a>
<a href="http://openid.net/specs/openid-authentication-1_1.html#delegating_authentication">delegation model</a>
<a href="http://xmlns.com/foaf/spec/#sec-autodesc">technique</a></p>
<h3>Property: foaf:pastProject</h3>
<h3>Property: foaf:phone</h3>
<h3>Property: foaf:plan</h3>
<p><a href="http://www.rajivshah.com/Case_Studies/Finger/Finger.htm">History of the
Finger Protocol</a></p>
<h3>Property: foaf:publications</h3>
<h3>Property: foaf:schoolHomepage</h3>
<h3>Property: foaf:skypeID</h3>
<h3>Property: foaf:thumbnail</h3>
<h3>Property: foaf:tipjar</h3>
<p><a href="http://rdfweb.org/mt/foaflog/archives/2004/02/12/20.07.32/">discussions</a>
<a href="http://www.paypal.com/">PayPal</a></p>
<h3>Property: foaf:title</h3>
<p><a href="http://wiki.foaf-project.org/w/IssueTracker">FOAF Issue Tracker</a></p>
<h3>Property: foaf:topic</h3>
<h3>Property: foaf:topic_interest</h3>
<h3>Property: foaf:workInfoHomepage</h3>
<h3>Property: foaf:workplaceHomepage</h3>
<h3>Property: foaf:yahooChatID</h3>
<p><a href="http://chat.yahoo.com/">Yahoo! Chat</a>
<a href="http://www.yahoogroups.com/">Yahoo! Groups</a></p>
<h3>Property: foaf:age</h3>
<h3>Property: foaf:birthday</h3>
<p><a href="http://wiki.foaf-project.org/w/BirthdayIssue">BirthdayIssue</a></p>
<h3>Property: foaf:membershipClass</h3>
<h3>Property: foaf:sha1</h3>
<h3>Property: foaf:status</h3>
<h3>Property: foaf:dnaChecksum</h3>
<h3>Property: foaf:family_name</h3>
<h3>Property: foaf:fundedBy</h3>
<h3>Property: foaf:geekcode</h3>
<p><a href="http://en.wikipedia.org/wiki/Geek_Code">Wikipedia entry</a></p>
<h3>Property: foaf:givenname</h3>
<p><a href="http://wiki.foaf-project.org/w/NameVocabIssue">issue tracker</a></p>
<h3>Property: foaf:holdsAccount</h3>
<h3>Property: foaf:surname</h3>
<p><a href="http://wiki.foaf-project.org/w/IssueTracker">issue
tracker</a></p>
<h3>Property: foaf:theme</h3>
<h2>External Vocabulary References</h2>
<h3>Status Vocabulary</h3>
<p><a href="http://www.w3.org/2003/06/sw-vocab-status/note">SemWeb Vocab Status Ontology</a></p>
<h3>W3C Basic Geo (WGS84 lat/long) Vocabulary</h3>
<p><a href="http://www.w3.org/2003/01/geo/">W3CBasic Geo Vocabulary</a></p>
<h3>RDF Vocabulary Description - core concepts</h3>
<p><a href="http://www.w3.org/2001/sw/">W3C&#39;s site</a>
<a href="http://www.w3.org/TR/webarch/#identification">more background on URIs</a>
<a href="http://www.w3.org/DesignIssues/LinkedData">linked data</a>
<a href="http://www.w3.org/2004/02/skos/">SKOS</a></p>
<h3>Dublin Core terms</h3>
<p><a href="http://dublincore.org/documents/dcmi-terms/">Dublin Core terms</a>
<a href="http://dublincore.org/documents/dcmi-terms/#classes-Agent">dct:Agent</a>
<a href="http://dublincore.org/documents/dcmi-terms/#terms-creator">dct:creator</a></p>
<h3>Wordnet terms</h3>
<p><a href="http://www.w3.org/TR/wordnet-rdf/">recent</a></p>
<h3>SIOC terms</h3>
<p><a href="http://rdfs.org/sioc/ns#">SIOC</a>
<a href="http://www.sioc-project.org/">SIOC</a></p>
<h3>Acknowledgments</h3>
<p><a href="http://rdfweb.org/pipermail/rdfweb-dev/">rdfweb-dev</a>
<a href="http://rdfweb.org/irc/">#foaf</a>
<a href="http://xml.mfd-consult.dk/foaf/explorer/">FoafExplorer</a>
<a href="http://eikeon.com/foaf/">Web View</a>
<a href="http://www.ldodds.com/foaf/foaf-a-matic.html">foaf-a-matic</a>
<a href="http://www.ecademy.com/">Ecademy</a>
<a href="http://www.typepad.com/">TypePad</a>
<a href="http://conferences.oreillynet.com/cs/et2003/view/e_sess/3633">many</a>
<a href="http://hackdiary.com/">explaining</a>
<a href="http://kanzaki.com/docs/sw/foaf.html">in Japanese</a>
<a href="http://f14web.com.ar/inkel/2003/01/27/foaf.html">Spanish</a>
<a href="http://crschmidt.net/">Chris Schmidt</a>
<a href="http://xmlns.com/foaf/0.1/specgen.py">spec generation</a>
<a href="http://crschmidt.net/semweb/">cool hacks</a>
<a href="http://iandavis.com/2006/foaf-icons/">FOAF Logo</a>
<a href="http://www.w3.org/History/1989/proposal.html">years ago</a></p>
<h2>Recent Changes</h2>
<h3>Changes in version 0.99 (2014-01-14)</h3>
<p><a href="http://schema.org/">schema.org</a>
<a href="http://schema.org/Person">Person</a>
<a href="http://schema.org/ImageObject">ImageObject</a>
<a href="http://schema.org/CreativeWork">CreativeWork</a></p>
<h3>2010-08-09</h3>
<p><a href="http://vocab.org/bio/0.1/.html">Bio vocabulary</a></p>
<h3>Changes from version 0.97 and 0.96</h3>
<p><a href="http://xmlns.com/foaf/spec/20100101.html">0.97</a>
<a href="http://xmlns.com/foaf/spec/20091215.html">0.96</a>
<a href="http://portablecontacts.net/">Portable Contacts</a></p>
<h3>2009-12-15</h3>
<h3>2007-11-02</h3>
<h3>2007-05-24</h3>

================
File: src/applications/link-lister/data/links.md
================
[Main page](https://en.wikipedia.org/wiki/Main_Page)
[Contents](https://en.wikipedia.org/wiki/Wikipedia:Contents)
[Current events](https://en.wikipedia.org/wiki/Portal:Current_events)
[Random article](https://en.wikipedia.org/wiki/Special:Random)
[About Wikipedia](https://en.wikipedia.org/wiki/Wikipedia:About)
[Contact us](https://en.wikipedia.org/wiki/Wikipedia:Contact_us)
[Donate](https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en)
[Help](https://en.wikipedia.org/wiki/Help:Contents)
[Learn to edit](https://en.wikipedia.org/wiki/Help:Introduction)
[Community portal](https://en.wikipedia.org/wiki/Wikipedia:Community_portal)
[Recent changes](https://en.wikipedia.org/wiki/Special:RecentChanges)
[Upload file](https://en.wikipedia.org/wiki/Wikipedia:File_upload_wizard)
[
	
	
		
		
	
](https://en.wikipedia.org/wiki/Main_Page)
[

Search
	](https://en.wikipedia.org/wiki/Special:Search)
[Create account](https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=FOAF)
[Log in](https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=FOAF)
[ Create account](https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=FOAF)
[ Log in](https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=FOAF)
[learn more](https://en.wikipedia.org/wiki/Help:Introduction)
[Contributions](https://en.wikipedia.org/wiki/Special:MyContributions)
[Talk](https://en.wikipedia.org/wiki/Special:MyTalk)

## Contents


# FOAF

[Català](https://ca.wikipedia.org/wiki/FOAF)
[Deutsch](https://de.wikipedia.org/wiki/FOAF)
[Español](https://es.wikipedia.org/wiki/FOAF)
[فارسی](https://fa.wikipedia.org/wiki/%D8%A7%D9%81%E2%80%8C%D8%A7%D9%88%D8%A7%DB%8C%E2%80%8C%D8%A7%D9%81_(%D9%87%D8%B3%D8%AA%DB%8C%E2%80%8C%D8%B4%D9%86%D8%A7%D8%B3%DB%8C))
[Français](https://fr.wikipedia.org/wiki/FOAF)
[Italiano](https://it.wikipedia.org/wiki/FOAF)
[Latviešu](https://lv.wikipedia.org/wiki/FOAF)
[Nederlands](https://nl.wikipedia.org/wiki/FOAF)
[日本語](https://ja.wikipedia.org/wiki/Friend_of_a_Friend)
[Norsk bokmål](https://no.wikipedia.org/wiki/FOAF)
[Polski](https://pl.wikipedia.org/wiki/FOAF_(format))
[Português](https://pt.wikipedia.org/wiki/FOAF)
[Русский](https://ru.wikipedia.org/wiki/FOAF)
[Українська](https://uk.wikipedia.org/wiki/FOAF)
[Edit links](https://www.wikidata.org/wiki/Special:EntityPage/Q1389366#sitelinks-wikipedia)
[Article](https://en.wikipedia.org/wiki/FOAF)
[Talk](https://en.wikipedia.org/wiki/Talk:FOAF)
[Read](https://en.wikipedia.org/wiki/FOAF)
[Edit](https://en.wikipedia.org/w/index.php?title=FOAF&action=edit)
[View history](https://en.wikipedia.org/w/index.php?title=FOAF&action=history)
[Read](https://en.wikipedia.org/wiki/FOAF)
[Edit](https://en.wikipedia.org/w/index.php?title=FOAF&action=edit)
[View history](https://en.wikipedia.org/w/index.php?title=FOAF&action=history)
[What links here](https://en.wikipedia.org/wiki/Special:WhatLinksHere/FOAF)
[Related changes](https://en.wikipedia.org/wiki/Special:RecentChangesLinked/FOAF)
[Upload file](https://en.wikipedia.org/wiki/Wikipedia:File_Upload_Wizard)
[Special pages](https://en.wikipedia.org/wiki/Special:SpecialPages)
[Permanent link](https://en.wikipedia.org/w/index.php?title=FOAF&oldid=1165941964)
[Page information](https://en.wikipedia.org/w/index.php?title=FOAF&action=info)
[Cite this page](https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&page=FOAF&id=1165941964&wpFormIdentifier=titleform)
[Get shortened URL](https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FFOAF)
[Download QR code](https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FFOAF)
[Wikidata item](https://www.wikidata.org/wiki/Special:EntityPage/Q1389366)
[Download as PDF](https://en.wikipedia.org/w/index.php?title=Special:DownloadAsPdf&page=FOAF&action=show-download-screen)
[Printable version](https://en.wikipedia.org/w/index.php?title=FOAF&printable=yes)
[Wikimedia Commons](https://commons.wikimedia.org/wiki/Category:FOAF)
[friend of a friend](https://en.wikipedia.org/wiki/Friend_of_a_friend)
[Friend of a Friend (disambiguation)](https://en.wikipedia.org/wiki/Friend_of_a_Friend_(disambiguation))
[](https://en.wikipedia.org/wiki/File:FoafLogo.svg)
[RDF](https://en.wikipedia.org/wiki/Resource_Description_Framework)
[OWL](https://en.wikipedia.org/wiki/Web_Ontology_Language)
[Semantic Web](https://en.wikipedia.org/wiki/Semantic_Web)
[CC BY 1.0](https://en.wikipedia.org/wiki/Creative_Commons_license)
[xmlns.com/foaf/spec/](http://xmlns.com/foaf/spec/)
[friend of a friend](https://en.wikipedia.org/wiki/Friend_of_a_friend)
[machine-readable](https://en.wikipedia.org/wiki/Machine-readable_data)
[ontology](https://en.wikipedia.org/wiki/Ontology_(information_science))
[persons](https://en.wikipedia.org/wiki/Person)
[social networks](https://en.wikipedia.org/wiki/Social_networks)
[Resource Description Framework](https://en.wikipedia.org/wiki/Resource_Description_Framework)
[Web Ontology Language](https://en.wikipedia.org/wiki/Web_Ontology_Language)
[e-mail addresses](https://en.wikipedia.org/wiki/E-mail_address)
[telephone number](https://en.wikipedia.org/wiki/Telephone_number)
[Facebook](https://en.wikipedia.org/wiki/Facebook)
[Jabber ID](https://en.wikipedia.org/wiki/Extensible_Messaging_and_Presence_Protocol)
[URI](https://en.wikipedia.org/wiki/Uniform_Resource_Identifier)
[Social Semantic Web](https://en.wikipedia.org/wiki/Social_Semantic_Web)
[citation needed](https://en.wikipedia.org/wiki/Wikipedia:Citation_needed)
[RDF](https://en.wikipedia.org/wiki/Resource_Description_Framework)
[social web](https://en.wikipedia.org/wiki/Social_web)
[clarification needed](https://en.wikipedia.org/wiki/Wikipedia:Please_clarify)
[Tim Berners-Lee](https://en.wikipedia.org/wiki/Tim_Berners-Lee)
[semantic web](https://en.wikipedia.org/wiki/Semantic_web)
[Giant Global Graph](https://en.wikipedia.org/wiki/Giant_Global_Graph)
[Internet](https://en.wikipedia.org/wiki/Internet)
[World Wide Web](https://en.wikipedia.org/wiki/World_Wide_Web)

## WebID[edit]

[edit](https://en.wikipedia.org/w/index.php?title=FOAF&action=edit&section=1)
[WebID](https://en.wikipedia.org/wiki/WebID)

## Deployment[edit]

[edit](https://en.wikipedia.org/w/index.php?title=FOAF&action=edit&section=2)
[Live Journal](https://en.wikipedia.org/wiki/Live_Journal)
[DeadJournal](https://en.wikipedia.org/wiki/DeadJournal)
[My Opera](https://en.wikipedia.org/wiki/My_Opera)
[Identi.ca](https://en.wikipedia.org/wiki/Identi.ca)
[FriendFeed](https://en.wikipedia.org/wiki/FriendFeed)
[WordPress](https://en.wikipedia.org/wiki/WordPress)
[TypePad](https://en.wikipedia.org/wiki/TypePad)
[Yandex](https://en.wikipedia.org/wiki/Yandex)
[Safari](https://en.wikipedia.org/wiki/Safari_(web_browser))
[Firefox](https://en.wikipedia.org/wiki/Firefox_(web_browser))
[Semantic MediaWiki](https://en.wikipedia.org/wiki/Semantic_MediaWiki)
[semantic annotation](https://en.wikipedia.org/wiki/Semantic_annotation)
[linked data](https://en.wikipedia.org/wiki/Linked_data)
[MediaWiki](https://en.wikipedia.org/wiki/MediaWiki)
[content management systems](https://en.wikipedia.org/wiki/Content_management_systems)

## Example[edit]

[edit](https://en.wikipedia.org/w/index.php?title=FOAF&action=edit&section=3)
[Turtle](https://en.wikipedia.org/wiki/Turtle_(syntax))
[web resources](https://en.wikipedia.org/wiki/Web_resource)

## History[edit]

[edit](https://en.wikipedia.org/w/index.php?title=FOAF&action=edit&section=4)

### Versions[edit]

[edit](https://en.wikipedia.org/w/index.php?title=FOAF&action=edit&section=5)
[http://xmlns.com/foaf/0.1/](http://xmlns.com/foaf/0.1/)
[http://xmlns.com/foaf/0.1/](http://xmlns.com/foaf/0.1/)

## See also[edit]

[edit](https://en.wikipedia.org/w/index.php?title=FOAF&action=edit&section=6)
[Resource Description Framework](https://en.wikipedia.org/wiki/Resource_Description_Framework)
[Web Ontology Language](https://en.wikipedia.org/wiki/Web_Ontology_Language)
[Social web](https://en.wikipedia.org/wiki/Social_web)
[Semantic Web](https://en.wikipedia.org/wiki/Semantic_Web)
[Description of a Career](https://en.wiktionary.org/wiki/DOAC)
[Description of a Project](https://en.wikipedia.org/wiki/DOAP)
[Semantically-Interlinked Online Communities](https://en.wikipedia.org/wiki/Semantically-Interlinked_Online_Communities)
[hCard](https://en.wikipedia.org/wiki/HCard)
[vCard](https://en.wikipedia.org/wiki/VCard)
[XHTML Friends Network](https://en.wikipedia.org/wiki/XHTML_Friends_Network)

## References[edit]

[edit](https://en.wikipedia.org/w/index.php?title=FOAF&action=edit&section=7)
[XML Watch: Finding friends with XML and RDF](https://web.archive.org/web/20091223003446/http://www.ibm.com/developerworks/xml/library/x-foaf.html)
[IBM DeveloperWorks](https://en.wikipedia.org/wiki/IBM_DeveloperWorks)
[XML Watch: Support online communities with FOAF](https://web.archive.org/web/20100307223814/http://www.ibm.com/developerworks/xml/library/x-foaf2.html)
[IBM DeveloperWorks](https://en.wikipedia.org/wiki/IBM_DeveloperWorks)
["Giant Global Graph"](https://web.archive.org/web/20160713021037/http://dig.csail.mit.edu/breadcrumbs/node/215)
[the original](http://dig.csail.mit.edu/breadcrumbs/node/215)
["LiveJournal FOAF"](https://web.archive.org/web/20100118151037/http://community.livejournal.com/ljfoaf)
[the original](http://community.livejournal.com/ljfoaf)
["Known FOAF data providers"](https://web.archive.org/web/20100226072731/http://wiki.foaf-project.org/w/DataSources)
[the original](http://wiki.foaf-project.org/w/DataSources)
["press release on the social networking support"](http://company.yandex.com/press_center/press_releases/2008/2008-08-15.xml)
["FOAF Support in Safari RSS"](http://ejohn.org/blog/foaf-support-in-safari-rss/)
["Semantic Radar plugin for the Firefox browser"](https://web.archive.org/web/20140108014347/https://addons.mozilla.org/en-US/firefox/addon/semantic-radar/)
[the original](https://addons.mozilla.org/en-US/firefox/addon/semantic-radar/)
["FOAF support module for Perl"](https://metacpan.org/pod/XML::FOAF)
["FOAF+SSL authentication support for Perl"](https://metacpan.org/pod/Web::ID)
[http://drupal.org/project/foaf](https://drupal.org/project/foaf)
[Drupal](https://en.wikipedia.org/wiki/Drupal)
["FOAF Vocabulary Specification 0.99"](http://xmlns.com/foaf/spec/20140114.html)
[Archived](https://web.archive.org/web/20220303180551/http://xmlns.com/foaf/spec/20140114.html)

## External links[edit]

[edit](https://en.wikipedia.org/w/index.php?title=FOAF&action=edit&section=8)
[Official website](http://www.foaf-project.org)
[Archived](https://web.archive.org/web/20211023122305/http://www.foaf-project.org/)
[Wayback Machine](https://en.wikipedia.org/wiki/Wayback_Machine)
[FOAF dataset](http://ebiquity.umbc.edu/resource/html/id/82/)
[FOAF-search - a search engine for FOAF data](https://web.archive.org/web/20181130195340/https://www.foaf-search.net/)
[Wayback Machine](https://en.wikipedia.org/wiki/Wayback_Machine)
[v](https://en.wikipedia.org/wiki/Template:Semantic_Web)
[t](https://en.wikipedia.org/wiki/Template_talk:Semantic_Web)
[e](https://en.wikipedia.org/wiki/Special:EditPage/Template:Semantic_Web)
[Semantic Web](https://en.wikipedia.org/wiki/Semantic_Web)
[Databases](https://en.wikipedia.org/wiki/Database)
[Hypertext](https://en.wikipedia.org/wiki/Hypertext)
[Internet](https://en.wikipedia.org/wiki/Internet)
[Ontologies](https://en.wikipedia.org/wiki/Ontology_(computer_science))
[Semantics](https://en.wikipedia.org/wiki/Semantics_(computer_science))
[Semantic networks](https://en.wikipedia.org/wiki/Semantic_network)
[World Wide Web](https://en.wikipedia.org/wiki/World_Wide_Web)
[Dataspaces](https://en.wikipedia.org/wiki/Dataspaces)
[Hyperdata](https://en.wikipedia.org/wiki/Hyperdata)
[Linked data](https://en.wikipedia.org/wiki/Linked_data)
[Rule-based systems](https://en.wikipedia.org/wiki/Rule-based_system)
[Semantic analytics](https://en.wikipedia.org/wiki/Semantic_analytics)
[Semantic broker](https://en.wikipedia.org/wiki/Semantic_broker)
[Semantic computing](https://en.wikipedia.org/wiki/Semantic_computing)
[Semantic mapper](https://en.wikipedia.org/wiki/Semantic_mapper)
[Semantic matching](https://en.wikipedia.org/wiki/Semantic_matching)
[Semantic publishing](https://en.wikipedia.org/wiki/Semantic_publishing)
[Semantic reasoner](https://en.wikipedia.org/wiki/Semantic_reasoner)
[Semantic search](https://en.wikipedia.org/wiki/Semantic_search)
[Semantic service-oriented architecture](https://en.wikipedia.org/wiki/Semantic_service-oriented_architecture)
[Semantic wiki](https://en.wikipedia.org/wiki/Semantic_wiki)
[Solid](https://en.wikipedia.org/wiki/Solid_(web_decentralization_project))
[Collective intelligence](https://en.wikipedia.org/wiki/Collective_intelligence)
[Description logic](https://en.wikipedia.org/wiki/Description_logic)
[Folksonomy](https://en.wikipedia.org/wiki/Folksonomy)
[Geotagging](https://en.wikipedia.org/wiki/Geotagging)
[Information architecture](https://en.wikipedia.org/wiki/Information_architecture)
[Knowledge extraction](https://en.wikipedia.org/wiki/Knowledge_extraction)
[Knowledge management](https://en.wikipedia.org/wiki/Knowledge_management)
[Knowledge representation and reasoning](https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning)
[Library 2.0](https://en.wikipedia.org/wiki/Library_2.0)
[Digital library](https://en.wikipedia.org/wiki/Digital_library)
[Digital humanities](https://en.wikipedia.org/wiki/Digital_humanities)
[Metadata](https://en.wikipedia.org/wiki/Metadata)
[References](https://en.wikipedia.org/wiki/Reference_(computer_science))
[Topic map](https://en.wikipedia.org/wiki/Topic_map)
[Web 2.0](https://en.wikipedia.org/wiki/Web_2.0)
[Web engineering](https://en.wikipedia.org/wiki/Web_engineering)
[Web Science Trust](https://en.wikipedia.org/wiki/Web_Science_Trust)
[HTTP](https://en.wikipedia.org/wiki/HTTP)
[IRI](https://en.wikipedia.org/wiki/Internationalized_Resource_Identifier)
[URI](https://en.wikipedia.org/wiki/Uniform_Resource_Identifier)
[RDF](https://en.wikipedia.org/wiki/Resource_Description_Framework)
[triples](https://en.wikipedia.org/wiki/Semantic_triple)
[RDF/XML](https://en.wikipedia.org/wiki/RDF/XML)
[JSON-LD](https://en.wikipedia.org/wiki/JSON-LD)
[Turtle](https://en.wikipedia.org/wiki/Turtle_(syntax))
[TriG](https://en.wikipedia.org/wiki/TriG_(syntax))
[Notation3](https://en.wikipedia.org/wiki/Notation3)
[N-Triples](https://en.wikipedia.org/wiki/N-Triples)
[TriX](https://en.wikipedia.org/wiki/TriX_(serialization_format))
[RRID](https://en.wikipedia.org/wiki/Research_Resource_Identifier)
[SPARQL](https://en.wikipedia.org/wiki/SPARQL)
[XML](https://en.wikipedia.org/wiki/XML)
[Semantic HTML](https://en.wikipedia.org/wiki/Semantic_HTML)
[Common Logic](https://en.wikipedia.org/wiki/Common_Logic)
[OWL](https://en.wikipedia.org/wiki/Web_Ontology_Language)
[RDFS](https://en.wikipedia.org/wiki/RDF_Schema)
[Rule Interchange Format](https://en.wikipedia.org/wiki/Rule_Interchange_Format)
[Semantic Web Rule Language](https://en.wikipedia.org/wiki/Semantic_Web_Rule_Language)
[ALPS](https://en.wikipedia.org/w/index.php?title=Application-Level_Profile_Semantics_(ALPS)&action=edit&redlink=1)
[SHACL](https://en.wikipedia.org/wiki/SHACL)
[eRDF](https://en.wikipedia.org/wiki/Embedded_RDF)
[GRDDL](https://en.wikipedia.org/wiki/GRDDL)
[Microdata](https://en.wikipedia.org/wiki/Microdata_(HTML))
[Microformats](https://en.wikipedia.org/wiki/Microformat)
[RDFa](https://en.wikipedia.org/wiki/RDFa)
[SAWSDL](https://en.wikipedia.org/wiki/SAWSDL)
[Facebook Platform](https://en.wikipedia.org/wiki/Facebook_Platform)
[DOAP](https://en.wikipedia.org/wiki/DOAP)
[Dublin Core](https://en.wikipedia.org/wiki/Dublin_Core)
[Schema.org](https://en.wikipedia.org/wiki/Schema.org)
[SIOC](https://en.wikipedia.org/wiki/Semantically_Interlinked_Online_Communities)
[SKOS](https://en.wikipedia.org/wiki/Simple_Knowledge_Organization_System)
[hAtom](https://en.wikipedia.org/wiki/HAtom)
[hCalendar](https://en.wikipedia.org/wiki/HCalendar)
[hCard](https://en.wikipedia.org/wiki/HCard)
[hProduct](https://en.wikipedia.org/wiki/HProduct)
[hRecipe](https://en.wikipedia.org/wiki/HRecipe)
[hReview](https://en.wikipedia.org/wiki/HReview)
[v](https://en.wikipedia.org/wiki/Template:Social_networking)
[t](https://en.wikipedia.org/wiki/Template_talk:Social_networking)
[e](https://en.wikipedia.org/wiki/Special:EditPage/Template:Social_networking)
[Social networks](https://en.wikipedia.org/wiki/Social_network)
[social media](https://en.wikipedia.org/wiki/Social_media)
[Personal](https://en.wikipedia.org/wiki/Personal_network)
[Professional](https://en.wikipedia.org/wiki/Professional_network_service)
[Sexual](https://en.wikipedia.org/wiki/Sexual_network)
[Value](https://en.wikipedia.org/wiki/Value_network)
[Clique](https://en.wikipedia.org/wiki/Clique)
[Adolescent](https://en.wikipedia.org/wiki/Adolescent_clique)
[Corporate social media](https://en.wikipedia.org/wiki/Corporate_social_media)
[Distributed social network](https://en.wikipedia.org/wiki/Distributed_social_network)
[list](https://en.wikipedia.org/wiki/Comparison_of_software_and_protocols_for_distributed_social_networking)
[Enterprise social networking](https://en.wikipedia.org/wiki/Enterprise_social_networking)
[Enterprise social software](https://en.wikipedia.org/wiki/Enterprise_social_software)
[Mobile social network](https://en.wikipedia.org/wiki/Mobile_social_network)
[Personal knowledge networking](https://en.wikipedia.org/wiki/Personal_knowledge_networking)
[Services](https://en.wikipedia.org/wiki/Social_networking_service)
[List of social networking services](https://en.wikipedia.org/wiki/List_of_social_networking_services)
[List of virtual communities with more than 1 million users](https://en.wikipedia.org/wiki/List_of_virtual_communities_with_more_than_1_million_users)
[Ambient awareness](https://en.wikipedia.org/wiki/Ambient_awareness)
[Assortative mixing](https://en.wikipedia.org/wiki/Assortative_mixing)
[Attention inequality](https://en.wikipedia.org/wiki/Attention_inequality)
[Interpersonal bridge](https://en.wikipedia.org/wiki/Bridge_(interpersonal))
[Organizational network analysis](https://en.wikipedia.org/wiki/Organizational_network_analysis)
[Small-world experiment](https://en.wikipedia.org/wiki/Small-world_experiment)
[Social aspects of television](https://en.wikipedia.org/wiki/Social_aspects_of_television)
[Social capital](https://en.wikipedia.org/wiki/Social_capital)
[Social data revolution](https://en.wikipedia.org/wiki/Social_data_revolution)
[Social exchange theory](https://en.wikipedia.org/wiki/Social_exchange_theory)
[Social identity theory](https://en.wikipedia.org/wiki/Social_identity_theory)
[Social media and psychology](https://en.wikipedia.org/wiki/Social_media_and_psychology)
[Social media intelligence](https://en.wikipedia.org/wiki/Social_media_intelligence)
[Social media mining](https://en.wikipedia.org/wiki/Social_media_mining)
[Social media optimization](https://en.wikipedia.org/wiki/Social_media_optimization)
[Social network analysis](https://en.wikipedia.org/wiki/Social_network_analysis)
[Social web](https://en.wikipedia.org/wiki/Social_web)
[Structural endogamy](https://en.wikipedia.org/wiki/Structural_endogamy)
[Virtual collective consciousness](https://en.wikipedia.org/wiki/Virtual_collective_consciousness)
[Account verification](https://en.wikipedia.org/wiki/Account_verification)
[Aggregation](https://en.wikipedia.org/wiki/Social_network_aggregation)
[Change detection](https://en.wikipedia.org/wiki/Social_network_change_detection)
[Blockmodeling](https://en.wikipedia.org/wiki/Blockmodeling)
[Collaboration graph](https://en.wikipedia.org/wiki/Collaboration_graph)
[Collaborative consumption](https://en.wikipedia.org/wiki/Collaborative_consumption)
[Giant Global Graph](https://en.wikipedia.org/wiki/Giant_Global_Graph)
[Lateral communication](https://en.wikipedia.org/wiki/Lateral_communication)
[Reputation system](https://en.wikipedia.org/wiki/Reputation_system)
[Social bot](https://en.wikipedia.org/wiki/Social_bot)
[Social graph](https://en.wikipedia.org/wiki/Social_graph)
[Social media analytics](https://en.wikipedia.org/wiki/Social_media_analytics)
[Social network analysis software](https://en.wikipedia.org/wiki/Social_network_analysis_software)
[Social networking potential](https://en.wikipedia.org/wiki/Social_networking_potential)
[Social television](https://en.wikipedia.org/wiki/Social_television)
[Structural cohesion](https://en.wikipedia.org/wiki/Structural_cohesion)
[Affinity fraud](https://en.wikipedia.org/wiki/Affinity_fraud)
[Attention economy](https://en.wikipedia.org/wiki/Attention_economy)
[Collaborative finance](https://en.wikipedia.org/wiki/Collaborative_finance)
[Creator economy](https://en.wikipedia.org/wiki/Creator_economy)
[Influencer marketing](https://en.wikipedia.org/wiki/Influencer_marketing)
[Narrowcasting](https://en.wikipedia.org/wiki/Narrowcasting)
[Sharing economy](https://en.wikipedia.org/wiki/Sharing_economy)
[Social commerce](https://en.wikipedia.org/wiki/Social_commerce)
[Social sorting](https://en.wikipedia.org/wiki/Social_sorting)
[Viral marketing](https://en.wikipedia.org/wiki/Viral_marketing)
[Algorithmic radicalization](https://en.wikipedia.org/wiki/Algorithmic_radicalization)
[Community recognition](https://en.wikipedia.org/wiki/Community_recognition)
[Complex contagion](https://en.wikipedia.org/wiki/Complex_contagion)
[Computer addiction](https://en.wikipedia.org/wiki/Computer_addiction)
[Consequential strangers](https://en.wikipedia.org/wiki/Consequential_strangers)
[Friend of a friend](https://en.wikipedia.org/wiki/Friend_of_a_friend)
[Friending and following](https://en.wikipedia.org/wiki/Friending_and_following)
[Friendship paradox](https://en.wikipedia.org/wiki/Friendship_paradox)
[Influence-for-hire](https://en.wikipedia.org/wiki/Influence-for-hire)
[Internet addiction](https://en.wikipedia.org/wiki/Internet_addiction)
[Information overload](https://en.wikipedia.org/wiki/Information_overload)
[Overchoice](https://en.wikipedia.org/wiki/Overchoice)
[Six degrees of separation](https://en.wikipedia.org/wiki/Six_degrees_of_separation)
[Social media addiction](https://en.wikipedia.org/wiki/Social_media_addiction)
[Social media and suicide](https://en.wikipedia.org/wiki/Social_media_and_suicide)
[Social invisibility](https://en.wikipedia.org/wiki/Social_invisibility)
[Social network game](https://en.wikipedia.org/wiki/Social_network_game)
[Suicide and the Internet](https://en.wikipedia.org/wiki/Suicide_and_the_Internet)
[Tribe](https://en.wikipedia.org/wiki/Tribe_(internet))
[Viral phenomenon](https://en.wikipedia.org/wiki/Viral_phenomenon)
[Friendship recession](https://en.wikipedia.org/wiki/Friendship_recession)
[Peer pressure](https://en.wikipedia.org/wiki/Peer_pressure)
[Researchers](https://en.wikipedia.org/wiki/List_of_social_network_researchers)
[User profile](https://en.wikipedia.org/wiki/User_profile)
[Online identity](https://en.wikipedia.org/wiki/Online_identity)
[Persona](https://en.wikipedia.org/wiki/Persona_(user_experience))
[Social profiling](https://en.wikipedia.org/wiki/Social_profiling)
[Viral messages](https://en.wikipedia.org/wiki/Viral_messages)
[Virtual community](https://en.wikipedia.org/wiki/Virtual_community)
[https://en.wikipedia.org/w/index.php?title=FOAF&oldid=1165941964](https://en.wikipedia.org/w/index.php?title=FOAF&oldid=1165941964)
[Categories](https://en.wikipedia.org/wiki/Help:Category)
[Ontology (information science)](https://en.wikipedia.org/wiki/Category:Ontology_(information_science))
[Semantic Web](https://en.wikipedia.org/wiki/Category:Semantic_Web)
[2000 software](https://en.wikipedia.org/wiki/Category:2000_software)
[Articles with short description](https://en.wikipedia.org/wiki/Category:Articles_with_short_description)
[Short description matches Wikidata](https://en.wikipedia.org/wiki/Category:Short_description_matches_Wikidata)
[All articles with unsourced statements](https://en.wikipedia.org/wiki/Category:All_articles_with_unsourced_statements)
[Articles with unsourced statements from April 2017](https://en.wikipedia.org/wiki/Category:Articles_with_unsourced_statements_from_April_2017)
[Wikipedia articles needing clarification from April 2017](https://en.wikipedia.org/wiki/Category:Wikipedia_articles_needing_clarification_from_April_2017)
[Webarchive template wayback links](https://en.wikipedia.org/wiki/Category:Webarchive_template_wayback_links)
[Creative Commons Attribution-ShareAlike License 4.0](https://en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License)
[](https://en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License)
[Terms of Use](https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Terms_of_Use)
[Privacy Policy](https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy)
[Wikimedia Foundation, Inc.](https://www.wikimediafoundation.org/)
[Privacy policy](https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy)
[About Wikipedia](https://en.wikipedia.org/wiki/Wikipedia:About)
[Disclaimers](https://en.wikipedia.org/wiki/Wikipedia:General_disclaimer)
[Contact Wikipedia](https://en.wikipedia.org/wiki/Wikipedia:Contact_us)
[Code of Conduct](https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Universal_Code_of_Conduct)
[Developers](https://developer.wikimedia.org)
[Statistics](https://stats.wikimedia.org/#/en.wikipedia.org)
[Cookie statement](https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Cookie_statement)
[Mobile view](https://en.m.wikipedia.org/w/index.php?title=FOAF&mobileaction=toggle_view_mobile)
[](https://wikimediafoundation.org/)
[](https://www.mediawiki.org/)

# FOAF Vocabulary Specification 0.99


## Namespace Document 14 January 2014 - Paddington Edition

[http://xmlns.com/foaf/spec/20140114.html](http://xmlns.com/foaf/spec/20140114.html)
[rdf](http://xmlns.com/foaf/spec/20140114.rdf)
[http://xmlns.com/foaf/spec/](http://xmlns.com/foaf/spec/)
[rdf](http://xmlns.com/foaf/spec/index.rdf)
[http://xmlns.com/foaf/spec/20100809.html](http://xmlns.com/foaf/spec/20100809.html)
[rdf](http://xmlns.com/foaf/spec/20100809.rdf)
[Dan Brickley](mailto:danbri@danbri.org)
[Libby Miller](mailto:libby@nicecupoftea.org)
[foaf-dev@lists.foaf-project.org](http://lists.foaf-project.org/)
[RDF
    and Semantic Web developer community](http://www.w3.org/2001/sw/interest/)
[](http://creativecommons.org/licenses/by/1.0/)
[Creative Commons Attribution License](http://creativecommons.org/licenses/by/1.0/)
[RDF](http://www.w3.org/RDF/)

## Abstract


## Status of This Document

[FOAF project](http://www.foaf-project.org/)
[RDFS/OWL](http://xmlns.com/foaf/spec/index.rdf)
[per-term](http://xmlns.com/foaf/doc/)
[multilingual translations](http://svn.foaf-project.org/foaftown/foaf18n/)
[direct link](http://xmlns.com/foaf/spec/index.rdf)
[content negotiation](http://en.wikipedia.org/wiki/Content_negotiation)
[namespace URI](http://xmlns.com/foaf/0.1/)
[foaf-dev@lists.foaf-project.org](mailto:foaf-dev@lists.foaf-project.org)
[public archives](http://lists.foaf-project.org)
[FOAF mailing list](mailto:foaf-dev@lists.foaf-project.org)
[FOAF website](http://www.foaf-project.org/)

### Changes in version 0.99


## Table of Contents


## FOAF at a glance

[Dublin Core](http://www.dublincore.org/)
[SKOS](http://www.w3.org/2004/02/skos/)
[DOAP](http://trac.usefulinc.com/doap)
[SIOC](http://sioc-project.org/)
[Org vocabulary](http://www.epimorphics.com/public/vocabulary/org.html)
[Bio vocabulary](http://vocab.org/bio/0.1/.html)
[Portable Contacts](http://portablecontacts.net/)
[W3C Social Web group](http://www.w3.org/2005/Incubator/socialweb/)

### FOAF Core


### Social Web


### A-Z of FOAF terms (current and archaic)


## Example


## 1 Introduction: FOAF Basics


### The Semantic Web

[W3 future directions](http://www.w3.org/Talks/WWW94Tim/)
[Giant Global Graph](http://dig.csail.mit.edu/breadcrumbs/node/215)
[foaf](http://www.w3.org/People/Berners-Lee/card)

### FOAF and the Semantic Web

[Semantic Web](http://www.w3.org/2001/sw/)
[SPARQL](http://www.w3.org/TR/rdf-sparql-query/)
[SKOS](http://www.w3.org/2004/02/skos/)
[GRDDL](http://www.w3.org/2001/sw/grddl-wg/)
[RDFa](http://www.w3.org/TR/xhtml-rdfa-primer/)
[Linked 
  Data](http://www.w3.org/DesignIssues/LinkedData.html)

### The Basic Idea

[FOAF namespace
  document](http://xmlns.com/foaf/0.1/)

## What's FOAF for?

[XML
  Watch: Finding friends with XML and RDF](http://www-106.ibm.com/developerworks/xml/library/x-foaf.html)
[with image metadata](http://rdfweb.org/2002/01/photo/)
[co-depiction](http://rdfweb.org/2002/01/photo/)
[FOAF-a-matic](http://www.ldodds.com/foaf/foaf-a-matic.html)
[FOAF project home page](http://www.foaf-project.org)

## Background

[alt.folklore.urban archive](http://www.urbanlegends.com/)
[snopes.com](http://www.snopes.com/)

## FOAF and Standards

[ISO
  Standardisation](http://www.iso.ch/iso/en/ISOOnline.openerpage)
[W3C](http://www.w3.org/)
[Process](http://www.w3.org/Consortium/Process/)
[Open Source](http://www.opensource.org/)
[Free Software](http://www.gnu.org/philosophy/free-sw.html)
[Jabber
  JEPs](http://www.jabber.org/jeps/jep-0001.html)
[Resource Description Framework](http://www.w3.org/RDF/)

## The FOAF Vocabulary Description

[RDF](http://www.w3.org/RDF/)
[Semantic Web](http://www.w3.org/2001/sw/)
[Semantic Web](http://www.w3.org/2001/sw/)

### Evolution and Extension of FOAF

[Dublin Core](http://dublincore.org/)

## FOAF Auto-Discovery: Publishing and Linking FOAF files

[foaf-a-matic](http://www.ldodds.com/foaf/foaf-a-matic.html)
[FOAF
  autodiscovery](http://web.archive.org/web/20040416181630/rdfweb.org/mt/foaflog/archives/000041.html)

## FOAF cross-reference: Listing FOAF Classes and
  Properties

[RDF/XML](http://xmlns.com/foaf/spec/index.rdf)

### Classes and Properties (full detail)


## Classes


### Class: foaf:Agent


### Class: foaf:Document


### Class: foaf:Group

[issue tracker](http://wiki.foaf-project.org/w/IssueTracker)
[OWL](http://www.w3.org/2001/sw/WebOnt)

### Class: foaf:Image


### Class: foaf:Organization


### Class: foaf:Person


### Class: foaf:OnlineAccount


### Class: foaf:PersonalProfileDocument

[GRDDL](http://www.w3.org/2004/01/rdxh/spec)

### Class: foaf:Project


### Class: foaf:LabelProperty


### Class: foaf:OnlineChatAccount

[Jabber](http://www.jabber.org/)
[AIM](http://www.aim.com/)
[MSN](http://chat.msn.com/)
[ICQ](http://web.icq.com/icqchat/)
[Yahoo!](http://chat.yahoo.com/)
[MSN](http://chat.msn.com/)
[Freenode](http://www.freenode.net/)

### Class: foaf:OnlineEcommerceAccount

[Amazon](http://www.amazon.com/)
[eBay](http://www.ebay.com/)
[PayPal](http://www.paypal.com/)
[thinkgeek](http://www.thinkgeek.com/)

### Class: foaf:OnlineGamingAccount

[EverQuest](http://everquest.station.sony.com/)
[Xbox live](http://www.xbox.com/live/)
[Neverwinter Nights](http://nwn.bioware.com/)

## Properties


### Property: foaf:homepage


### Property: foaf:isPrimaryTopicOf


### Property: foaf:knows

[Relationship module](http://www.perceive.net/schemas/20021119/relationship/)
[scutters](http://wiki.foaf-project.org/w/ScutterSpec)

### Property: foaf:made


### Property: foaf:maker

[UsingDublinCoreCreator](http://wiki.foaf-project.org/w/UsingDublinCoreCreator)

### Property: foaf:mbox

[RFC 2368](http://ftp.ics.uci.edu/pub/ietf/uri/rfc2368.txt)

### Property: foaf:member


### Property: foaf:page


### Property: foaf:primaryTopic

[Wikipedia](http://www.wikipedia.org/)
[NNDB](http://www.nndb.com/)

### Property: foaf:weblog


### Property: foaf:account


### Property: foaf:accountName


### Property: foaf:accountServiceHomepage


### Property: foaf:aimChatID

[AIM](http://www.aim.com/)
[iChat](http://www.apple.com/macosx/what-is-macosx/ichat.html)
[Apple](http://www.apple.com/)

### Property: foaf:based_near

[geo-positioning vocabulary](http://www.w3.org/2003/01/geo/wgs84_pos#)
[GeoInfo](http://esw.w3.org/topic/GeoInfo)
[GeoOnion vocab](http://esw.w3.org/topic/GeoOnion)
[UsingContactNearestAirport](http://wiki.foaf-project.org/w/UsingContactNearestAirport)

### Property: foaf:currentProject


### Property: foaf:depiction

[Co-Depiction](http://rdfweb.org/2002/01/photo/)
['Annotating Images With SVG'](http://www.jibbering.com/svg/AnnotateImage.html)

### Property: foaf:depicts


### Property: foaf:familyName

[issue tracker](http://wiki.foaf-project.org/w/NameVocabIssue)

### Property: foaf:firstName

[issue tracker](http://wiki.foaf-project.org/w/NameVocabIssue)

### Property: foaf:focus

[SKOS](http://www.w3.org/2004/02/skos/)
[In SKOS](http://www.w3.org/TR/2005/WD-swbp-skos-core-guide-20050510/#secmodellingrdf)
[2005 discussion](http://www.w3.org/TR/2005/WD-swbp-skos-core-guide-20051102/#secopen)
[TDB URI scheme](http://larry.masinter.net/duri.html)
[original goals](http://www.foaf-project.org/original-intro)

### Property: foaf:gender

[foaf-dev](http://lists.foaf-project.org/mailman/listinfo/foaf-dev)

### Property: foaf:givenName

[issue tracker](http://wiki.foaf-project.org/w/NameVocabIssue)

### Property: foaf:icqChatID

[icq chat](http://web.icq.com/icqchat/)
[What is ICQ?](http://www.icq.com/products/whatisicq.html)
[About Us](http://company.icq.com/info/)

### Property: foaf:img


### Property: foaf:interest

[RDF](http://www.w3.org/RDF/)
[CPAN](http://www.cpan.org/)

### Property: foaf:jabberID

[Jabber](http://www.jabber.org/)
[Jabber](http://www.jabber.org/)

### Property: foaf:lastName

[issue tracker](http://wiki.foaf-project.org/w/NameVocabIssue)

### Property: foaf:logo


### Property: foaf:mbox_sha1sum

[Edd Dumbill's 
documentation](http://usefulinc.com/foaf/)
[FOAF-based whitelists](http://www.w3.org/2001/12/rubyrdf/util/foafwhite/intro.html)
[in Sam Ruby's 
weblog entry](http://www.intertwingly.net/blog/1545.html)

### Property: foaf:msnChatID

[Windows Live Messenger](http://en.wikipedia.org/wiki/Windows_Live_Messenger)
[Microsoft mesenger](http://download.live.com/messenger)
[Windows Live ID](http://en.wikipedia.org/wiki/Windows_Live_ID)

### Property: foaf:myersBriggs

[this article](http://www.teamtechnology.co.uk/tt/t-articl/mb-simpl.htm)
[Cory Caplinger's summary table](http://webspace.webring.com/people/cl/lifexplore/mbintro.htm)
[FOAF Myers Briggs addition](http://web.archive.org/web/20080802184922/http://rdfweb.org/mt/foaflog/archives/000004.html)

### Property: foaf:name

[issue tracker](http://wiki.foaf-project.org/w/IssueTracker)

### Property: foaf:nick


### Property: foaf:openid

[indirect identifier](http://www.w3.org/TR/webarch/#indirect-identification)
[OpenID](http://openid.net/specs/openid-authentication-1_1.html)
[delegation model](http://openid.net/specs/openid-authentication-1_1.html#delegating_authentication)
[technique](http://xmlns.com/foaf/spec/#sec-autodesc)

### Property: foaf:pastProject


### Property: foaf:phone


### Property: foaf:plan

[History of the 
Finger Protocol](http://www.rajivshah.com/Case_Studies/Finger/Finger.htm)

### Property: foaf:publications


### Property: foaf:schoolHomepage


### Property: foaf:skypeID


### Property: foaf:thumbnail


### Property: foaf:tipjar

[discussions](http://rdfweb.org/mt/foaflog/archives/2004/02/12/20.07.32/)
[PayPal](http://www.paypal.com/)

### Property: foaf:title

[FOAF Issue Tracker](http://wiki.foaf-project.org/w/IssueTracker)

### Property: foaf:topic


### Property: foaf:topic_interest


### Property: foaf:workInfoHomepage


### Property: foaf:workplaceHomepage


### Property: foaf:yahooChatID

[Yahoo! Chat](http://chat.yahoo.com/)
[Yahoo! Groups](http://www.yahoogroups.com/)

### Property: foaf:age


### Property: foaf:birthday

[BirthdayIssue](http://wiki.foaf-project.org/w/BirthdayIssue)

### Property: foaf:membershipClass


### Property: foaf:sha1


### Property: foaf:status


### Property: foaf:dnaChecksum


### Property: foaf:family_name


### Property: foaf:fundedBy


### Property: foaf:geekcode

[Wikipedia entry](http://en.wikipedia.org/wiki/Geek_Code)

### Property: foaf:givenname

[issue tracker](http://wiki.foaf-project.org/w/NameVocabIssue)

### Property: foaf:holdsAccount


### Property: foaf:surname

[issue 
tracker](http://wiki.foaf-project.org/w/IssueTracker)

### Property: foaf:theme


## External Vocabulary References


### Status Vocabulary

[SemWeb Vocab Status Ontology](http://www.w3.org/2003/06/sw-vocab-status/note)

### W3C Basic Geo (WGS84 lat/long) Vocabulary

[W3CBasic Geo Vocabulary](http://www.w3.org/2003/01/geo/)

### RDF Vocabulary Description - core concepts

[W3C's site](http://www.w3.org/2001/sw/)
[more background on URIs](http://www.w3.org/TR/webarch/#identification)
[linked data](http://www.w3.org/DesignIssues/LinkedData)
[SKOS](http://www.w3.org/2004/02/skos/)

### Dublin Core terms

[Dublin Core terms](http://dublincore.org/documents/dcmi-terms/)
[dct:Agent](http://dublincore.org/documents/dcmi-terms/#classes-Agent)
[dct:creator](http://dublincore.org/documents/dcmi-terms/#terms-creator)

### Wordnet terms

[recent](http://www.w3.org/TR/wordnet-rdf/)

### SIOC terms

[SIOC](http://rdfs.org/sioc/ns#)
[SIOC](http://www.sioc-project.org/)

### Acknowledgments

[rdfweb-dev](http://rdfweb.org/pipermail/rdfweb-dev/)
[#foaf](http://rdfweb.org/irc/)
[FoafExplorer](http://xml.mfd-consult.dk/foaf/explorer/)
[Web View](http://eikeon.com/foaf/)
[foaf-a-matic](http://www.ldodds.com/foaf/foaf-a-matic.html)
[Ecademy](http://www.ecademy.com/)
[TypePad](http://www.typepad.com/)
[many](http://conferences.oreillynet.com/cs/et2003/view/e_sess/3633)
[explaining](http://hackdiary.com/)
[in Japanese](http://kanzaki.com/docs/sw/foaf.html)
[Spanish](http://f14web.com.ar/inkel/2003/01/27/foaf.html)
[Chris Schmidt](http://crschmidt.net/)
[spec generation](http://xmlns.com/foaf/0.1/specgen.py)
[cool hacks](http://crschmidt.net/semweb/)
[FOAF Logo](http://iandavis.com/2006/foaf-icons/)
[years ago](http://www.w3.org/History/1989/proposal.html)

## Recent Changes


### Changes in version 0.99 (2014-01-14)

[schema.org](http://schema.org/)
[Person](http://schema.org/Person)
[ImageObject](http://schema.org/ImageObject)
[CreativeWork](http://schema.org/CreativeWork)

### 2010-08-09

[Bio vocabulary](http://vocab.org/bio/0.1/.html)

### Changes from version 0.97 and 0.96

[0.97](http://xmlns.com/foaf/spec/20100101.html)
[0.96](http://xmlns.com/foaf/spec/20091215.html)
[Portable Contacts](http://portablecontacts.net/)

### 2009-12-15


### 2007-11-02


### 2007-05-24

================
File: src/applications/link-lister/data/starter-links.md
================
https://en.wikipedia.org/wiki/FOAF

# https://en.wikipedia.org/wiki/WebID

# https://en.wikipedia.org/wiki/Resource_Description_Framework

http://xmlns.com/foaf/spec/

================
File: src/applications/link-lister/services.ttl
================
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix trm: <http://purl.org/stuff/transmission/> .
# @prefix fs: <http://purl.org/stuff/filesystem/> .
@prefix t: <http://hyperdata.it/transmissions/> . # for custom terms & instances

t:linklister trm:hasDataMap t:llSourceMap .
t:linklister trm:hasDataMap t:llGotMap .
t:linklister trm:hasDataMap t:llLinkMap .

t:llSourceMap a trm:DataMap ;
    trm:key t:sourceFile ;
    trm:value "starter-links.md" .

t:llGotMap a trm:DataMap ;
    trm:key t:gotFile ;
    trm:value "got.html" .

t:llLinkMap a trm:DataMap ;
    trm:key t:linkFile ;
    trm:value "links.md" .

t:htmlMap a trm:DataMap ;
    trm:key t:htmlFile ;
    trm:value "links.html" .

================
File: src/applications/link-lister/transmission.ttl
================
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix trm: <http://purl.org/stuff/transmission/> .
@prefix : <http://hyperdata.it/transmissions/> . # for custom terms & instances

:linklister a trm:Pipeline ;
    trm:pipe (:s1 :s2 :s3 :s4 :s5 :s6 :s7 :s8) .

:s1 a :FileReader ;
    trm:configKey :sourceFile .
:s2 a :LineReader .
:s3 a :HttpGet .

:s4 a :LinkFinder .

:s5 a :StringMerger .

:s6 a :FileWriter ;
    trm:configKey :linkFile .
# :s6 a :NOP .
:s7 a :MarkdownToHTML .

:s8 a :FileWriter ;
    trm:configKey :htmlFile .

#:s8 a :StringFilter .
#:s9 a :StringMerger .
#:s10 a :FileWriter 
#        trm:configKey :linkFile .
# :s4 a :NOP .
# :s4 a :FileWriter ;
#     trm:configKey :gotFile .

# :s5 a :NOP .

================
File: src/applications/postcraft/services.ttl
================
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix trm: <http://purl.org/stuff/transmission/> .
# @prefix fs: <http://purl.org/stuff/filesystem/> .
@prefix t: <http://hyperdata.it/transmissions/> . # for custom terms & instances

trm:Describe  a trm:ServiceConfig ; 
 trm:key trm:describe .

t:phaseOne a trm:ServiceConfig ; 
    trm:key t:markdownToRawPosts ;
    trm:marker "Phase One" .

# STYLES ETC not yet implemented
t:copyCSS a trm:FileCopy ;
        trm:key t:cssCopy .

t:copyFonts a trm:FileCopy ;
        trm:key t:fontsCopy .

t:copyJS a trm:FileCopy ;
        trm:key t:jsCopy .

# TODO IS COPY, not rename!!

t:walkPrep a trm:ReMap ;
    trm:rename (t:pp1 t:pp2) . # consider using blank nodes
    t:pp1   trm:pre     "content" ;
            trm:post    "template"  .
    t:pp2   trm:pre     "entryContentMeta.sourceDir" ;
            trm:post    "sourceDir" .
  #  t:pp2   trm:pre     "filename" ;
   #         trm:post    "filename"  .
 
t:entryRawPrep a trm:ReMap ;
    trm:rename (t:er1 t:er3) . 
   t:er1   trm:pre     "targetFilename" ;
            trm:post    "filepath" . 
    t:er3   trm:pre     "content" ;
            trm:post    "contentBlocks.content" .

t:entryPagePrep a trm:ReMap ;
    trm:rename (t:ppp1) . 
    t:ppp1   trm:pre     "content" ;
            trm:post    "contentBlocks.content" .

================
File: src/applications/postcraft/transmission.ttl
================
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix trm: <http://purl.org/stuff/transmission/> . # TODO make plural
@prefix : <http://hyperdata.it/transmissions/> . # for custom terms & instances - TODO make one @services s: 

#############################################################
# insert into pipe for debugging
:DE a :DeadEnd . # ends the current pipe quietly
:H  a :Halt . # kills everything 
:SM a :ShowMessage . # verbose report, continues pipe
:N  a :NOP . # no operation (except for showing stage in pipe)
:UF a :Unfork . # collapses all pipes but one 
#############################################################

:postTemplating a trm:Pipeline ;
    trm:pipe (:s1 :s2  :s3 :s4  :s5 :s6 :s7 :s8 :s9 :s10 :s11 :s12 :s13 :s14 :s15  :s16 :s17 :s18) .

:s1 a :ContextReader . # read the manifest
# trm:configKey trm:describe .

:s2 a :ConfigMap ; ### use services.ttl? - defer to RemapContext as possible
    trm:configKey :markdownToRawPosts .

:s3 a :FileReader ; # the template for raw entry content
    trm:describe trm:all .

:s4 a :RemapContext ;
    trm:configKey :walkPrep .

:s5 a :DirWalker . # automatically forks

:s6 a :FileReader . # the markdown content

:s7 a :PostcraftPrep . # set up title, filenames etc

:s8 a :MarkdownToHTML . 

:s9 a :RemapContext ;
   trm:configKey :entryRawPrep .

 :s10 a :Templater .

:s11 a :FileWriter .

############### entryContentToEntryPage
:s12 a :EntryContentToPagePrep .
#:s12 a :RemapContext ;
 #  trm:configKey :entryPagePrep .

:s13 a :Templater .

:s14 a :FileWriter .

#######################
:s15  a :Unfork .

:s16 a :FrontPagePrep . 

:s17 a :Templater .

:s18 a :FileWriter .

================
File: src/applications/string-pipeline/services.ttl
================
### NOT USED

@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix dc: <http://purl.org/dc/terms/> .
@prefix trm: <http://purl.org/stuff/transmission/> .
@prefix : <http://hyperdata.it/transmissions/> . # for custom terms & instances

:StringPipeline dc:title "Hello" .

================
File: src/applications/string-pipeline/transmission.ttl
================
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix trm: <http://purl.org/stuff/transmission/> .
@prefix : <http://hyperdata.it/transmissions/> . # for custom terms & instances

:stringpipe a trm:Pipeline ;
    trm:pipe (:s1 :s2 :s3 :s4) .

:s1 a :StringSource .
:s2 a :AppendProcess .
:s3 a :AppendProcess .
:s4 a :StringSink .

================
File: src/applications/test_fork/about.md
================
# Test Fork/Unfork

```
./run test_fork | grep 's2 a NOP'
```

should show the number of forks + 1 (for `message.done`)

```
./run test_fork | grep s1.s2.s10.s11.s12.s13
```

should show just one

================
File: src/applications/test_fork/services.ttl
================
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix trm: <http://purl.org/stuff/transmission/> .
# @prefix fs: <http://purl.org/stuff/filesystem/> .
@prefix t: <http://hyperdata.it/transmissions/> . # for custom terms & instances

t:dirWalkerPosts a trm:ServiceConfig ;
    trm:key t:files .

t:postTemplateMap a trm:ReMap ;
   trm:rename (t:rn1) . # consider using blank nodes
     t:rn1    trm:pre     "content" ;
            trm:post    "template"  .

t:postSaver a trm:ReMap ;
    trm:rename (t:rn2) . 
    t:rn2   trm:pre     "targetFilename" ;
            trm:post    "filename" .

================
File: src/applications/test_fork/transmission.ttl
================
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix trm: <http://purl.org/stuff/transmission/> . # TODO make plural
@prefix : <http://hyperdata.it/transmissions/> . # for custom terms & instances - TODO make one @services s: 

# ./run test_fork | grep s1.s2.s10.s11.s12.s13

:test_fork a :Transmission ;
   trm:contains :pipeA .

:pipeA a trm:Pipeline ;
trm:pipe (:s1 :s2 :s10 :s11 :s12 :s13) .

:s1 a :Fork .
:s2 a :NOP .
:s10 a :Unfork .
:s11 a :NOP .
:s12 a :NOP .
:s13 a :NOP .
# :s12 a :ShowMessage .

================
File: src/applications/test_multi-pipe/services.ttl
================
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix trm: <http://purl.org/stuff/transmission/> .
# @prefix fs: <http://purl.org/stuff/filesystem/> .
@prefix t: <http://hyperdata.it/transmissions/> . # for custom terms & instances

t:dirWalkerPosts a trm:ServiceConfig ;
    trm:key t:files .

t:postTemplateMap a trm:ReMap ;
   trm:rename (t:rn1) . # consider using blank nodes
     t:rn1    trm:pre     "content" ;
            trm:post    "template"  .

t:postSaver a trm:ReMap ;
    trm:rename (t:rn2) . 
    t:rn2   trm:pre     "targetFilename" ;
            trm:post    "filename" .

================
File: src/applications/test_multi-pipe/transmission.ttl
================
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix trm: <http://purl.org/stuff/transmission/> . # TODO make plural
@prefix : <http://hyperdata.it/transmissions/> . # for custom terms & instances - TODO make one @services s: 

:test_multi-pipes a :Transmission ;
   trm:contains :pipeA, :pipeB, :pipeC .

:pipeA a trm:Pipeline ;
trm:pipe (:s1 :s2 :s3 ) .

:pipeB  a trm:Pipeline ;
 trm:pipe (:s3 :s104 :s105) .

:pipeC a trm:Pipeline ;
trm:pipe (:s3 :s204 :s205) .

# :postcraft a trm:Pipeline ;

:s1 a :NOP .
:s2 a :NOP .
:s3 a :NOP .

:s104 a :NOP .
:s105 a :NOP .

:s204 a :NOP .
:s205 a :ShowTransmission .

================
File: src/engine/AbstractServiceFactory.js
================
import logger from '../utils/Logger.js'
import ns from '../utils/ns.js'
import TestServicesFactory from '../services/test/TestServicesFactory.js'
import FsServicesFactory from '../services/fs/FsServicesFactory.js'
import MarkupServicesFactory from '../services/markup/MarkupServicesFactory.js'
import UtilServicesFactory from '../services/util/UtilServicesFactory.js'
import TextServicesFactory from '../services/text/TextServicesFactory.js'
import ProtocolsServicesFactory from '../services/protocols/ProtocolsServicesFactory.js'
import RDFServicesFactory from '../services/rdf/RDFServicesFactory.js'
import PostcraftServicesFactory from '../services/postcraft/PostcraftServicesFactory.js'
class AbstractServiceFactory {
    static createService(type, config) {
        var service = TestServicesFactory.createService(type, config)
        if (service) return service
        var service = UtilServicesFactory.createService(type, config)
        if (service) return service
        service = FsServicesFactory.createService(type, config)
        if (service) return service
        service = MarkupServicesFactory.createService(type, config)
        if (service) return service
        service = TextServicesFactory.createService(type, config)
        if (service) return service
        service = ProtocolsServicesFactory.createService(type, config)
        if (service) return service
        service = RDFServicesFactory.createService(type, config)
        if (service) return service
        service = PostcraftServicesFactory.createService(type, config)
        if (service) return service
        throw new Error("Unknown service type: " + type.value)
    }
}
export default AbstractServiceFactory

================
File: src/engine/Connector.js
================
import { EventEmitter } from 'events'
import logger from '../utils/Logger.js'
import footpath from '../utils/footpath.js'
class Connector extends EventEmitter {
    constructor(fromName, toName) {
        super();
        this.fromName = fromName
        this.toName = toName
    }
    connect(services) {
        let fromService = services[this.fromName]
        let toService = services[this.toName]
        fromService.on('message', (message) => {
            var tags = ''
            //     if (toService.message) {
            tags = ' (' + fromService.message.tags + ') '
            toService.tags = tags
            const thisTag = footpath.urlLastPart(this.toName)
            logger.log("| Running : " + tags + thisTag + " a " + toService.constructor.name)
            toService.receive(message)
        })
    }
}
export default Connector

================
File: src/engine/Transmission.js
================
import logger from '../utils/Logger.js'
import Connector from './Connector.js'
class Transmission {
  constructor() {
    this.services = {}
    this.connectors = []
  }
  register(serviceName, instance) {
    this.services[serviceName] = instance
  }
  get(serviceName) {
    return this.services[serviceName]
  }
  connect(fromServiceName, toServiceName) {
    let connector = new Connector(fromServiceName, toServiceName)
    this.connectors.push(connector)
    connector.connect(this.services)
  }
  async execute(message) {
    logger.log("\n+ ***** Execute *****")
    const serviceName = this.connectors[0].fromName
    let service = this.get(serviceName)
    logger.log("| Running : " + serviceName + " a " + service.constructor.name)
    service.receive(message)
  }
  toString() {
    let description = 'Transmission Structure:\n';
    description += 'Services:\n';
    Object.keys(this.services).forEach(serviceName => {
      description += `  - ${serviceName}\n`;
    });
    description += 'Connectors:\n';
    this.connectors.forEach((connector, index) => {
      description += `  - Connector ${index + 1}: ${connector.fromName} -> ${connector.toName}\n`;
    })
    return description
  }
}
export default Transmission

================
File: src/engine/TransmissionBuilder.js
================
import rdf from 'rdf-ext'
import grapoi from 'grapoi'
import { fromFile, toFile } from 'rdf-utils-fs'
import ns from '../utils/ns.js'
import GrapoiHelpers from '../utils/GrapoiHelpers.js'
import logger from '../utils/Logger.js'
import AbstractServiceFactory from "./AbstractServiceFactory.js";
import Transmission from './Transmission.js'
class TransmissionBuilder {
  static async build(transmissionConfigFile, servicesConfigFile) {
    logger.info('\n+ ***** Load Config ******')
    logger.info('[Transmission : ' + transmissionConfigFile + ']')
    const transmissionConfig = await TransmissionBuilder.readDataset(transmissionConfigFile)
    logger.info('[Config : ' + servicesConfigFile + ']')
    const servicesConfig = await TransmissionBuilder.readDataset(servicesConfigFile)
    const poi = grapoi({ dataset: transmissionConfig })
    const transmission = new Transmission()
    for (const q of poi.out(ns.rdf.type).quads()) {
      if (q.object.equals(ns.trm.Pipeline)) {
        TransmissionBuilder.addPipeline(transmission, transmissionConfig, q.subject, servicesConfig)
      }
    }
    return transmission
  }
  static addPipeline(transmission, transmissionConfig, pipelineID, servicesConfig) {
    logger.log('\n+ ***** Construct *****')
    let previousName = "nothing"
    const pipenodes = GrapoiHelpers.listToArray(transmissionConfig, pipelineID, ns.trm.pipe)
    this.createNodes(transmission, pipenodes, transmissionConfig, servicesConfig)
    this.connectNodes(transmission, pipenodes)
    return transmission
  }
  static createNodes(transmission, pipenodes, transmissionConfig, servicesConfig) {
    for (let i = 0; i < pipenodes.length; i++) {
      let node = pipenodes[i]
      let serviceName = node.value
      if (!transmission.get(serviceName)) {
        let np = rdf.grapoi({ dataset: transmissionConfig, term: node })
        let serviceType = np.out(ns.rdf.type).term
        let serviceConfig = np.out(ns.trm.configKey).term
        try {
          logger.log("| Create service <" + serviceName + "> of type <" + serviceType.value + ">")
        } catch (err) {
          logger.error('-> Can\'t resolve ' + serviceName + ' check transmission.ttl\n')
        }
        let service = AbstractServiceFactory.createService(serviceType, servicesConfig)
        service.id = serviceName
        service.type = serviceType
        service.transmission = transmission
        if (serviceConfig) {
          service.configKey = serviceConfig
        }
        transmission.register(serviceName, service)
      }
    }
  }
  static connectNodes(transmission, pipenodes) {
    for (let i = 0; i < pipenodes.length - 1; i++) {
      let leftNode = pipenodes[i]
      let leftServiceName = leftNode.value
      let rightNode = pipenodes[i + 1]
      let rightServiceName = rightNode.value
      logger.log("  > Connect #" + i + " [" + leftServiceName + "] => [" + rightServiceName + "]")
      transmission.connect(leftServiceName, rightServiceName)
    }
  }
  static async readDataset(filename) {
    const stream = fromFile(filename)
    const dataset = await rdf.dataset().import(stream)
    return dataset
  }
  static async writeDataset(dataset, filename) {
    await toFile(dataset.toStream(), filename)
  }
}
export default TransmissionBuilder

================
File: src/engine/WorkerPool.js
================
import { Worker } from 'worker_threads'
class WorkerPool {
    constructor(module, size) {
        this.workers = [];
        this.queue = [];
        for (let i = 0; i < size; i++) {
            const worker = new Worker(module);
            worker.on('message', () => {
                this.markWorkerIdle(worker);
            });
            this.workers.push({ worker, busy: false });
        }
    }
    enqueueMessage(message) {
        this.queue.push(message);
        this.dispatch();
    }
    dispatch() {
        const idleWorkerWrapper = this.workers.find(wrapper => !wrapper.busy);
        if (idleWorkerWrapper && this.queue.length) {
            const message = this.queue.shift();
            idleWorkerWrapper.busy = true;
            idleWorkerWrapper.worker.postMessage(message);
        }
    }
    markWorkerIdle(workerWrapper) {
        workerWrapper.busy = false;
        this.dispatch();
    }
}

================
File: src/services/ServiceExample.js
================
import { readFile } from 'node:fs/promises'
import logger from '../utils/Logger.js'
import Service from '../base/Service.js'
class ServiceExample extends Service {
    constructor(config) {
        super(config)
    }
    async execute(message) {
        this.emit('message', message)
    } catch(err) {
        logger.error("ServiceExample.execute error : " + err.message)
    }
}
export default ServiceExample

================
File: src/services/base/ProcessService.js
================
import logger from '../../utils/Logger.js'
import Service from './Service.js'
class ProcessService extends Service {
    constructor(config) {
        super(config)
    }
    async execute(message) {
        this.emit('message', message)
    }
}
export default ProcessService

================
File: src/services/base/Service.js
================
import logger from '../../utils/Logger.js'
import { EventEmitter } from 'events'
import rdf from 'rdf-ext'
import grapoi from 'grapoi'
import ns from '../../utils/ns.js'
import footpath from '../../utils/footpath.js'
class Service extends EventEmitter {
    constructor(config) {
        super()
        this.config = config
        this.messageQueue = []
        this.processing = false
        this.done = false
    }
    preProcess(message) {
        return
        const servicePoi = rdf.grapoi({ dataset: this.config, term: this.configKey })
        logger.log('this.configKey = ' + this.configKey.value)
        logger.poi(servicePoi)
        logger.log('describe Desc')
        if (this.configKey.value === ns.trm.describe.value) {
            this.describe()
        }
    }
    describe() {
        logger.log('describe')
        const inputs = this.getInputKeys()
        const outputs = this.getOutputKeys()
        for (var input of inputs) {
            logger.log('input = ' + input)
            logger.log(this.message[input] + ' = ' + this.message[input])
        }
        for (var output of outputs) {
            logger.log('output = ' + output)
            logger.log(this.message[output] + ' = ' + this.message[output])
        }
    }
    getMyConfigNode() {
        const dataset = this.config
        const configNode = grapoi({ dataset, term: this.configKey }).in()
        return configNode.term
    }
    getMyPoi() {
        const dataset = this.config
        const myConfigNode = this.getMyConfigNode()
        const poi = grapoi({ dataset: dataset, term: myConfigNode })
        return poi
    }
    async addPropertyToMyConfig(predicate, value) {
        logger.log('addPropertyToMyConfig predicate = ' + predicate)
        logger.log('addPropertyToMyConfig value = ' + value)
        const myConfigNode = this.getMyConfigNode()
        const s = myConfigNode.value
        logger.log('addPropertyToMyConfig  myConfigNode.value = ' + myConfigNode.value)
        const dataset = this.config
        dataset.add(myConfigNode, predicate, value)
        this.config = dataset
    }
    showMyConfig() {
        const poi = this.getMyPoi()
        logger.log('POI = ')
        logger.poi(poi)
    }
    async deletePropertyFromMyConfig(predicate, value) {
        const myConfigNode = this.getMyConfigNode()
        const s = myConfigNode.value
        logger.log('DELETING FROM ' + s)
        const dataset = this.config
        dataset.delete(myConfigNode, predicate, value)
        this.config = dataset
    }
    async receive(message) {
        await this.enqueue(message)
    }
    async enqueue(message) {
        this.messageQueue.push({ message })
        if (!this.processing) {
            this.executeQueue()
        }
    }
    cloneContext(baseContext) {
        const message = structuredClone(baseContext)
        if (baseContext.dataset) {
            message.dataset = baseContext.dataset
        }
        return message
    }
    async executeQueue() {
        this.processing = true
        while (this.messageQueue.length > 0) {
            let { message } = this.messageQueue.shift()
            message = this.cloneContext(message)
            this.message = message
            this.addTag(message)
            await this.execute(message)
        }
        this.processing = false
    }
    addTag(message) {
        const tag = this.getTag()
        if (!message.tags) {
            message.tags = tag
            return
        }
        message.tags = message.tags + '.' + tag
    }
    getTag() {
        return footpath.urlLastPart(this.id)
    }
    async execute(message) {
        throw new Error('execute method not implemented')
    }
    async doEmit(message) {
        this.emit(message)
    }
}
export default Service

================
File: src/services/base/SinkService.js
================
import Service from './Service.js'
class SinkService extends Service {
    constructor(config) {
        super(config)
    }
    async execute(message) {
    }
}
export default SinkService

================
File: src/services/base/SourceService.js
================
import Service from './Service.js'
class SourceService extends Service {
    constructor(config) {
        super(config);
    }
}
export default SourceService

================
File: src/services/fs/DirWalker.js
================
import rdf from 'rdf-ext'
import ns from '../../utils/ns.js'
import { readdir } from 'fs/promises'
import { join, extname } from 'path'
import grapoi from 'grapoi'
import logger from '../../utils/Logger.js'
import SourceService from '../base/SourceService.js'
class DirWalker extends SourceService {
    constructor(config) {
        super(config)
        const dataset = this.config
        const poi = grapoi({ dataset })
        this.desiredExtensions = ['.md']
    }
    async execute(message) {
        await this.emitThem(message)
        message.done = true
        this.emit('message', message)
    }
    async emitThem(message) {
        message.counter = 0
        message.slugs = []
        message.done = false
        const dirPath = message.rootDir + '/' + message.sourceDir
        try {
            const entries = await readdir(dirPath, { withFileTypes: true })
            for (const entry of entries) {
                const fullPath = join(dirPath, entry.name)
                if (entry.isDirectory()) {
                    await this.execute(entry.name, message)
                } else {
                    if (this.desiredExtensions.includes(extname(entry.name))) {
                        message.filename = entry.name
                        message.filepath = message.sourceDir + '/' + entry.name
                        const slug = this.extractSlug(message.filename)
                        message.slugs.push(slug)
                        message.done = false
                        message.counter = message.counter + 1
                        const messageClone = structuredClone(message)
                        this.emit('message', messageClone)
                    }
                }
            }
        } catch (err) {
            logger.error("DirWalker.execute error : " + err.message)
        }
    }
    extractSlug(filepath) {
        var slug = filepath
        if (slug.includes('.')) {
            slug = slug.substr(0, slug.lastIndexOf("."))
        }
        return slug
    }
}
export default DirWalker

================
File: src/services/fs/FileCopy.js
================
import { copyFile, mkdir, readdir, stat } from 'node:fs/promises'
import { join } from 'node:path'
import logger from '../../utils/Logger.js'
import Service from '../base/Service.js'
class FileCopy extends Service {
    constructor(config) {
        super(config)
    }
    async execute(message) {
        try {
            const { source, destination } = message
            const sourceStat = await stat(source)
            if (sourceStat.isFile()) {
                await this.copyFile(source, destination)
            } else if (sourceStat.isDirectory()) {
                await this.copyDirectory(source, destination)
            }
            this.emit('message', message)
        } catch (err) {
            logger.error("FileCopy.execute error: " + err.message)
        }
    }
    async copyFile(source, destination) {
        try {
            const destPath = join(destination, source.split('/').pop())
            await copyFile(source, destPath)
        } catch (err) {
            logger.error("FileCopy.copyFile error: " + err.message)
        }
    }
    async copyDirectory(source, destination) {
        try {
            const destDir = join(destination, source.split('/').pop())
            await mkdir(destDir, { recursive: true })
            const entries = await readdir(source, { withFileTypes: true })
            for (const entry of entries) {
                const srcPath = join(source, entry.name)
                const destPath = join(destDir, entry.name)
                if (entry.isDirectory()) {
                    await this.copyDirectory(srcPath, destPath)
                } else {
                    await copyFile(srcPath, destPath)
                }
            }
        } catch (err) {
            logger.error("FileCopy.copyDirectory error: " + err.message)
        }
    }
}
export default FileCopy

================
File: src/services/fs/FileReader.js
================
import { readFile } from 'node:fs/promises'
import logger from '../../utils/Logger.js'
import SourceService from '../base/SourceService.js'
class FileReader extends SourceService {
    constructor(config) {
        super(config)
    }
    async execute(message) {
        this.preProcess(message)
        var filepath = message.filepath
        if (!filepath) {
            filepath = this.getMyConfig().value
        }
        logger.log(' - FileReader reading filepath : ' + filepath)
        const f = message.rootDir + '/' + filepath
        try {
            message.content = (await readFile(f)).toString()
            this.emit('message', message)
        } catch (err) {
            logger.error("FileReader.execute error : " + err.message)
        }
    }
}
export default FileReader

================
File: src/services/fs/FileRemove.js
================
import { unlink, readdir, stat, rm } from 'node:fs/promises'
import { join } from 'node:path'
import logger from '../../utils/Logger.js'
import Service from '../base/Service.js'
class FileRemove extends Service {
    constructor(config) {
        super(config)
    }
    async execute(message) {
        try {
            const { remove } = message
            const removeStat = await stat(remove)
            if (removeStat.isFile()) {
                await this.removeFile(remove)
            } else if (removeStat.isDirectory()) {
                await this.removeDirectoryContents(remove)
            }
            this.emit('message', message)
        } catch (err) {
            logger.error("FileRemove.execute error: " + err.message)
        }
    }
    async removeFile(filePath) {
        try {
            await unlink(filePath)
        } catch (err) {
            logger.error("FileRemove.removeFile error: " + err.message)
        }
    }
    async removeDirectoryContents(dirPath) {
        try {
            const entries = await readdir(dirPath, { withFileTypes: true })
            for (const entry of entries) {
                const entryPath = join(dirPath, entry.name)
                if (entry.isDirectory()) {
                    await this.removeDirectoryContents(entryPath)
                } else {
                    await unlink(entryPath)
                }
            }
        } catch (err) {
            logger.error("FileRemove.removeDirectoryContents error: " + err.message)
        }
    }
}
export default FileRemove

================
File: src/services/fs/FileWriter.js
================
import { writeFile } from 'node:fs/promises'
import { dirname, join } from 'node:path'
import { mkdir, mkdirSync } from 'node:fs'
import logger from '../../utils/Logger.js'
import SinkService from '../base/SinkService.js'
class FileWriter extends SinkService {
    constructor(config) {
        super(config)
    }
    getInputKeys() {
        return ['filepath, content']
    }
    async execute(message) {
        this.preProcess()
        var filepath = message.filepath
        const content = message.content
        logger.debug("Filewriter.targetFile = " + filepath)
        const dirName = dirname(filepath)
        try {
            await this.mkdirs(dirName)
            logger.log(' - FileWriter writing : ' + filepath)
            await writeFile(filepath, content)
        } catch (err) {
            logger.error("FileWriter.execute error : " + err.message)
        }
        this.emit('message', message)
    }
    async mkdirs(dir) {
        if (!dir) return;
        try {
            mkdir(dir, { recursive: true }, (error) => { })
        } catch (error) {
            console.error(error);
        }
    }
}
export default FileWriter

================
File: src/services/fs/FsServicesFactory.js
================
import logger from '../../utils/Logger.js'
import ns from '../../utils/ns.js'
import DirWalker from './DirWalker.js'
import FileReader from './FileReader.js'
import FileWriter from './FileWriter.js'
import FileCopy from './FileCopy.js'
import FileRemove from './FileRemove.js'
class FsServicesFactory {
    static createService(type, config) {
        if (type.equals(ns.t.DirWalker)) {
            return new DirWalker(config)
        }
        if (type.equals(ns.t.FileReader)) {
            return new FileReader(config)
        }
        if (type.equals(ns.t.FileWriter)) {
            return new FileWriter(config)
        }
        if (type.equals(ns.t.FileCopy)) {
            return new FileCopy(config)
        }
        if (type.equals(ns.t.FileRemove)) {
            return new FileRemove(config)
        }
        return false
    }
}
export default FsServicesFactory

================
File: src/services/markup/LinkFinder.js
================
import * as cheerio from 'cheerio'
import logger from '../../utils/Logger.js'
import ProcessService from '../base/ProcessService.js'
class LinkFinder extends ProcessService {
    async execute(message) {
        await this.extractLinks(message)
        if (data === '~~done~~') {
            logger.log('LF DONE*****************')
            this.emitLocal('message', '~~done~~', message)
            return
        }
    }
    relocate(filename, extension) {
        const split = filename.split('.').slice(0, -1)
        return split.join('.') + extension
    }
    async extractLinks(htmlContent, message) {
        const $ = cheerio.load(htmlContent)
        let label = ''
        $('a, h1, h2, h3, h4, h5, h6').each((_, element) => {
            const tagName = element.tagName.toLowerCase()
            if (tagName.startsWith('h')) {
                const level = tagName.substring(1)
                const headerText = $(element).text()
                label = `\n\n${'#'.repeat(parseInt(level))} ${headerText}\n`;
            } else if (tagName === 'a') {
                const linkText = $(element).text()
                let href = $(element).attr('href')
                if (!href || href.startsWith('#')) return
                if (href && !href.includes('://')) {
                    const baseURL = message.sourceURL
                    href = new URL(href, baseURL).toString();
                }
                label = `\n[${linkText}](${href})`
            }
            message.label = label
            this.emit('message', message)
        })
    }
}
export default LinkFinder

================
File: src/services/markup/MarkdownToHTML.js
================
import logger from '../../utils/Logger.js'
import ProcessService from '../base/ProcessService.js'
import { parse } from 'marked'
class MarkdownToHTML extends ProcessService {
    async execute(message) {
        const input = message.content
        message.content = await parse(input.toString())
        this.emit('message', message)
    }
}
export default MarkdownToHTML

================
File: src/services/markup/MarkupServicesFactory.js
================
import logger from '../../utils/Logger.js'
import ns from '../../utils/ns.js'
import MetadataExtractor from './MetadataExtractor.js'
import LinkFinder from './LinkFinder.js'
import MarkdownToHTML from './MarkdownToHTML.js'
class MarkupServicesFactory {
    static createService(type, config) {
        if (type.equals(ns.t.MetadataExtractor)) {
            return new MetadataExtractor(config)
        }
        if (type.equals(ns.t.MarkdownToHTML)) {
            return new MarkdownToHTML(config)
        }
        if (type.equals(ns.t.LinkFinder)) {
            return new LinkFinder(config)
        }
        return false
    }
}
export default MarkupServicesFactory

================
File: src/services/markup/MetadataExtractor.js
================
import * as cheerio from 'cheerio'
import logger from '../../utils/Logger.js'
import ProcessService from '../base/ProcessService.js'
class MetadataExtractor extends ProcessService {
    async execute(message) {
        const filename = data.filename
        const content = data.content
        logger.debug("MetadataExtractor input file : " + filename)
        const targetFilename = this.relocate(filename)
        logger.debug("MetadataExtractor outputfile : " + targetFilename)
        const jsonData = this.convertEmailToJSON(content)
        const jsonString = JSON.stringify(jsonData)
        const output = { filename: targetFilename, content: jsonString }
        this.emit('message', output, message)
    }
    relocate(filename) {
        const split = filename.split('.').slice(0, -1)
        var newFileName = split.join('.') + '.json'
        return newFileName
    }
    convertEmailToJSON(htmlContent) {
        const $ = cheerio.load(htmlContent);
        var subjectLine = $('H1').text().trim()
        var fromName = $('B').first().text().trim()
        var nextMessageLink = $('LINK[REL="Next"]').attr('HREF')
        var previousMessageLink = $('LINK[REL="Previous"]').attr('HREF')
        var messageText = $('PRE').text().trim()
        messageText = this.pruneContent(messageText)
        const jsonResult = {
            subjectLine: subjectLine,
            fromName: fromName,
            nextMessageLink: nextMessageLink,
            previousMessageLink: previousMessageLink,
            messageText: messageText
        }
        return jsonResult;
    }
    pruneContent(content) {
        const regex1 = /(^|\n).*?:\n>/s
        content = content.replace(regex1, '$1')
        const regex2 = /\n>.*?\n/g;
        content = content.replace(regex2, '\n')
        return content
    }
}
export default MetadataExtractor

================
File: src/services/postcraft/EntryContentToPagePrep.js
================
import ns from '../../utils/ns.js'
import rdf from 'rdf-ext'
import grapoi from 'grapoi'
import footpath from '../../utils/footpath.js'
import logger from '../../utils/Logger.js'
import ProcessService from '../base/ProcessService.js'
class EntryContentToPagePrep extends ProcessService {
  constructor(config) {
    super(config)
  }
  async execute(message) {
    if (message.done) {
      this.emit('message', message)
      return
    }
    message.templateFilename = message.rootDir + '/' + message.entryContentToPage.templateFilename
    message.template = false
    message.contentBlocks.content = message.content
    message.filepath = message.rootDir + '/' + message.entryContentToPage.targetDir + '/' + message.slug + '.html'
    this.emit('message', message)
  }
}
export default EntryContentToPagePrep

================
File: src/services/postcraft/FrontPagePrep.js
================
import ns from '../../utils/ns.js'
import rdf from 'rdf-ext'
import grapoi from 'grapoi'
import footpath from '../../utils/footpath.js'
import logger from '../../utils/Logger.js'
import ProcessService from '../base/ProcessService.js'
import { readFile } from 'node:fs/promises'
class FrontPagePrep extends ProcessService {
  constructor(config) {
    super(config)
  }
  async execute(message) {
    try {
      message.templateFilename = message.rootDir + '/' + message.indexPage.templateFilename
      logger.log('TERMPLATE = ' + message.templateFilename)
      const rawEntryPaths = this.resolveRawEntryPaths(message)
      message.content = ''
      // TODO move this out to template and/or separate services
      //   for (var f of rawEntryPaths) {
      //   const n = rawEntryPaths.length
      const entryCount = 5
      //    for (var i = entryCount - 1; i >= 0; i--) {
      for (var i = 0; i < entryCount; i++) {
        const rawEntryPath = rawEntryPaths.pop()
        message.content += (await readFile(rawEntryPath)).toString()
      }
      // needed?
      message.contentBlocks.content = message.content
      //  "indexPage": {
      //  "filepath": "public/blog/index.html",
      message.filepath = message.rootDir + '/' + message.indexPage.filepath
      // message.rootDir + '/' + message.entryContentToPage.targetDir + '/' + message.slug + '.html'
      this.emit('message', message)
    } catch (err) {
      logger.error('Error in FrontPagePrep')
      logger.error(err)
    }
  }
  resolveRawEntryPaths(message) {
    var paths = []
    const slugs = message.slugs
    const entryCount = slugs.length
    var path
    for (let i = 0; i < entryCount; i++) {
      var path = slugs[i]
      if (!path) break
      path = message.rootDir + '/' + message.entryContentMeta.targetDir + '/' + path + '.html'
      paths.push(path)
    }
    return paths
  }
}
export default FrontPagePrep

================
File: src/services/postcraft/PostcraftDispatcher.js
================

import ns from '../../utils/ns.js'
import rdf from 'rdf-ext'
import grapoi from 'grapoi'
import footpath from '../../utils/footpath.js'
import logger from '../../utils/Logger.js'
import ProcessService from '../base/ProcessService.js'
class PostcraftDispatcher extends ProcessService {
  constructor(config) {
    super(config)
  }
  async execute(message) {
    const postcraftConfig = message.dataset
    message.template = data.toString()
    logger.log('PostcraftDispatcherPostcraftDispatcherPostcraftDispatcher ' + data)
    const poi = grapoi({ dataset: postcraftConfig })
    for (const q of poi.out(ns.rdf.type).quads()) {
      if (q.object.equals(ns.pc.ContentGroup)) {
        await this.processContentGroup(message, q.subject)
      }
    }
  }
  async processContentGroup(message, contentGroupID) {
    const postcraftConfig = message.dataset
    const groupPoi = rdf.grapoi({ dataset: postcraftConfig, term: contentGroupID })
    const sourceDir = groupPoi.out(ns.fs.sourceDirectory).term.value
    const targetDir = groupPoi.out(ns.fs.targetDirectory).term.value
    const templateFilename = groupPoi.out(ns.pc.template).term.value
    message.sourceDir = sourceDir
    message.targetDir = targetDir
    message.templateFilename = templateFilename
    message.loadContext = 'template'
    this.emit('message', sourceDir, message)
  }
}
export default PostcraftDispatcher

================
File: src/services/postcraft/PostcraftPrep.js
================
import ns from '../../utils/ns.js'
import rdf from 'rdf-ext'
import grapoi from 'grapoi'
import footpath from '../../utils/footpath.js'
import logger from '../../utils/Logger.js'
import ProcessService from '../base/ProcessService.js'
class PostcraftPrep extends ProcessService {
  constructor(config) {
    super(config)
  }
  async execute(message) {
    message.slug = this.extractSlug(message)
    message.targetFilename = this.extractTargetFilename(message) + '.html'
    message.contentBlocks = {}
    message.contentBlocks.relURL = this.extractRelURL(message)
    message.contentBlocks.link = message.siteURL + '/' + message.contentBlocks.relURL
    message.contentBlocks.title = this.extractTitle(message)
    const { created, updated } = this.extractDates(message)
    message.contentBlocks.created = created
    message.contentBlocks.updated = updated
    this.emit('message', message)
  }
  extractSlug(message) {
    var slug = message.filename
    if (slug.includes('.')) {
      slug = slug.substr(0, slug.lastIndexOf("."))
    }
    return slug
  }
  extractTargetFilename(message) {
    return message.rootDir + '/' + message.entryContentMeta.targetDir + '/' + this.extractSlug(message)
  }
  extractRelURL(message) {
    return message.subdir + '/' + this.extractSlug(message) + '.html'
  }
  extractDates(message) {
    const today = (new Date()).toISOString().split('T')[0]
    const dates = { created: today, updated: today }
    const nonExt = message.filename.split('.').slice(0, -1).join()
    const shreds = nonExt.split('_')
    if (Date.parse(shreds[0])) {
      dates.created = shreds[0]
    }
    return dates
  }
  extractTitle(message) {
    let title = 'Title'
    let match = message.content.toString().match(/^#(.*)$/m)
    let contentTitle = match ? match[1].trim() : null
    if (contentTitle) {
      title = contentTitle.replaceAll('#', '') // TODO make nicer
      return title
    }
    // derive from filename
    // eg. 2024-04-19_hello-postcraft.md
    try {
      const nonExt = message.filename.split('.').slice(0, -1).join()
      const shreds = nonExt.split('_')
      title = shreds[1].split('-')
        .map(word => word.charAt(0).toUpperCase() + word.slice(1))
        .join(' ');
    } catch (err) {
      title = message.filename
    }
    return title
  }
}
export default PostcraftPrep

================
File: src/services/postcraft/PostcraftServicesFactory.js
================
import logger from '../../utils/Logger.js'
import ns from '../../utils/ns.js'
import PostcraftDispatcher from './PostcraftDispatcher.js'
import PostcraftPrep from './PostcraftPrep.js'
import EntryContentToPagePrep from './EntryContentToPagePrep.js'
import FrontPagePrep from './FrontPagePrep.js'
class PostcraftServicesFactory {
    static createService(type, config) {
        if (type.equals(ns.t.PostcraftDispatcher)) {
            return new PostcraftDispatcher(config)
        }
        if (type.equals(ns.t.PostcraftPrep)) {
            return new PostcraftPrep(config)
        }
        if (type.equals(ns.t.EntryContentToPagePrep)) {
            return new EntryContentToPagePrep(config)
        }
        if (type.equals(ns.t.FrontPagePrep)) {
            return new FrontPagePrep(config)
        }
        return false
    }
}
export default PostcraftServicesFactory

================
File: src/services/protocols/HttpGet.js
================
import axios from 'axios'
import grapoi from 'grapoi'
import ns from '../../utils/ns.js'
import footpath from '../../utils/footpath.js'
import logger from '../../utils/Logger.js'
import ProcessService from '../base/ProcessService.js'
class HttpGet extends ProcessService {
    constructor(config) {
        super(config)
    }
    async execute(url, message) {
        if (url === '~~done~~') {
            logger.log('HG DONE*****************')
            this.emit('message', url, message)
            return
        }
        try {
            logger.log('HG GETTING*****************')
            const response = await axios.get(url)
            const content = response.data
            message.sourceURL = url
            this.emit('message', content, message)
        } catch (error) {
            logger.error("HttpGet.execute error\n" + error)
        }
    }
}
export default HttpGet

================
File: src/services/protocols/ProtocolsServicesFactory.js
================
import logger from '../../utils/Logger.js'
import ns from '../../utils/ns.js'
import HttpGet from './HttpGet.js'
class ProtocolsServicesFactory {
    static createService(type, config) {
        if (type.equals(ns.t.HttpGet)) {
            return new HttpGet(config)
        }
        return false
    }
}
export default ProtocolsServicesFactory

================
File: src/services/rdf/ConfigMap.js
================
import ns from '../../utils/ns.js'
import rdf from 'rdf-ext'
import grapoi from 'grapoi'
import footpath from '../../utils/footpath.js'
import logger from '../../utils/Logger.js'
import ProcessService from '../base/ProcessService.js'
class ConfigMap extends ProcessService {
  constructor(config) {
    super(config)
  }
  async execute(message) {
    this.preProcess(message)
    const dataset = message.dataset
    const poi = grapoi({ dataset, factory: rdf })
    const quads = await poi.out(ns.rdf.type).quads()
    for (const q of quads) {
      const type = q.object
      if (type.equals(ns.pc.ContentGroup)) {
        await this.processContentGroup(message, q.subject)
      }
    }
    this.emit('message', message)
  }
  async processContentGroup(message, contentGroupID) {
    switch (contentGroupID.value) {
      case ns.t.PostContent.value:
        await this.markdownToEntryContent(message, contentGroupID)
        return
      case ns.t.PostPages.value:
        await this.entryContentToPostPage(message, contentGroupID)
        return
      case ns.t.IndexPage.value:
        await this.indexPage(message, contentGroupID)
        return
      default:
        logger.log('Group not found in dataset :' + contentGroupID.value)
        return
    }
  }
  async markdownToEntryContent(message, contentGroupID) {
    const postcraftConfig = message.dataset
    const groupPoi = rdf.grapoi({ dataset: postcraftConfig, term: contentGroupID })
    const siteURL = groupPoi.out(ns.pc.site).term.value
    message.siteURL = siteURL
    const subdir = groupPoi.out(ns.pc.subdir).term.value
    message.subdir = subdir
    const sourceDir = groupPoi.out(ns.fs.sourceDirectory).term.value
    const targetDir = groupPoi.out(ns.fs.targetDirectory).term.value
    const templateFilename = groupPoi.out(ns.pc.template).term.value
    message.filepath = templateFilename
    message.template = '§§§ placeholer for debugging §§§'
    message.entryContentMeta = {
      sourceDir: sourceDir,
      targetDir: targetDir,
      templateFilename: templateFilename
    }
  }
  async entryContentToPostPage(message, contentGroupID) {
    const postcraftConfig = message.dataset
    const groupPoi = rdf.grapoi({ dataset: postcraftConfig, term: contentGroupID })
    const targetDir = groupPoi.out(ns.fs.targetDirectory).term.value
    const templateFilename = groupPoi.out(ns.pc.template).term.value
    message.entryContentToPage = {
      targetDir: targetDir,
      templateFilename: templateFilename
    }
  }
  async indexPage(message, contentGroupID) {
    const postcraftConfig = message.dataset
    const groupPoi = rdf.grapoi({ dataset: postcraftConfig, term: contentGroupID })
    const quads = await groupPoi.out().quads()
    for (const q of quads) {
    }
    const filepath = groupPoi.out(ns.fs.filepath).term.value
    const templateFilename = groupPoi.out(ns.pc.template).term.value
    message.indexPage = {
      filepath: filepath,
      templateFilename: templateFilename
    }
  }
}
export default ConfigMap

================
File: src/services/rdf/ContextReader.js
================
import rdf from 'rdf-ext'
import { fromFile, toFile } from 'rdf-utils-fs'
import SourceService from '../base/SourceService.js'
import logger from '../../utils/Logger.js'
class ContextReader extends SourceService {
    constructor(config) {
        super(config)
    }
    getInputKeys() {
        return ['sdfsdf']
    }
    getOutputKeys() {
        return ['sdfsdfsdfdataset']
    }
    async execute(message) {
        this.preProcess(message)
        const manifestFilename = message.rootDir + '/manifest.ttl'
        const stream = fromFile(manifestFilename)
        message.dataset = await rdf.dataset().import(stream)
        this.emit('message', message)
    }
}
export default ContextReader

================
File: src/services/rdf/RDFServicesFactory.js
================
import ns from '../../utils/ns.js'
import ContextReader from './ContextReader.js'
import ConfigMap from './ConfigMap.js'
class RDFServicesFactory {
    static createService(type, config) {
        if (type.equals(ns.t.ContextReader)) {
            return new ContextReader(config)
        }
        if (type.equals(ns.t.ConfigMap)) {
            return new ConfigMap(config)
        }
        return false
    }
}
export default RDFServicesFactory

================
File: src/services/test/AppendProcess.js
================
import logger from '../../utils/Logger.js'
import ProcessService from '../base/ProcessService.js'
class AppendProcess extends ProcessService {
    async execute(input, message) {
        logger.debug("AppendProcess data : " + input)
        let output = input + " world"
        this.emit('message', output, message)
    }
}
export default AppendProcess

================
File: src/services/test/FileSink.js
================
import path from 'path'
import { fileURLToPath } from 'url'
import { writeFile } from 'node:fs/promises';
import footpath from '../../utils/footpath.js'
import grapoi from 'grapoi'
import ns from '../../utils/ns.js'
import logger from '../../utils/Logger.js'
import SinkService from '../base/SinkService.js'
class FileSink extends SinkService {
    constructor(config) {
        super(config)
        const dataset = this.config
        const poi = grapoi({ dataset })
        this.destinationFile = poi.out(ns.trm.destinationFile).value
    }
    async execute(message) {
        const toRootDir = '../../../'
        const dataDir = path.join(toRootDir, message.dataDir)
        const df = footpath.resolve(import.meta.url, dataDir, this.destinationFile)
        logger.debug("FileSink to = " + df)
        await writeFile(df, data)
        this.emit('message', message)
    }
}
export default FileSink

================
File: src/services/test/FileSource.js
================
import path from 'path'
import { fileURLToPath } from 'url'
import { readFile } from 'node:fs/promises'
import footpath from '../../utils/footpath.js'
import rdf from 'rdf-ext'
import grapoi from 'grapoi'
import ns from '../../utils/ns.js'
import logger from '../../utils/Logger.js'
import SourceService from '../base/SourceService.js'
class FileSource extends SourceService {
    constructor(config) {
        super(config)
        const dataset = this.config
        const poi = grapoi({ dataset })
        this.sourceFile = poi.out(ns.trm.sourceFile).value
    }
    async execute(message) {
        try {
            const toRootDir = '../../../'
            const dataDir = toRootDir + message.dataDir
            const sf = footpath.resolve(import.meta.url, dataDir, this.sourceFile)
            logger.debug('FileSource file : ' + sf)
            const contents = await readFile(sf, { encoding: 'utf8' })
            logger.debug('FileSource data : ' + contents)
            this.emit('message', contents, message)
        } catch (err) {
            logger.error("FileSource.execute error : " + err.message)
        }
    }
}
export default FileSource

================
File: src/services/test/StringSink.js
================
import logger from '../../utils/Logger.js'
import SinkService from '../base/SinkService.js'
class StringSink extends SinkService {
    execute(message) {
        logger.log("\n\nStringSink outputs : \"" + data + "\"\n\n")
    }
}
export default StringSink

================
File: src/services/test/StringSource.js
================
import SourceService from '../base/SourceService.js'
class StringSource extends SourceService {
    constructor(config) {
        super(config)
    }
    async execute(message) {
        console.log("message = " + message)
        console.log("data = " + data)
        this.emit('message', message)
    }
}
export default StringSource

================
File: src/services/test/TestServicesFactory.js
================
import logger from '../../utils/Logger.js'
import ns from '../../utils/ns.js'
import StringSource from './StringSource.js'
import StringSink from './StringSink.js'
import AppendProcess from './AppendProcess.js'
import FileSource from './FileSource.js'
import FileSink from './FileSink.js'
class TestServicesFactory {
    static createService(type, config) {
        if (type.equals(ns.t.StringSource)) {
            return new StringSource(config)
        }
        if (type.equals(ns.t.StringSink)) {
            return new StringSink(config)
        }
        if (type.equals(ns.t.AppendProcess)) {
            return new AppendProcess(config)
        }
        if (type.equals(ns.t.FileSource)) {
            return new FileSource(config)
        }
        if (type.equals(ns.t.FileSink)) {
            return new FileSink(config)
        }
        return false
    }
}
export default TestServicesFactory

================
File: src/services/text/LineReader.js
================
import { readFile } from 'node:fs/promises'
import grapoi from 'grapoi'
import ns from '../../utils/ns.js'
import footpath from '../../utils/footpath.js'
import logger from '../../utils/Logger.js'
import ProcessService from '../base/ProcessService.js'
class LineReader extends ProcessService {
    constructor(config) {
        super(config)
    }
    async execute(message) {
        const text = data.toString()
        const lines = text.split('\n')
        for await (let line of lines) {
            if (line.trim() && !line.startsWith('#')) {
                logger.debug('Line = [[[' + line + ']]]')
                this.emit('message', line, message)
            }
        }
        this.emit('message', '~~done~~', message)
    }
}
export default LineReader

================
File: src/services/text/StringFilter.js
================
import logger from '../../utils/Logger.js'
import ProcessService from '../base/Service.js'
class StringFilter extends ProcessService {
    constructor(config) {
        super(config)
        this.reject = ['mailto:', 'example.org', 'wikipedia', 'wikimedia']
    }
    async execute(message) {
        logger.debug('StringFilter data = ' + data.toString())
        if (this.containsAny(data.toString(), this.reject)) return
        this.emit('message', message)
    }
    containsAny(contentString, matchers) {
        const contains = matchers.some(matcher => contentString.includes(matcher))
        console.log(contentString, contains)
        return contains
    }
}
export default StringFilter

================
File: src/services/text/StringMerger.js
================
import logger from '../../utils/Logger.js'
import ProcessService from '../base/ProcessService.js'
class StringMerger extends ProcessService {
    constructor(config) {
        super(config)
        this.merged = ''
    }
    async execute(message) {
        logger.log('SMDATA*********************************\n' + data)
        if (data === '~~done~~') {
            logger.log('SM  DONE**********************************\n' + this.merged)
            this.emit('message', this.merged, message)
            return
        }
        this.merged = this.merged + data
    }
}
export default StringMerger

================
File: src/services/text/Templater copy.js
================
import ProcessService from '../base/ProcessService.js'
import nunjucks from 'nunjucks'
import logger from '../../utils/Logger.js'
class Templater extends ProcessService {
    constructor(config) {
        super(config)
    }
    async execute(message) {
        if (message.templateFilename) {
            const path = message.templateFilename.substr(0, message.templateFilename.lastIndexOf("/"))
            const filename = message.templateFilename.substr(message.templateFilename.lastIndexOf("/") + 1)
            nunjucks.configure(path, { autoescape: false })
            message.content = nunjucks.render(filename, message.contentBlocks)
        } else {
            nunjucks.configure({ autoescape: false });
            message.content = nunjucks.renderString(message.template, message.contentBlocks)
        }
        this.emit('message', message)
    }
}
export default Templater

================
File: src/services/text/Templater.js
================
import ProcessService from '../base/ProcessService.js'
import nunjucks from 'nunjucks'
import logger from '../../utils/Logger.js'
class Templater extends ProcessService {
    constructor(config) {
        super(config)
    }
    async execute(message) {
        if (message.templateFilename) {
            const path = message.templateFilename.substr(0, message.templateFilename.lastIndexOf("/"))
            const filename = message.templateFilename.substr(message.templateFilename.lastIndexOf("/") + 1)
            nunjucks.configure(path, { autoescape: false })
            message.content = nunjucks.render(filename, message.contentBlocks)
        } else {
            nunjucks.configure({ autoescape: false });
            message.content = nunjucks.renderString(message.template, message.contentBlocks)
        }
        this.emit('message', message)
    }
}
export default Templater

================
File: src/services/text/TextServicesFactory.js
================
import logger from '../../utils/Logger.js'
import ns from '../../utils/ns.js'
import LineReader from './LineReader.js'
import StringFilter from './StringFilter.js'
import StringMerger from './StringMerger.js'
import Templater from './Templater.js'
class TextServicesFactory {
    static createService(type, config) {
        if (type.equals(ns.t.Templater)) {
            return new Templater(config)
        }
        if (type.equals(ns.t.LineReader)) {
            return new LineReader(config)
        }
        if (type.equals(ns.t.StringFilter)) {
            return new StringFilter(config)
        }
        if (type.equals(ns.t.StringMerger)) {
            return new StringMerger(config)
        }
        return false
    }
}
export default TextServicesFactory

================
File: src/services/unsafe/chatgpt.md
================
User
What different ways of creating instances of classes in node js, including the esoteric ones?
ChatGPT
Creating instances of classes in Node.js primarily revolves around using the `new` operator with constructor functions or class definitions. However, there are several techniques, including some less commonly used (or esoteric) methods, to instantiate objects. Here's an overview:

### 1. Standard Instantiation with `new`

The most common method involves defining a class or constructor function and using the `new` keyword to create instances.

```javascript
class MyClass {
  constructor(name) {
    this.name = name;
  }
}

const instance = new MyClass("Example");
```

### 2. Factory Functions

Factory functions return a new object and can encapsulate the use of `new` internally or return object literals directly.

```javascript
function createInstance(name) {
  return new MyClass(name);
}
const instance = createInstance("Example");
```

### 3. Object.create()

`Object.create(proto[, propertiesObject])` creates a new object with the specified prototype object and properties.

```javascript
const prototype = {
  sayName() {
    console.log(this.name);
  },
};
const instance = Object.create(prototype);
instance.name = "Example";
```

### 4. Calling Constructor without `new` (Esoteric)

Using the constructor directly without `new` is not standard for creating instances and usually results in errors or unexpected behavior. However, some constructors might internally manage instantiation to allow this.

```javascript
function MyClass(name) {
  if (!(this instanceof MyClass)) {
    return new MyClass(name);
  }
  this.name = name;
}

const instance = MyClass("Example"); // Works due to internal handling
```

### 5. Clone Existing Instance

Creating a new instance by cloning an existing one, although not creating a fresh instance in the strictest sense, serves to produce a new object.

```javascript
const original = new MyClass("Original");
const clone = Object.assign(
  Object.create(Object.getPrototypeOf(original)),
  original
);
```

### 6. Deserialization

Creating an instance from a string representation, typically used in conjunction with serialization.

```javascript
const serialized = '{"name":"Example"}'; // Could be the result of JSON.stringify(instance)
const instance = Object.assign(new MyClass(), JSON.parse(serialized));
```

### 7. Function.prototype.bind()

You can set the `this` value in the constructor function, allowing for partial application or setting certain initial parameters ahead of time.

```javascript
function MyClass(name, message) {
  this.name = name;
  this.message = message;
}

const PreConfigured = MyClass.bind(null, "PreConfiguredName");
const instance = new PreConfigured("Hello World");
```

### 8. Proxy for Constructor (Esoteric)

Using a `Proxy` to intercept and customize the instantiation process.

```javascript
const MyClassProxy = new Proxy(MyClass, {
  construct(target, args) {
    console.log("MyClass instantiated with args:", args);
    return new target(...args);
  },
});

const instance = new MyClassProxy("Example");
```

These methods showcase the flexibility of object creation in JavaScript and Node.js, ranging from straightforward and common practices to more unusual and esoteric approaches. Each has its use cases, depending on the requirements for flexibility, pattern use, and object initialization specifics.
User
If all the object needs is a distinct name 'MyClass', the ability to set the value of a property 'config' in a constructor-like function where properties will be set, and a function execute(data) which returns a processed version of data, what is the minimum code necessary? Could these objects be create with something like a const instance = create('MyName') kind of function?
ChatGPT
For a minimal implementation that meets the specified requirements, you can use a factory function to create instances. Each instance needs a distinct name (`MyClass`), the ability to set the value of a `config` property in a constructor-like function, and an `execute(data)` method that returns a processed version of the data. Here's a concise way to accomplish this:

```javascript
function createInstance(name) {
  return {
    name: name,
    config: null,
    execute(data) {
      // Process and return the data
      // This example simply returns the data as-is; replace with actual processing logic
      return data;
    },
    setConfig(config) {
      this.config = config;
    },
  };
}

// Example usage:
const instance = createInstance("MyName");
instance.setConfig({ key: "value" }); // Setting the config
console.log(instance.execute("some data")); // Executing and processing data
```

This approach uses a simple object literal inside the `createInstance` factory function to define the necessary properties and methods. Each created instance will have its own `name`, `config`, and `execute` method, as per the requirements.

- `name` is assigned based on the argument passed to `createInstance`.
- `config` can be set using the `setConfig` method, which simulates constructor-like behavior for setting initial properties.
- `execute(data)` method is defined to process and return data. You can replace the placeholder logic with actual data processing as needed.

This solution provides a lightweight and flexible way to create instances with the desired functionality, following your example of a `create('MyName')` style function call.
User
Could the execute function be created from a string?
ChatGPT
Yes, the `execute` function can be created from a string using the `new Function()` constructor. This method allows you to dynamically create a function from a string of JavaScript code. Here's how you could modify the previous example to include an `execute` function created from a string:

```javascript
function createInstance(name, executeFunctionString) {
  return {
    name: name,
    config: null,
    execute: new Function("data", executeFunctionString),
    setConfig(config) {
      this.config = config;
    },
  };
}

// Example usage:
const executeCode = 'return data + " processed";'; // String of code for the execute function
const instance = createInstance("MyName", executeCode);
instance.setConfig({ key: "value" }); // Setting the config

console.log(instance.execute("some data")); // Outputs: "some data processed"
```

In this example, the `executeFunctionString` parameter is passed to `new Function('data', executeFunctionString)`, where `'data'` is the name of the argument that the function will receive, and `executeFunctionString` is the body of the function. This dynamically created function is then assigned to the `execute` property of the object returned by `createInstance`.

**Note of Caution:** Using `new Function()` to create functions from strings poses similar risks to `eval()` in terms of security and performance:

- **Security Risk:** If the string is derived from user input or an untrusted source, it could potentially introduce security vulnerabilities, such as code injection attacks.
- **Debugging Difficulty:** Debugging can be more challenging because the dynamically generated code may not be as readily traceable in debugging tools.
- **Performance:** The JavaScript engine can't optimize these functions as well as it can for statically declared functions.

Always validate and sanitize any input if you choose to use this approach, and consider whether the dynamic nature of function creation is necessary for your use case.
User
In RS6, can imports be done inside functions?
ChatGPT
In ES6 (ECMAScript 2015), the standard import syntax (`import ... from '...'`) cannot be used conditionally or inside functions, blocks, or any other statements that are not at the top level of a module. The ES6 `import` statements are static and must be at the top level of your JavaScript file or module, allowing for these imports to be statically analyzed by JavaScript engines and bundlers.

However, you can dynamically import modules using the `import()` function, which returns a promise. This feature is not part of ES6, but it was added later in the ES2020 (ECMAScript 11) specification. The `import()` function can be used inside functions, conditionals, loops, or anywhere you can execute a function. It is useful for lazy-loading modules only when they are needed, which can improve the performance of your application by reducing the initial load time.

Here's an example of how to use dynamic imports within a function:

```javascript
async function loadModuleDynamically() {
  const moduleName = "./myModule.js"; // The module path
  const module = await import(moduleName);
  module.myFunction(); // Use a function from the imported module
}

loadModuleDynamically().then(() => {
  console.log("Module loaded and function executed");
});
```

In this example, `import(moduleName)` dynamically imports the module specified by `moduleName`, and because `import()` returns a promise, you can use `await` within an async function to wait for the module to be loaded before using it.

This approach provides flexibility for loading modules based on conditions, user actions, or any logic that requires modules to be loaded dynamically at runtime.
User
How could you check at runtime to see if import() was supported?
ChatGPT
To check at runtime whether dynamic `import()` is supported, you can use a feature detection approach. This involves attempting to use `import()` with a data URI or a no-op (no operation) module and catching any errors if the feature is not supported. Since `import()` returns a promise, you can use a try-catch block within an asynchronous function to perform this check. Here's how you could implement it:

```javascript
async function supportsDynamicImport() {
  try {
    // Attempt to dynamically import a module using a no-op or data URI
    // For actual deployment, a more reliable check with a real module path may be preferable
    await new Function('return import("data:text/javascript;base64,Cg==")')();
    return true; // Dynamic import is supported
  } catch (error) {
    return false; // Dynamic import is not supported
  }
}

// Example usage
supportsDynamicImport().then((isSupported) => {
  if (isSupported) {
    console.log("Dynamic import is supported");
  } else {
    console.log("Dynamic import is not supported");
  }
});
```

This function works by dynamically creating a function that attempts to `import` a base64-encoded empty JavaScript module. If the browser or environment supports dynamic imports, this operation will succeed, and the function will return `true`. If not, the operation will throw an exception, and the function will return `false`.

Note: The use of `new Function()` allows this check to not cause a syntax error in environments that do not recognize `import()` syntax at all, as the `import()` call is within a string and not directly in the JavaScript code being parsed.

This method provides a straightforward way to determine the availability of dynamic imports, allowing you to conditionally implement fallback logic or alternative module loading strategies if necessary.
User
Can imports go in eval() strings?
ChatGPT
Using `import` statements directly within `eval()` strings in JavaScript does not work in the same way as using them at the top level of modules or through dynamic `import()` expressions. The static `import` statement is part of the module syntax and expected to be statically analyzable at the top level of module files, not dynamically executed within function bodies, `eval()`, or similar constructs.

However, dynamic imports using `import()` can be used within `eval()` because `import()` is a function that returns a promise. This allows for dynamically importing modules even in messages where static import statements are not syntactically valid. Here's an example:

```javascript
eval('import("./module.js").then(module => { console.log(module); })');
```

This uses `eval()` to dynamically execute a string that contains a dynamic import statement. Note that this approach does indeed work, but it combines two powerful and potentially risky features of JavaScript: `eval()` and dynamic imports. Both should be used cautiously because:

- `eval()` can execute arbitrary code, which poses significant security risks, especially with untrusted input. It's also generally slower and harder to debug compared to other methods of executing JavaScript.
- Dynamic imports can introduce complexity to your module loading strategy and potentially impact performance negatively if not used judyiciously.

Given these considerations, while you can use dynamic `import()` within `eval()` strings, it's essential to carefully assess whether this approach is necessary and ensure that the code being evaluated is from a trusted source to avoid security vulnerabilities.

================
File: src/services/util/DeadEnd.js
================
import logger from '../../utils/Logger.js'
import Service from '../base/Service.js'
class DeadEnd extends Service {
    async execute(message) {
        logger.log('DeadEnd  at (' + message.tags + ') ' + this.getTag())
    }
}
export default DeadEnd

================
File: src/services/util/Fork.js
================
import logger from '../../utils/Logger.js'
import Service from '../base/Service.js'
import ns from '../../utils/ns.js'
import rdf from 'rdf-ext'
import grapoi from 'grapoi'
class Fork extends Service {
    constructor(config) {
        super(config)
    }
    async execute(data, baseContext) {
        for (let i = 0; i < 5; i++) {
            var message = this.cloneContext(baseContext)
            message.done = false
            logger.log('--- emit --- ' + i)
            this.emit('message', message)
        }
        var message = this.cloneContext(baseContext)
        message.done = true
        this.emit('message', message)
    }
}
export default Fork

================
File: src/services/util/Halt.js
================
import logger from '../../utils/Logger.js'
import Service from '../base/Service.js'
class Halt extends Service {
    execute(message) {
        logger.log('\n************************************************************************')
        logger.log('*** << Thou Hast Summoned HALT, the Mighty Stopper of All Things  >> ***')
        logger.log('*** <<                   ~~~ ALL IS GOOD ~~~                      >> ***')
        logger.log('*** <<                     Have a nice day!                       >> ***')
        logger.log('************************************************************************\n')
        logger.log('*** Pipeline was : ' + message.tags)
        logger.log('*** Context now : ')
        logger.reveal(message)
        process.exit()
    }
}
export default Halt

================
File: src/services/util/NOP.js
================
import logger from '../../utils/Logger.js'
import Service from '../base/Service.js'
class NOP extends Service {
    async execute(message) {
        logger.log('NOP at (' + message.tags + ') ' + this.getTag())
        this.emit('message', message)
    }
    double(string) {
        return string + string
    }
}
export default NOP

================
File: src/services/util/RemapContext.js
================
import logger from '../../utils/Logger.js'
import rdf from 'rdf-ext'
import ns from '../../utils/ns.js'
import GrapoiHelpers from '../../utils/GrapoiHelpers.js'
import Service from '../base/Service.js'
class RemapContext extends Service {
    constructor(config) {
        super(config)
    }
    async execute(message) {
        if (this.preProcess(message)) {
            return
        }
        logger.log('RemapContext this.configKey = ' + this.configKey.value)
        const renames = GrapoiHelpers.listToArray(this.config, this.configKey, ns.trm.rename)
        const dataset = this.config
        for (let i = 0; i < renames.length; i++) {
            let rename = renames[i]
            let poi = rdf.grapoi({ dataset: dataset, term: rename })
            let pre = poi.out(ns.trm.pre).value
            let post = poi.out(ns.trm.post).value
            var value
            if (pre.includes('.')) {
                const spre = pre.split('.')
                logger.log('pre- split = ' + spre)
                value = message[spre[0]][spre[1]]
            } else {
                value = message[pre]
            }
            value = value.toString()
            if (post.includes('.')) {
                const s = post.split('.')
                logger.log('post split = ' + s)
                message[s[0]][s[1]] = value
            } else {
                message[post] = value
            }
            logger.log(' - Rename : ' + pre + ' to ' + post)
        }
        this.emit('message', message)
    }
}
export default RemapContext

================
File: src/services/util/ShowMessage.js
================
import logger from '../../utils/Logger.js'
import SinkService from '../base/SinkService.js'
class ShowMessage extends SinkService {
    constructor(config) {
        super(config)
        this.verbose = false
    }
    async execute(message) {
        if (this.verbose) logger.log("\n***  Show Message ***")
        logger.log("***************************")
        logger.log("***  Context")
        logger.reveal(message)
        logger.log("***************************")
        this.emit('message', message)
    }
}
export default ShowMessage

================
File: src/services/util/ShowTransmission.js
================
import logger from '../../utils/Logger.js'
import Service from '../base/Service.js'
class ShowTransmission extends Service {
    async execute(message) {
        logger.log(this.transmission.toString())
        this.emit('message', message)
    }
}
export default ShowTransmission

================
File: src/services/util/Stash.js
================
import rdf from 'rdf-ext'
import { fromFile, toFile } from 'rdf-utils-fs'
import SourceService from '../base/SourceService.js'
class Stash extends SourceService {
    constructor(config) {
        super(config)
    }
    async execute(message) {
        const manifestFilename = rootDir + '/manifest.ttl'
        const stream = fromFile(manifestFilename)
        message.rootDir = rootDir
        message.dataset = await rdf.dataset().import(stream)
        this.emit('message', message)
    }
}
export default Stash

================
File: src/services/util/Unfork.js
================
import logger from '../../utils/Logger.js'
import Service from '../base/Service.js'
import ns from '../../utils/ns.js'
import rdf from 'rdf-ext'
import grapoi from 'grapoi'
import DeadEnd from './DeadEnd.js'
class Unfork extends Service {
    constructor(config) {
        super(config)
    }
    async execute(message) {
        if (message.done) {
            logger.log(' - Unfork passing message')
            message.done = false
            this.emit('message', message)
        } else {
            logger.log(' - Unfork terminating pipe')
        }
    }
}
export default Unfork

================
File: src/services/util/UtilServicesFactory.js
================
import logger from '../../utils/Logger.js'
import ns from '../../utils/ns.js'
import NOP from './NOP.js'
import DeadEnd from './DeadEnd.js'
import ShowMessage from './ShowMessage.js'
import Halt from './Halt.js'
import RemapContext from './RemapContext.js'
import Unfork from './Unfork.js'
import Fork from './Fork.js'
import ShowTransmission from './ShowTransmission.js'
class UtilServicesFactory {
    static createService(type, config) {
        if (type.equals(ns.t.NOP)) {
            return new NOP(config)
        }
        if (type.equals(ns.t.DeadEnd)) {
            return new DeadEnd(config)
        }
        if (type.equals(ns.t.ShowMessage)) {
            return new ShowMessage(config)
        }
        if (type.equals(ns.t.Halt)) {
            return new Halt(config)
        }
        if (type.equals(ns.t.RemapContext)) {
            return new RemapContext(config)
        }
        if (type.equals(ns.t.Fork)) {
            return new Fork(config)
        }
        if (type.equals(ns.t.Unfork)) {
            return new Unfork(config)
        }
        if (type.equals(ns.t.ShowTransmission)) {
            return new ShowTransmission(config)
        }
        return false
    }
}
export default UtilServicesFactory

================
File: src/utils/GrapoiHelpers.js
================
import rdf from 'rdf-ext'
import grapoi from 'grapoi'
import { fromFile, toFile } from 'rdf-utils-fs'
import ns from './ns.js'
import logger from './Logger.js'
class GrapoiHelpers {
    static async readDataset(filename) {
        const stream = fromFile(filename)
        const dataset = await rdf.dataset().import(stream)
        return dataset
    }
    static async writeDataset(dataset, filename) {
        await toFile(dataset.toStream(), filename)
    }
    static listToArray(dataset, term, property) {
        const poi = rdf.grapoi({ dataset: dataset, term: term })
        const first = poi.out(property).term
        let p = rdf.grapoi({ dataset, term: first })
        let object = p.out(ns.rdf.first).term
        const result = [object]
        while (true) {
            let restHead = p.out(ns.rdf.rest).term
            let p2 = rdf.grapoi({ dataset, term: restHead })
            let object = p2.out(ns.rdf.first).term
            logger.log('restHead = ' + restHead.value)
            if (restHead.equals(ns.rdf.nil)) break
            result.push(object)
            p = rdf.grapoi({ dataset, term: restHead })
        }
        return result
    }
    static listObjects(dataset, subjectList, predicate) {
        const objects = []
        for (const subject of subjectList) {
            logger.log("subject = " + subject.value)
            let p = rdf.grapoi({ dataset, term: subject })
            let object = p.out(predicate).term
            logger.log("object = " + object.value)
            objects.push(object)
        }
        return objects
    }
}
export default GrapoiHelpers

================
File: src/utils/Logger.js
================

import fs from 'fs'
let logger = {}
logger.logfile = 'latest.log'
const LOG_LEVELS = [
    "debug",
    "info",
    "log",
    "warn",
    "error",
];
const logComponent = "api.logger";
logger.appendLogToFile = function (message) {
    if (logger.logfile) {
        fs.appendFileSync(logger.logfile, message + '\n', 'utf8');
    }
}
logger.setLogLevel = function (logLevel = "warn") {
    console[logLevel]("[%s] log level: %s", logComponent, logLevel);
    let limit = LOG_LEVELS.indexOf(logLevel);
    LOG_LEVELS.filter(function (level, index) {
        if (index < limit) {
            console[logLevel]("[%s] disabling console.%s()", logComponent, level);
            console[level] = function () { }
        }
    });
};
logger.timestampISO = function () {
    let now = new Date();
    return now.toISOString();
};
logger.log = function (msg, level = "log") {
    console[level](msg)
    const logMessage = `[${logger.timestampISO()}] [${level.toUpperCase()}] - ${msg}`
    logger.appendLogToFile(logMessage)
}
logger.reveal = function (instance) {
    const serialized = {};
    for (const key in instance) {
        if (key === 'dataset') {
            serialized[key] = instance[key].toString()
        } else {
            if (instance.hasOwnProperty(key)) {
                let kiki = instance[key]
                if (Buffer.isBuffer(kiki)) {
                    kiki = kiki.toString()
                }
                if (kiki.length > 100) {
                    kiki = kiki.substring(0, 100) + '...'
                }
                serialized[key] = kiki
            }
        }
    }
    const props = JSON.stringify(serialized, null, 2)
    logger.log(`Instance of ${instance.constructor.name} with properties - \n${props}`)
}
logger.debug = function (msg) {
    logger.log(msg, "debug");
}
logger.info = function (msg) {
    logger.log(msg, "info");
}
logger.warn = function (msg) {
    logger.log(msg, "warn");
}
logger.error = function (msg) {
    logger.log(msg, "error");
}
logger.poi = function exploreGrapoi(grapoi, predicates, objects, subjects) {
    console.log('Properties of the Grapoi object:');
    for (const prop in grapoi) {
        console.log(`\t${prop}: ${grapoi[prop]}`);
    }
    console.log('\nPath:');
    const path = grapoi.out(predicates, objects).in(predicates, subjects);
    for (const quad of path.quads()) {
        console.log(`\t${quad.predicate.value}: ${quad.object.value}`);
    }
}
function handleExit(options, exitCode) {
    if (options.cleanup) {
    }
    if (exitCode || exitCode === 0) console.log(exitCode);
    if (options.exit) process.exit();
}
process.on('exit', handleExit.bind(null, { cleanup: true }));
process.on('SIGINT', handleExit.bind(null, { exit: true }));
process.on('SIGUSR1', handleExit.bind(null, { exit: true }));
process.on('SIGUSR2', handleExit.bind(null, { exit: true }));
process.on('uncaughtException', handleExit.bind(null, { exit: true }));
export default logger;

================
File: src/utils/footpath.js
================
import path from 'path'
import { fileURLToPath } from 'url'
import logger from './Logger.js'
let footpath = {}
footpath.resolve = function footpath(here, relative, start) {
    const loggy = false
    if (loggy) {
        logger.debug("\n*** start footpath.resolve ***")
        logger.debug("process.cwd() = " + process.cwd())
        logger.debug("here = " + here)
        logger.debug("relative = " + relative)
        logger.debug("start = " + start)
    }
    const __filename = fileURLToPath(here)
    const __dirname = path.dirname(__filename)
    const rootDir = path.resolve(__dirname, relative)
    const filePath = path.join(rootDir, start)
    if (loggy) {
        logger.debug("__filename = " + __filename)
        logger.debug("__dirname = " + __dirname)
        logger.debug("rootDir = " + rootDir)
        logger.debug("filePath = " + filePath)
        logger.debug("*** end footpath.resolve ***\n")
    }
    return filePath
}
footpath.urlLastPart = function footpath(url) {
    const urlObj = new URL(url);
    const hash = urlObj.hash;
    const path = urlObj.pathname;
    const lastPart = hash ? hash.replace(/^#/, '') : path.split('/').pop();
    return lastPart;
}
export default footpath

================
File: src/utils/ns.js
================
import rdf from 'rdf-ext'
const ns = {
    rdf: rdf.namespace('http://www.w3.org/1999/02/22-rdf-syntax-ns#'),
    dc: rdf.namespace('http://purl.org/dc/terms/'),
    schema: rdf.namespace('http://schema.org/'),
    xsd: rdf.namespace('http://www.w3.org/2001/XMLSchema#'),
    trm: rdf.namespace('http://purl.org/stuff/transmission/'),
    t: rdf.namespace('http://hyperdata.it/transmissions/'),
    fs: rdf.namespace('http://purl.org/stuff/filesystem/'),
    pc: rdf.namespace('http://purl.org/stuff/postcraft/')
}
export default ns

================
File: src/utils/t2j.js
================

import { Readable } from 'readable-stream'
import rdf from '@rdfjs/data-model'
import SerializerJsonld from '@rdfjs/serializer-jsonld'
import Serializer from '@rdfjs/serializer-turtle'
import N3Parser from '@rdfjs/parser-n3'
import { fromFile } from 'rdf-utils-fs'
import { toFile } from 'rdf-utils-fs'
const testTurtle = `
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix trm: <http://purl.org/stuff/transmission/> .
@prefix : <https://hyperdata.it/transmissions/> . # for custom terms & instances
:simplepipe a trm:PipelineTransmission ;
    trm:pipe (:s1 :s2 :s3) .
:s1 a trm:StringSource .
:s2 a trm:AppendProcess .
:s3 a trm:StringSink .
`
export class Turtle2JSONLD {
    static async convert(turtle) {
        let parser = new N3Parser({ factory: rdf })
        const input = Readable.from(turtle)
        const output = parser.import(input)
        const serializerJsonld = new SerializerJsonld()
        const jsonStream = serializerJsonld.import(output)
        const outputJson = await Turtle2JSONLD.streamToString(jsonStream)
        return outputJson
    }
    static stringToStream(str) {
        const stream = new Readable();
        stream.push(str);
        stream.push(null);
        return stream;
    }
    static streamToString(stream) {
        const chunks = [];
        return new Promise((resolve, reject) => {
            stream.on('data', (chunk) => {
                chunks.push(Buffer.from(chunk))
                console.log('chunk:', chunk)
            }
            );
            stream.on('error', (err) => reject(err));
            stream.on('end', () => {
                const result = Buffer.concat(chunks).toString('utf8')
                resolve(result)
                console.log('****************** result:', result)
            });
        })
    }
}
const testJson = await Turtle2JSONLD.convert(testTurtle)
console.log('àààààààààààààààààààààà')
console.log(testJson)

================
File: src/utils/test_runner.js
================
import fs from 'fs';
import path from 'path';
const testFiles = fs.readdirSync(__dirname).filter(file => file.startsWith('test_'));
testFiles.forEach(testFile => {
    console.log(`Running ${testFile}`);
    require(path.join(__dirname, testFile));
});

================
File: tests/grapoi-raw-tests.js
================
import { namedNode, literal } from '@rdfjs/data-model';
import { Grapoi } from '@grapoi';
import { Term } from '@rdfjs/types';
describe('Grapoi', () => {
    let grapoi;
    beforeEach(() => {
        grapoi = new Grapoi();
    });
    describe('.addList', () => {
        it('should return a Grapoi instance', () => {
            const predicates: Term[] = [namedNode('https://housemd.rdf-ext.org/person/allison-cameron'), namedNode('http://schema.org/knows')];
            const items: Term[] = [namedNode('https://housemd.rdf-ext.org/person/robert-chase')];
            const result = grapoi.addList(predicates, items);
            expect(result).toBeInstanceOf(Grapoi);
        });
    });
});
import { namedNode, literal } from '@rdfjs/data-model';
import { Grapoi } from '@grapoi';
import { Term } from '@rdfjs/types';
describe('Grapoi', () => {
    let grapoi;
    beforeEach(() => {
        grapoi = new Grapoi();
    });
    describe('.addList', () => {
        it('should return a Grapoi instance', () => {
            const predicates: Term[] = [namedNode('https://housemd.rdf-ext.org/person/allison-cameron'), namedNode('http://schema.org/knows')];
            const items: Term[] = [namedNode('https://housemd.rdf-ext.org/person/robert-chase')];
            const result = grapoi.addList(predicates, items);
            expect(result).toBeInstanceOf(Grapoi);
        });
    });
    describe('.addOut', () => {
        it('should return a Grapoi instance', () => {
            const predicates: Term[] = [namedNode('https://housemd.rdf-ext.org/person/allison-cameron'), namedNode('http://schema.org/knows')];
            const objects: Term[] = [namedNode('https://housemd.rdf-ext.org/person/robert-chase')];
            const result = grapoi.addOut(predicates, objects);
            expect(result).toBeInstanceOf(Grapoi);
        });
    });
});
describe('.base', () => {
    it('should return a Grapoi instance', () => {
        const base: Term = namedNode('https://housemd.rdf-ext.org/person/allison-cameron');
        const result = grapoi.base(base);
        expect(result).toBeInstanceOf(Grapoi);
    });
});
import { namedNode, literal } from '@rdfjs/data-model';
import { Path } from '@grapoi';
import { Term } from '@rdfjs/types';
describe('Path', () => {
    let path;
    beforeEach(() => {
        path = new Path();
    });
    describe('.addList', () => {
        it('should return a Path instance', () => {
            const predicates: Term[] = [namedNode('https://housemd.rdf-ext.org/person/allison-cameron'), namedNode('http://schema.org/knows')];
            const items: Term[] = [namedNode('https://housemd.rdf-ext.org/person/robert-chase')];
            const result = path.addList(predicates, items);
            expect(result).toBeInstanceOf(Path);
        });
    });
});
import { namedNode, literal } from '@rdfjs/data-model';
import { PathList } from '@grapoi';
import { Term } from '@rdfjs/types';
describe('PathList', () => {
    let pathList;
    beforeEach(() => {
        pathList = new PathList();
    });
    describe('.addList', () => {
        it('should return a PathList instance', () => {
            const predicates: Term[] = [namedNode('https://housemd.rdf-ext.org/person/allison-cameron'), namedNode('http://schema.org/knows')];
            const items: Term[] = [namedNode('https://housemd.rdf-ext.org/person/robert-chase')];
            const result = pathList.addList(predicates, items);
            expect(result).toBeInstanceOf(PathList);
        });
    });
});
describe('.addOut', () => {
    it('should return a Path instance', () => {
        const predicates: Term[] = [namedNode('https://housemd.rdf-ext.org/person/allison-cameron'), namedNode('http://schema.org/knows')];
        const objects: Term[] = [namedNode('https://housemd.rdf-ext.org/person/robert-chase')];
        const result = path.addOut(predicates, objects);
        expect(result).toBeInstanceOf(Path);
    });
});
describe('.addOut', () => {
    it('should return a PathList instance', () => {
        const predicates: Term[] = [namedNode('https://housemd.rdf-ext.org/person/allison-cameron'), namedNode('http://schema.org/knows')];
        const objects: Term[] = [namedNode('https://housemd.rdf-ext.org/person/robert-chase')];
        const result = pathList.addOut(predicates, objects);
        expect(result).toBeInstanceOf(PathList);
    });
});
describe('.deleteIn', () => {
    it('should return a Path instance', () => {
        const predicates: Term[] = [namedNode('https://housemd.rdf-ext.org/person/allison-cameron'), namedNode('http://schema.org/knows')];
        const result = path.deleteIn(predicates);
        expect(result).toBeInstanceOf(Path);
    });
});
describe('.deleteIn', () => {
    it('should return a PathList instance', () => {
        const predicates: Term[] = [namedNode('https://housemd.rdf-ext.org/person/allison-cameron'), namedNode('http://schema.org/knows')];
        const result = pathList.deleteIn(predicates);
        expect(result).toBeInstanceOf(PathList);
    });
});

================
File: tests/helpers/reporter.js
================
import { SpecReporter } from 'jasmine-spec-reporter';
class CustomReporter {
    constructor() {
        this.specReporter = new SpecReporter({
            spec: {
                displayPending: true
            }
        });
    }
    jasmineStarted() {
        this.specReporter.jasmineStarted.apply(this.specReporter, arguments);
    }
    suiteStarted() {
        this.specReporter.suiteStarted.apply(this.specReporter, arguments);
    }
    specStarted() {
        this.specReporter.specStarted.apply(this.specReporter, arguments);
    }
    specDone() {
        this.specReporter.specDone.apply(this.specReporter, arguments);
    }
    suiteDone() {
        this.specReporter.suiteDone.apply(this.specReporter, arguments);
    }
    jasmineDone() {
        this.specReporter.jasmineDone.apply(this.specReporter, arguments);
    }
}
export default CustomReporter;

================
File: tests/integration/file-pipeline.spec.js
================
import footpath from '../../src/utils/footpath.js'
import path from 'path'
import { fileURLToPath } from 'url'
import { expect } from 'chai'
import { exec } from 'child_process'
import fs from 'fs'
describe('file-pipeline', function () {
    const __filename = fileURLToPath(import.meta.url);
    const __dirname = path.dirname(__filename)
    const rootDir = path.resolve(__dirname, '../../')
    const dataFile = footpath.resolve(import.meta.url, '../../src/applications/file-pipeline/data/', 'output.txt')
    console.log('in file-pipeline.spec.js dataFile = ' + dataFile)
    it('produces correct output', function (done) {
        if (fs.existsSync(dataFile)) {
            fs.unlinkSync(dataFile);
        }
        exec('node run.js file-pipeline', (error, stdout, stderr) => {
            if (error) {
                console.error(`exec error: ${error}`);
                return;
            }
            fs.readFile(dataFile, 'utf8', (err, data) => {
                if (err) {
                    console.error(`readFile error: ${err}`);
                    return;
                }
                expect(data.trim()).to.equal('Hello world world');
                done();
            });
        });
    });
});

================
File: tests/integration/string-pipeline.speeec.js
================
import { expect } from 'chai'
import { exec } from 'child_process'
describe('string-pipeline', function () {
    it('produces correct output', function (done) {
        exec('node run.js string-pipeline Hello', (error, stdout, stderr) => {
            if (error) {
                console.error(`exec error: ${error}`);
                return;
            }
            const match = stdout.match(/"([^"]+)"/)
            const output = match ? match[1] : ''
            expect(output).to.equal('Hello world world')
            done();
        });
    });
});

================
File: tests/unit/NOP.spec.js
================
import NOP from '../../src/services/util/NOP.js'
import { expect } from 'chai'
describe('NOP', function () {
    it('double() should return the input string concatenated with itself', function () {
        const nop = new NOP()
        const input = 'test'
        const expectedOutput = 'testtest'
        const output = nop.double(input)
        expect(output).to.equal(expectedOutput)
    })
})

================
File: tests/unit/PostcraftPrep.spec.js
================
import PostcraftPrep from '../../src/services/postcraft/PostcraftPrep.js'
import { expect } from 'chai'
describe('PostcraftPrep', function () {
    beforeEach(function () {
        this.context = {
            content: 'only text',
            filename: 'minimal-filename.md'
        }
    })
    it('extractTitle(context) should lift the title from the filename', function () {
        this.context.filename = '2024-05-10_this-thing.md'
        const input = this.context
        const expectedOutput = 'This Thing'
        const pp = new PostcraftPrep()
        const output = pp.extractTitle(input)
        expect(output).to.equal(expectedOutput)
    })
    it('extractName(context) should return filename without path and extension', function () {
        this.context.filename = '2024-05-10_hello-postcraft.md'
        const input = this.context
        const expectedOutput = '2024-05-10_hello-postcraft.html'
        const pp = new PostcraftPrep()
        const output = pp.extractName(input)
        expect(output).to.equal(expectedOutput)
    })
    it('extractTargetFilename(context) should return the correct target filename', function () {
        this.context.filename = '2024-05-10_hello-postcraft.md'
        this.context.rootDir = '/root'
        this.context.targetDir = '/target'
        const input = this.context
        const expectedOutput = '/root/target/2024-05-10_hello-postcraft.html'
        const pp = new PostcraftPrep()
        const output = pp.extractTargetFilename(input)
        expect(output).to.equal(expectedOutput)
    })
    it('extractLink(context) should return the correct link', function () {
        this.context.filename = '2024-05-10_hello-postcraft.md'
        this.context.targetDir = 'target'
        const input = this.context
        const expectedOutput = '/target/2024-05-10_hello-postcraft.html'
        const pp = new PostcraftPrep()
        const output = pp.extractLink(input)
        expect(output).to.equal(expectedOutput)
    })
    it('extractDates(context) should return the correct dates', function () {
        this.context.filename = '2024-05-10_hello-postcraft.md'
        const input = this.context
        const expectedOutput = { created: '2024-05-10', updated: (new Date()).toISOString().split('T')[0] }
        const pp = new PostcraftPrep()
        const output = pp.extractDates(input)
        expect(output).to.deep.equal(expectedOutput)
    })
})

================
File: types/grapoi.d.ts
================
import { DatasetCore, Quad, Term } from "@rdfjs/types";
interface Grapoi extends PathList {
    addList(predicates: Term | Term[], items: Term | Term[]): Grapoi;
    addOut(predicates: Term | Term[], objects: Term | Term[], callback?: Function): Grapoi;
    base(base: Term | Term[]): Grapoi;
}
interface Edge {
    dataset: DatasetCore;
    end: string;
    quad: Quad;
    start: string;
    term: Term;
    graph: Term;
    startTerm: Term;
}
interface Instruction {
    operation?: string;
    quantifier?: string;
    start?: string;
    end?: string;
    subjects?: Term[];
    predicates?: Term[];
    objects?: Term[];
    graphs?: DatasetCore[];
    items?: Term[];
    callback?: (edge: Edge, ptr: Path | PathList) => Path | PathList;
}
interface Path {
    addList(predicates: Term | Term[], items: Term | Term[]): Path;
    addOut(predicates: Term | Term[], objects: Term | Term[], callback?: Function): Path;
    deleteIn(predicates: Term | Term[], subjects: Term | Term[]): Path;
    deleteList(predicates: Term | Term[]): Path;
    deleteOut(predicates: Term | Term[], objects: Term | Term[]): Path;
    extend(edge: Edge): Path;
    execute(instruction: Instruction): Path;
}
interface PathList {
    addList(predicates: Term | Term[], items: Term | Term[]): PathList;
    addOut(predicates: Term | Term[], objects: Term | Term[], callback?: Function): PathList;
    deleteIn(predicates: Term | Term[], subjects: Term | Term[]): PathList;
    deleteList(predicates: Term | Term[]): PathList;
    deleteOut(predicates: Term | Term[], objects: Term | Term[]): PathList;
    distinct(): PathList;
    in(predicates: Term | Term[], subjects: Term | Term[]): PathList;
    isAny(): boolean;
    isList(): boolean;
    list(): Iterator<Term> | undefined;
    map(callback: Function): PathList[];
    out(predicates: Term | Term[], objects: Term | Term[]): PathList;
    quads(): Iterator<Quad>;
    execute(instruction: Instruction): PathList[];
}

================
File: unfork.txt
================
[api.logger] log level: info
[api.logger] disabling console.debug()

+ ***** Load Config ******
[Transmission : src/applications/postcraft/transmission.ttl]
[Config : src/applications/postcraft/services.ttl]

+ ***** Construct *****
| Create service <http://hyperdata.it/transmissions/s1> of type <http://hyperdata.it/transmissions/ContextReader>
| Create service <http://hyperdata.it/transmissions/s2> of type <http://hyperdata.it/transmissions/ConfigMap>
| Create service <http://hyperdata.it/transmissions/s3> of type <http://hyperdata.it/transmissions/FileReader>
| Create service <http://hyperdata.it/transmissions/s4> of type <http://hyperdata.it/transmissions/RemapContext>
| Create service <http://hyperdata.it/transmissions/s5> of type <http://hyperdata.it/transmissions/DirWalker>
| Create service <http://hyperdata.it/transmissions/s6> of type <http://hyperdata.it/transmissions/FileReader>
| Create service <http://hyperdata.it/transmissions/s7> of type <http://hyperdata.it/transmissions/PostcraftPrep>
| Create service <http://hyperdata.it/transmissions/s8> of type <http://hyperdata.it/transmissions/MarkdownToHTML>
| Create service <http://hyperdata.it/transmissions/s9> of type <http://hyperdata.it/transmissions/RemapContext>
| Create service <http://hyperdata.it/transmissions/s10> of type <http://hyperdata.it/transmissions/Templater>
| Create service <http://hyperdata.it/transmissions/s11> of type <http://hyperdata.it/transmissions/FileWriter>
| Create service <http://hyperdata.it/transmissions/s12> of type <http://hyperdata.it/transmissions/EntryContentToPagePrep>
| Create service <http://hyperdata.it/transmissions/s13> of type <http://hyperdata.it/transmissions/Templater>
| Create service <http://hyperdata.it/transmissions/s14> of type <http://hyperdata.it/transmissions/FileWriter>
| Create service <http://hyperdata.it/transmissions/s15> of type <http://hyperdata.it/transmissions/Unfork>
| Create service <http://hyperdata.it/transmissions/s16> of type <http://hyperdata.it/transmissions/FrontPagePrep>
  > Connect #0 [http://hyperdata.it/transmissions/s1] => [http://hyperdata.it/transmissions/s2]
  > Connect #1 [http://hyperdata.it/transmissions/s2] => [http://hyperdata.it/transmissions/s3]
  > Connect #2 [http://hyperdata.it/transmissions/s3] => [http://hyperdata.it/transmissions/s4]
  > Connect #3 [http://hyperdata.it/transmissions/s4] => [http://hyperdata.it/transmissions/s5]
  > Connect #4 [http://hyperdata.it/transmissions/s5] => [http://hyperdata.it/transmissions/s6]
  > Connect #5 [http://hyperdata.it/transmissions/s6] => [http://hyperdata.it/transmissions/s7]
  > Connect #6 [http://hyperdata.it/transmissions/s7] => [http://hyperdata.it/transmissions/s8]
  > Connect #7 [http://hyperdata.it/transmissions/s8] => [http://hyperdata.it/transmissions/s9]
  > Connect #8 [http://hyperdata.it/transmissions/s9] => [http://hyperdata.it/transmissions/s10]
  > Connect #9 [http://hyperdata.it/transmissions/s10] => [http://hyperdata.it/transmissions/s11]
  > Connect #10 [http://hyperdata.it/transmissions/s11] => [http://hyperdata.it/transmissions/s12]
  > Connect #11 [http://hyperdata.it/transmissions/s12] => [http://hyperdata.it/transmissions/s13]
  > Connect #12 [http://hyperdata.it/transmissions/s13] => [http://hyperdata.it/transmissions/s14]
  > Connect #13 [http://hyperdata.it/transmissions/s14] => [http://hyperdata.it/transmissions/s15]
  > Connect #14 [http://hyperdata.it/transmissions/s15] => [http://hyperdata.it/transmissions/s16]

+ ***** Execute *****
| Running : http://hyperdata.it/transmissions/s1 a ContextReader
| Running :  (s1) s2 a ConfigMap
§§§§§§§§§§ contentGroupID http://hyperdata.it/transmissions/PostContent
*****************+ sourceDir = test
templateFilename  = layouts/mediocre/templates/entry-content_template.njk
§§§§§§§§§§ contentGroupID http://hyperdata.it/transmissions/PostPages
| Running :  (s1.s2) s3 a FileReader
 - FileReader reading filepath : layouts/mediocre/templates/entry-content_template.njk
| Running :  (s1.s2.s3) s4 a RemapContext
 - Rename : content to template
| Running :  (s1.s2.s3.s4) s5 a DirWalker
| Running :  (s1.s2.s3.s4.s5) s6 a FileReader
 - FileReader reading filepath : test/2024-05-03_one.md
| Running :  (s1.s2.s3.s4.s5) s6 a FileReader
| Running :  (s1.s2.s3.s4.s5) s6 a FileReader
| Running :  (s1.s2.s3.s4.s5.s6) s7 a PostcraftPrep
| Running :  (s1.s2.s3.s4.s5.s6.s7) s8 a MarkdownToHTML
| Running :  (s1.s2.s3.s4.s5.s6.s7.s8) s9 a RemapContext
 - Rename : targetFilename to filepath
 - Rename : content to contentBlocks.content
| Running :  (s1.s2.s3.s4.s5.s6.s7.s8.s9) s10 a Templater
| Running :  (s1.s2.s3.s4.s5.s6.s7.s8.s9.s10) s11 a FileWriter
 - FileReader reading filepath : test/2024-05-03_two.md
 - FileWriter writing : /home/danny/HKMS/postcraft/danny.ayers.name/public/entry-content-cache/2024-05-03_one.html
| Running :  (s1.s2.s3.s4.s5.s6) s7 a PostcraftPrep
| Running :  (s1.s2.s3.s4.s5.s6.s7) s8 a MarkdownToHTML
| Running :  (s1.s2.s3.s4.s5.s6.s7.s8) s9 a RemapContext
| Running :  (s1.s2.s3.s4.s5.s6.s7.s8.s9) s10 a Templater
| Running :  (s1.s2.s3.s4.s5.s6.s7.s8.s9.s10) s11 a FileWriter
 - FileReader reading filepath : test/2024-05-03_two.md
| Running :  (s1.s2.s3.s4.s5.s6.s7.s8.s9.s10.s11) s12 a EntryContentToPagePrep
| Running :  (s1.s2.s3.s4.s5.s6.s7.s8.s9.s10.s11.s12) s13 a Templater
| Running :  (s1.s2.s3.s4.s5.s6.s7.s8.s9.s10.s11.s12.s13) s14 a FileWriter
 - FileWriter writing : /home/danny/HKMS/postcraft/danny.ayers.name/public/blog/2024-05-03_one.html
 - FileWriter writing : test/2024-05-03_two.md
| Running :  (s1.s2.s3.s4.s5.s6) s7 a PostcraftPrep
| Running :  (s1.s2.s3.s4.s5.s6.s7) s8 a MarkdownToHTML
| Running :  (s1.s2.s3.s4.s5.s6.s7.s8) s9 a RemapContext
| Running :  (s1.s2.s3.s4.s5.s6.s7.s8.s9) s10 a Templater
| Running :  (s1.s2.s3.s4.s5.s6.s7.s8.s9.s10) s11 a FileWriter
| Running :  (s1.s2.s3.s4.s5.s6.s7.s8.s9.s10.s11.s12.s13.s14) s15 a Unfork
 - Unfork terminating pipe
| Running :  (s1.s2.s3.s4.s5.s6.s7.s8.s9.s10.s11) s12 a EntryContentToPagePrep
| Running :  (s1.s2.s3.s4.s5.s6.s7.s8.s9.s10.s11.s12) s13 a Templater
| Running :  (s1.s2.s3.s4.s5.s6.s7.s8.s9.s10.s11.s12.s13) s14 a FileWriter
 - FileWriter writing : test/2024-05-03_two.md
 - FileWriter writing : test/2024-05-03_two.md
| Running :  (s1.s2.s3.s4.s5.s6.s7.s8.s9.s10.s11.s12.s13.s14) s15 a Unfork
 - Unfork passing message
| Running :  (s1.s2.s3.s4.s5.s6.s7.s8.s9.s10.s11.s12.s13.s14.s15) s16 a FrontPagePrep
| Running :  (s1.s2.s3.s4.s5.s6.s7.s8.s9.s10.s11) s12 a EntryContentToPagePrep
| Running :  (s1.s2.s3.s4.s5.s6.s7.s8.s9.s10.s11.s12) s13 a Templater
| Running :  (s1.s2.s3.s4.s5.s6.s7.s8.s9.s10.s11.s12.s13) s14 a FileWriter
 - FileWriter writing : test/2024-05-03_two.md
| Running :  (s1.s2.s3.s4.s5.s6.s7.s8.s9.s10.s11.s12.s13.s14) s15 a Unfork
 - Unfork passing message
| Running :  (s1.s2.s3.s4.s5.s6.s7.s8.s9.s10.s11.s12.s13.s14.s15) s16 a FrontPagePrep
0

================
File: vocabs/dbooth-pipeline.n3.txt
================
# Ontology and inference rules used in describing an RDF data pipeline.
# See http://dbooth.org/2011/pipeline/

@prefix p: <http://purl.org/pipeline/ont#> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .

######### Basic Node types ##########
p:Node		a rdfs:Class .
p:CommandNode	rdfs:subClassOf p:Node .  # Default Node type
p:JenaNode      rdfs:subClassOf p:Node .
p:SesameNode    rdfs:subClassOf p:Node .
p:PerlNode      rdfs:subClassOf p:Node .
p:MysqlNode	rdfs:subClassOf p:Node .
p:OracleNode	rdfs:subClassOf p:Node .

######### Node properties ##########
p:inputs 	rdfs:domain p:Node .
p:parameters 	rdfs:domain p:Node .
p:dependsOn 	rdfs:domain p:Node .

# p:output specifies the output cache for a node.
# It is node-type-specific, e.g., filename for FileNode .
# It may be set explicitly, otherwise a default will be used.
p:output	rdfs:domain p:Node .

# p:updater specifies the updater method for a Node.
# It is node-type-specific, e.g., a script for CommandNode .
p:updater	rdfs:domain p:Node .

# p:updaterType specifies the type of updater used.
# It is node-type-specific.
p:updaterType	rdfs:domain p:Node .

######### Rules ##########
# A Node dependsOn its inputs and parameters:
{ ?a p:inputs ?b . }     => { ?a p:dependsOn ?b . } .
{ ?a p:parameters ?b . } => { ?a p:dependsOn ?b . } .

================
File: vocabs/info-store.rdf
================
<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
    xmlns:rdfs="http://www.w3.org/2000/01/rdf-schema#" xmlns:owl="http://www.w3.org/2002/07/owl#">

    <owl:Ontology rdf:about="http://rdflib.net/2002/InformationStore">
        <rdfs:label>InformationStore</rdfs:label>
        <rdfs:comment>A document defining a vocabulary used by an InformationStore, a TripleStore
            with support for multiple contexts.</rdfs:comment>
        <rdfs:isDefinedBy rdf:resource="http://rdflib.net/2002/InformationStore" />
    </owl:Ontology>

    <rdfs:Class rdf:about="http://rdflib.net/2002/InformationStore#Context">
        <rdfs:label>Context</rdfs:label>
        <rdfs:subClassOf rdf:resource="http://www.w3.org/2000/01/rdf-schema#Resource" />
        <rdfs:isDefinedBy rdf:resource="http://rdflib.net/2002/InformationStore" />
    </rdfs:Class>

    <rdfs:Class rdf:about="http://rdflib.net/2002/InformationStore#UpdateEvent">
        <rdfs:label>An Event for updating a Context</rdfs:label>
        <rdfs:subClassOf rdf:resource="http://www.w3.org/2000/01/rdf-schema#Resource" />
        <rdfs:isDefinedBy rdf:resource="http://rdflib.net/2002/InformationStore" />
    </rdfs:Class>

    <rdf:Property rdf:about="http://rdflib.net/2002/InformationStore#source">
        <rdfs:label>source</rdfs:label>
        <rdfs:domain rdf:resource="http://www.w3.org/2000/01/rdf-schema#Resource" />
        <rdfs:range rdf:resource="http://www.w3.org/2000/01/rdf-schema#Resource" />
        <rdfs:isDefinedBy rdf:resource="http://rdflib.net/2002/InformationStore" />
    </rdf:Property>

    <rdf:Property rdf:about="http://rdflib.net/2002/InformationStore#updateEvent">
        <rdfs:label>update event</rdfs:label>
        <rdfs:domain rdf:resource="http://www.w3.org/2000/01/rdf-schema#Context" />
        <rdfs:range rdf:resource="http://www.w3.org/2000/01/rdf-schema#UpdateEvent" />
        <rdfs:isDefinedBy rdf:resource="http://rdflib.net/2002/InformationStore" />
    </rdf:Property>

    <rdf:Property rdf:about="http://rdflib.net/2002/InformationStore#error">
        <rdfs:label>Error</rdfs:label>
        <rdfs:comment>This property is used to capture information about errors that occured while
            updating the context.</rdfs:comment>
        <rdfs:domain rdf:resource="http://www.w3.org/2000/01/rdf-schema#UpdateEvent" />
        <rdfs:range rdf:resource="http://www.w3.org/2000/01/rdf-schema#Literal" />
        <rdfs:isDefinedBy rdf:resource="http://rdflib.net/2002/InformationStore" />
    </rdf:Property>

    <rdf:Property rdf:about="http://rdflib.net/2002/InformationStore#http_status">
        <rdfs:label>http status</rdfs:label>
        <rdfs:comment>This property is used for the http status that was returned when updating the
            context.</rdfs:comment>
        <rdfs:domain rdf:resource="http://www.w3.org/2000/01/rdf-schema#UpdateEvent" />
        <rdfs:range rdf:resource="http://www.w3.org/2000/01/rdf-schema#Literal" />
        <rdfs:isDefinedBy rdf:resource="http://rdflib.net/2002/InformationStore" />
    </rdf:Property>

</rdf:RDF>

================
File: vocabs/info-store.ttl
================
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix owl: <http://www.w3.org/2002/07/owl#> .

<http://rdflib.net/2002/InformationStore>
    a owl:Ontology ;
    rdfs:comment """A document defining a vocabulary used by an InformationStore, a TripleStore
            with support for multiple contexts.""" ;
    rdfs:isDefinedBy <http://rdflib.net/2002/InformationStore> ;
    rdfs:label "InformationStore" .

<http://rdflib.net/2002/InformationStore#Context>
    a rdfs:Class ;
    rdfs:isDefinedBy <http://rdflib.net/2002/InformationStore> ;
    rdfs:label "Context" ;
    rdfs:subClassOf rdfs:Resource .

<http://rdflib.net/2002/InformationStore#UpdateEvent>
    a rdfs:Class ;
    rdfs:isDefinedBy <http://rdflib.net/2002/InformationStore> ;
    rdfs:label "An Event for updating a Context" ;
    rdfs:subClassOf rdfs:Resource .

<http://rdflib.net/2002/InformationStore#error>
    a rdf:Property ;
    rdfs:comment """This property is used to capture information about errors that occured while
            updating the context.""" ;
    rdfs:domain rdfs:UpdateEvent ;
    rdfs:isDefinedBy <http://rdflib.net/2002/InformationStore> ;
    rdfs:label "Error" ;
    rdfs:range rdfs:Literal .

<http://rdflib.net/2002/InformationStore#http_status>
    a rdf:Property ;
    rdfs:comment """This property is used for the http status that was returned when updating the
            context.""" ;
    rdfs:domain rdfs:UpdateEvent ;
    rdfs:isDefinedBy <http://rdflib.net/2002/InformationStore> ;
    rdfs:label "http status" ;
    rdfs:range rdfs:Literal .

<http://rdflib.net/2002/InformationStore#source>
    a rdf:Property ;
    rdfs:domain rdfs:Resource ;
    rdfs:isDefinedBy <http://rdflib.net/2002/InformationStore> ;
    rdfs:label "source" ;
    rdfs:range rdfs:Resource .

<http://rdflib.net/2002/InformationStore#updateEvent>
    a rdf:Property ;
    rdfs:domain rdfs:Context ;
    rdfs:isDefinedBy <http://rdflib.net/2002/InformationStore> ;
    rdfs:label "update event" ;
    rdfs:range rdfs:UpdateEvent .

================
File: vocabs/notes.md
================
---

- [specgen-ng](https://github.com/danja/specgen-ng)

rapper -o turtle email.rdf > email.ttl

cd /home/danny/HKMS/specgen-ng

mkdir spec/email

danny@danny-desktop:~/HKMS/transmissions/src$ cd /home/danny/foaf-archive/vocabs/
danny@danny-desktop:~/foaf-archive/vocabs$ mkdir email

python src/specgenng.py \
 --indir=/home/danny/foaf-archive/vocabs/email/ \
 --ns=http://www.w3.org/2000/04/maillog2rdf/email# \
 --prefix=email \
 --ontofile=email.ttl \
 --templatedir=template \
 --outdir=/home/danny/foaf-archive/vocabs/email/ \
 --outfile=email.html

grr, not enough input

email_danja_2024-03-16.ttl

rapper -i turtle -o rdfxml email_danja_2024-03-16.ttl > email_danja_2024-03-16.rdf

python src/specgenng.py \
 --indir=/home/danny/foaf-archive/vocabs/email/ \
 --ns=http://www.w3.org/2000/04/maillog2rdf/email# \
 --prefix=email \
 --ontofile=email_danja_2024-03-16.rdf \
 --templatedir=template \
 --outdir=/home/danny/foaf-archive/vocabs/email/ \
 --outfile=email.html

================
File: vocabs/slug-config.rdf
================
<?xml version='1.0'?>
<rdf:RDF  
  xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
  xmlns:scutter="http://www.hackdiary.com/scutter/" 
  xmlns:rdfs="http://www.w3.org/2000/01/rdf-schema#" 
  xmlns:dc="http://purl.org/dc/elements/1.1/"
  xmlns:slug="http://purl.org/NET/schemas/slug/config/">  

   <rdf:Description rdf:about="">
      <dc:title>Slug Configuration File</dc:title>
      <dc:description>
Configuration File for the Slug Semantic Web Crawler. Used to define crawler profiles 
with different worker, memory, consumer and filter configurations.
      </dc:description>      
   </rdf:Description>
   
   <!-- select config from cmd-line parameter -->
   
   <slug:Scutter rdf:about="default">
	 <dc:description>A default Scutter configuration</dc:description>
	 
	 <!-- configure global memory -->
     <slug:hasMemory rdf:resource="memory"/>

	 <!-- how many worker threads -->
     <slug:workers>10</slug:workers>

     <!-- configures consumers for incoming data -->
	 <slug:consumers>
	   <rdf:Seq>
	    <rdf:li rdf:resource="storer"/>
	    <rdf:li rdf:resource="rdf-consumer"/>	    
	   </rdf:Seq>	   
	 </slug:consumers>
	
	 <!-- configures filter pipeline for controller -->
	 <slug:filters>
	   <rdf:Seq>
	     <rdf:li rdf:resource="single-fetch-filter"/>	     	   
	     <rdf:li rdf:resource="depth-filter"/>
	     <rdf:li rdf:resource="regex-filter"/>	     
	   </rdf:Seq>
	 </slug:filters> 	 
	 
   </slug:Scutter>

   <slug:Scutter rdf:about="shallow-slow-scutter">
	 <dc:description>A Scutter which crawls only a shallow depth, with 
	 fewer workers</dc:description>

     <slug:hasMemory rdf:resource="memory"/>
     <!-- fewer workers, so slower -->
     <slug:workers>3</slug:workers>

	 <!-- standard consumer components -->
	 <slug:consumers>
	   <rdf:Seq>
	    <rdf:li rdf:resource="storer"/>
	    <rdf:li rdf:resource="rdf-consumer"/>	    
	   </rdf:Seq>	   
	 </slug:consumers>
	
	 <!-- alternate filters, using shallow-depth-filter -->
	 <slug:filters>
	   <rdf:Seq>
	     <rdf:li rdf:resource="single-fetch-filter"/>	     	   
	     <rdf:li rdf:resource="shallow-depth-filter"/>
	     <rdf:li rdf:resource="regex-filter"/>	     
	   </rdf:Seq>
	 </slug:filters> 	 
	 
   </slug:Scutter>

   <slug:Scutter rdf:about="mapping-scutter">
	 <dc:description>A Scutter which simply discovers and maps 
	 connections between files using source/origin properties in 
	 its memory</dc:description>

     <slug:hasMemory rdf:resource="memory"/>
     <slug:workers>10</slug:workers>

	 <!-- standard consumer components -->
	 <slug:consumers>
	   <rdf:Seq>
	    <rdf:li rdf:resource="rdf-consumer"/>	    
	   </rdf:Seq>	   
	 </slug:consumers>
	
	 <!-- alternate filters, using shallow-depth-filter -->
	 <slug:filters>
	   <rdf:Seq>
	     <rdf:li rdf:resource="single-fetch-filter"/>	     	   
	     <rdf:li rdf:resource="deep-depth-filter"/> 
	   </rdf:Seq>
	 </slug:filters> 	 
	 
   </slug:Scutter>

   <slug:Scutter rdf:about="persistent-scutter">
	 <dc:description>A Scutter that includes writing incoming data into 
	 a persistent memory. Note that the memory is different to that 
	 holdings Scutter persistent state.</dc:description>
	 
     <slug:hasMemory rdf:resource="memory"/>

	 <!-- how many worker threads? -->
     <slug:workers>10</slug:workers>

     <!-- configures consumers for incoming data. Added persistent-storer -->
	 <slug:consumers>
	   <rdf:Seq>
	    <rdf:li rdf:resource="storer"/>
	    <rdf:li rdf:resource="rdf-consumer"/>	    
	    <rdf:li rdf:resource="persistent-storer"/>	    	    
	   </rdf:Seq>	   
	 </slug:consumers>
	
	 <!-- configures filter pipeline for controller -->
	 <slug:filters>
	   <rdf:Seq>
	     <rdf:li rdf:resource="single-fetch-filter"/>	     	   
	     <rdf:li rdf:resource="depth-filter"/>
	     <rdf:li rdf:resource="regex-filter"/>	     
	   </rdf:Seq>
	 </slug:filters> 	 
	 
   </slug:Scutter>
   
   <slug:Scutter rdf:about="cache-builder">
	 <dc:description>Builds a local cache of fetched data, doesn't 
	 traverse RDF links to discover new resources.</dc:description>
	 
     <slug:hasMemory rdf:resource="memory"/>

	 <!-- how many worker threads? -->
     <slug:workers>10</slug:workers>

     <!-- configures consumers for incoming data -->
	 <slug:consumers>
	   <rdf:Seq>
	    <rdf:li rdf:resource="storer"/>
	   </rdf:Seq>	   
	 </slug:consumers>
		 
   </slug:Scutter>   
   
   <slug:Consumer rdf:about="storer">
     <dc:title>ResponseStorer</dc:title>
     <dc:description>Stores HTTP responses in a file system cache</dc:description>
   
     <slug:impl>com.ldodds.slug.http.ResponseStorer</slug:impl>
     <!-- must be a directory, will get created automatically if it doesn't exist -->
     <slug:cache>c:\temp\slug-cache</slug:cache>
   </slug:Consumer>

   <slug:Consumer rdf:about="persistent-storer">
     <dc:title>Database-backed ResponseStorer</dc:title>
     <dc:description>Stores HTTP responses in Jena persistent model</dc:description>
     <slug:impl>com.ldodds.slug.http.PersistentResponseStorer</slug:impl>
     <!-- must be reference to a Memory -->
     <slug:hasMemory rdf:resource="db-memory"/>
   </slug:Consumer>

   <slug:Consumer rdf:about="rdf-consumer">
     <dc:title>RDFConsumer</dc:title>
     <dc:description>Discovers seeAlso links in RDF models and adds them to task list</dc:description>
     <slug:impl>com.ldodds.slug.http.RDFConsumer</slug:impl>
   </slug:Consumer>

   <slug:Filter rdf:about="depth-filter">
     <dc:title>Limit Depth of Crawling</dc:title>
	 <slug:impl>com.ldodds.slug.http.DepthFilter</slug:impl>
	 <!-- if depth >= this then url not included. Initial depth is 0 -->
	 <slug:depth>3</slug:depth>
   </slug:Filter>

   <slug:Filter rdf:about="deep-depth-filter">
     <dc:title>Limit Depth of Crawling</dc:title>
	 <slug:impl>com.ldodds.slug.http.DepthFilter</slug:impl>
	 <!-- if depth >= this then url not included. Initial depth is 0 -->
	 <slug:depth>5</slug:depth>
   </slug:Filter>
   
   <slug:Filter rdf:about="shallow-depth-filter">
     <dc:title>Limit Depth of Crawling</dc:title>
	 <slug:impl>com.ldodds.slug.http.DepthFilter</slug:impl>
	 <!-- if depth >= this then url not included. Initial depth is 0 -->
	 <slug:depth>1</slug:depth>
   </slug:Filter>
   
   <slug:Filter rdf:about="regex-filter">
     <dc:title>Block URLs based on Regex</dc:title>
	 <slug:impl>com.ldodds.slug.http.RegexFilter</slug:impl>
	 <!-- regular expression, if matches, then url not included -->
	 <slug:filter>livejournal</slug:filter>
   </slug:Filter>

   <slug:Filter rdf:about="single-fetch-filter">
     <dc:title>Avoid Loops</dc:title>
	 <slug:impl>com.ldodds.slug.http.SingleFetchFilter</slug:impl>
   </slug:Filter>         
   
   <slug:Memory rdf:about="memory">
     <slug:file>memory.rdf</slug:file>
   </slug:Memory>

   <slug:Memory rdf:about="db-memory">
     <!-- name of the persistent model -->
     <slug:modelURI rdf:resource="CHANGEME"/>
     
     <!-- JDBC URL for database -->     
     <slug:dbURL>jdbc:mysql://localhost/CHANGEME</slug:dbURL>
     
     <!-- database username and password -->
     <slug:user>CHANGEME</slug:user>
     <slug:pass>CHANGEME</slug:pass>
     
     <!-- Jena Database Engine name -->
     <slug:dbName>MySQL</slug:dbName>
     
     <!-- JDBC Driver -->
     <slug:driver>com.mysql.jdbc.Driver</slug:driver>
     
   </slug:Memory>
   
</rdf:RDF>

================
File: vocabs/slug-config.ttl
================
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix scutter: <http://www.hackdiary.com/scutter/> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix dc: <http://purl.org/dc/elements/1.1/> .
@prefix slug: <http://purl.org/NET/schemas/slug/config/> .

<file:///home/danny/HKMS/transmissions/vocabs/cache-builder>
    slug:consumers [
        rdf:_1 <file:///home/danny/HKMS/transmissions/vocabs/storer> ;
        a rdf:Seq
    ] ;
    slug:hasMemory <file:///home/danny/HKMS/transmissions/vocabs/memory> ;
    slug:workers "10" ;
    dc:description """Builds a local cache of fetched data, doesn't 
	 traverse RDF links to discover new resources.""" ;
    a slug:Scutter .

<file:///home/danny/HKMS/transmissions/vocabs/db-memory>
    slug:dbName "MySQL" ;
    slug:dbURL "jdbc:mysql://localhost/CHANGEME" ;
    slug:driver "com.mysql.jdbc.Driver" ;
    slug:modelURI <file:///home/danny/HKMS/transmissions/vocabs/CHANGEME> ;
    slug:pass "CHANGEME" ;
    slug:user "CHANGEME" ;
    a slug:Memory .

<file:///home/danny/HKMS/transmissions/vocabs/deep-depth-filter>
    slug:depth "5" ;
    slug:impl "com.ldodds.slug.http.DepthFilter" ;
    dc:title "Limit Depth of Crawling" ;
    a slug:Filter .

<file:///home/danny/HKMS/transmissions/vocabs/default>
    slug:consumers [
        rdf:_1 <file:///home/danny/HKMS/transmissions/vocabs/storer> ;
        rdf:_2 <file:///home/danny/HKMS/transmissions/vocabs/rdf-consumer> ;
        a rdf:Seq
    ] ;
    slug:filters [
        rdf:_1 <file:///home/danny/HKMS/transmissions/vocabs/single-fetch-filter> ;
        rdf:_2 <file:///home/danny/HKMS/transmissions/vocabs/depth-filter> ;
        rdf:_3 <file:///home/danny/HKMS/transmissions/vocabs/regex-filter> ;
        a rdf:Seq
    ] ;
    slug:hasMemory <file:///home/danny/HKMS/transmissions/vocabs/memory> ;
    slug:workers "10" ;
    dc:description "A default Scutter configuration" ;
    a slug:Scutter .

<file:///home/danny/HKMS/transmissions/vocabs/depth-filter>
    slug:depth "3" ;
    slug:impl "com.ldodds.slug.http.DepthFilter" ;
    dc:title "Limit Depth of Crawling" ;
    a slug:Filter .

<file:///home/danny/HKMS/transmissions/vocabs/mapping-scutter>
    slug:consumers [
        rdf:_1 <file:///home/danny/HKMS/transmissions/vocabs/rdf-consumer> ;
        a rdf:Seq
    ] ;
    slug:filters [
        rdf:_1 <file:///home/danny/HKMS/transmissions/vocabs/single-fetch-filter> ;
        rdf:_2 <file:///home/danny/HKMS/transmissions/vocabs/deep-depth-filter> ;
        a rdf:Seq
    ] ;
    slug:hasMemory <file:///home/danny/HKMS/transmissions/vocabs/memory> ;
    slug:workers "10" ;
    dc:description """A Scutter which simply discovers and maps 
	 connections between files using source/origin properties in 
	 its memory""" ;
    a slug:Scutter .

<file:///home/danny/HKMS/transmissions/vocabs/memory>
    slug:file "memory.rdf" ;
    a slug:Memory .

<file:///home/danny/HKMS/transmissions/vocabs/persistent-scutter>
    slug:consumers [
        rdf:_1 <file:///home/danny/HKMS/transmissions/vocabs/storer> ;
        rdf:_2 <file:///home/danny/HKMS/transmissions/vocabs/rdf-consumer> ;
        rdf:_3 <file:///home/danny/HKMS/transmissions/vocabs/persistent-storer> ;
        a rdf:Seq
    ] ;
    slug:filters [
        rdf:_1 <file:///home/danny/HKMS/transmissions/vocabs/single-fetch-filter> ;
        rdf:_2 <file:///home/danny/HKMS/transmissions/vocabs/depth-filter> ;
        rdf:_3 <file:///home/danny/HKMS/transmissions/vocabs/regex-filter> ;
        a rdf:Seq
    ] ;
    slug:hasMemory <file:///home/danny/HKMS/transmissions/vocabs/memory> ;
    slug:workers "10" ;
    dc:description """A Scutter that includes writing incoming data into 
	 a persistent memory. Note that the memory is different to that 
	 holdings Scutter persistent state.""" ;
    a slug:Scutter .

<file:///home/danny/HKMS/transmissions/vocabs/persistent-storer>
    slug:hasMemory <file:///home/danny/HKMS/transmissions/vocabs/db-memory> ;
    slug:impl "com.ldodds.slug.http.PersistentResponseStorer" ;
    dc:description "Stores HTTP responses in Jena persistent model" ;
    dc:title "Database-backed ResponseStorer" ;
    a slug:Consumer .

<file:///home/danny/HKMS/transmissions/vocabs/rdf-consumer>
    slug:impl "com.ldodds.slug.http.RDFConsumer" ;
    dc:description "Discovers seeAlso links in RDF models and adds them to task list" ;
    dc:title "RDFConsumer" ;
    a slug:Consumer .

<file:///home/danny/HKMS/transmissions/vocabs/regex-filter>
    slug:filter "livejournal" ;
    slug:impl "com.ldodds.slug.http.RegexFilter" ;
    dc:title "Block URLs based on Regex" ;
    a slug:Filter .

<file:///home/danny/HKMS/transmissions/vocabs/shallow-depth-filter>
    slug:depth "1" ;
    slug:impl "com.ldodds.slug.http.DepthFilter" ;
    dc:title "Limit Depth of Crawling" ;
    a slug:Filter .

<file:///home/danny/HKMS/transmissions/vocabs/shallow-slow-scutter>
    slug:consumers [
        rdf:_1 <file:///home/danny/HKMS/transmissions/vocabs/storer> ;
        rdf:_2 <file:///home/danny/HKMS/transmissions/vocabs/rdf-consumer> ;
        a rdf:Seq
    ] ;
    slug:filters [
        rdf:_1 <file:///home/danny/HKMS/transmissions/vocabs/single-fetch-filter> ;
        rdf:_2 <file:///home/danny/HKMS/transmissions/vocabs/shallow-depth-filter> ;
        rdf:_3 <file:///home/danny/HKMS/transmissions/vocabs/regex-filter> ;
        a rdf:Seq
    ] ;
    slug:hasMemory <file:///home/danny/HKMS/transmissions/vocabs/memory> ;
    slug:workers "3" ;
    dc:description """A Scutter which crawls only a shallow depth, with 
	 fewer workers""" ;
    a slug:Scutter .

<file:///home/danny/HKMS/transmissions/vocabs/single-fetch-filter>
    slug:impl "com.ldodds.slug.http.SingleFetchFilter" ;
    dc:title "Avoid Loops" ;
    a slug:Filter .

<file:///home/danny/HKMS/transmissions/vocabs/slug-config.rdf>
    dc:description """
Configuration File for the Slug Semantic Web Crawler. Used to define crawler profiles 
with different worker, memory, consumer and filter configurations.
      """ ;
    dc:title "Slug Configuration File" .

<file:///home/danny/HKMS/transmissions/vocabs/storer>
    slug:cache "c:\\temp\\slug-cache" ;
    slug:impl "com.ldodds.slug.http.ResponseStorer" ;
    dc:description "Stores HTTP responses in a file system cache" ;
    dc:title "ResponseStorer" ;
    a slug:Consumer .

================
File: webpack.config.js
================

const path = require('path');
const HtmlWebpackPlugin = require('html-webpack-plugin');
const MiniCssExtractPlugin = require('mini-css-extract-plugin');
const WorkboxWebpackPlugin = require('workbox-webpack-plugin');
const isProduction = process.env.NODE_ENV == 'production';
const stylesHandler = MiniCssExtractPlugin.loader;
const config = {
    entry: './src/index.js',
    output: {
        path: path.resolve(__dirname, 'dist'),
    },
    devServer: {
        open: true,
        host: 'localhost',
    },
    plugins: [
        new HtmlWebpackPlugin({
            template: 'index.html',
        }),
        new MiniCssExtractPlugin(),
    ],
    module: {
        rules: [
            {
                test: /\.(js|jsx)$/i,
                loader: 'babel-loader',
            },
            {
                test: /\.css$/i,
                use: [stylesHandler, 'css-loader', 'postcss-loader'],
            },
            {
                test: /\.(eot|svg|ttf|woff|woff2|png|jpg|gif)$/i,
                type: 'asset',
            },
        ],
    },
};
module.exports = () => {
    if (isProduction) {
        config.mode = 'production';
        config.plugins.push(new WorkboxWebpackPlugin.GenerateSW());
    } else {
        config.mode = 'development';
    }
    return config;
};
