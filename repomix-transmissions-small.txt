This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-01-12T20:24:50.264Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
- Pay special attention to the Repository Description. These contain important context and guidelines specific to this project.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.
- Code comments have been removed.

Additional Info:
----------------
User Provided Header:
-----------------------
Transmissions source code

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Directory Structure
================================================================
src/
  api/
    cli/
      run.js
    common/
      CommandUtils.js
    http/
      WebRunner.js
  applications/
    file-pipeline/
      config.ttl
      transmissions.ttl
    string-pipeline/
      config.ttl
      transmissions.ttl
    test_fork/
      about.md
      config.ttl
      transmissions.ttl
  engine/
    Application.js
    Connector.js
    Transmission.js
  processors/
    base/
      AbstractProcessorFactory.js
      Processor copy 2.js
      Processor copy 3.js
      Processor.js
      ProcessorSettings.js
    flow/
      DeadEnd.js
      FlowProcessorsFactory.js
      ForEach.js
      Fork.js
      Halt.js
      NOP.js
      Ping.js
      Unfork.js
    util/
      CaptureAll.js
      SetMessage.js
      ShowConfig.js
      ShowMessage.js
      ShowTransmission.js
      Stash.js
      UtilProcessorsFactory.js
      WhiteboardToMessage.js
  utils/
    footpath.js
    GrapoiHelpers.js
    Logger.js
    ns.js
    t2j.js
    test_runner.js
package.json
README.md

================================================================
Files
================================================================

================
File: src/api/cli/run.js
================
import yargs from 'yargs'
import { hideBin } from 'yargs/helpers'
import CommandUtils from '../common/CommandUtils.js'
import WebRunner from '../http/WebRunner.js'
import chalk from 'chalk'

const defaultApplicationsDir = 'src/applications'
const commandUtils = new CommandUtils(defaultApplicationsDir)

import { readFileSync } from 'fs';
import { dirname, join } from 'path';
import { fileURLToPath } from 'url';

const __dirname = dirname(fileURLToPath(import.meta.url));
const packageJson = JSON.parse(readFileSync(join(__dirname, '../../../package.json')));
const buildInfo = process.env.BUILD_INFO || 'dev';
const version = `${packageJson.version} (${buildInfo})`;
const banner = `
  _____
 |_   _| __ __ _ _ __  ___
   | || '__/ _\` | '_ \\/ __|
   | || | | (_| | | | \\__ \\
   |_||_|  \\__,_|_| |_|___/
             ${version.padStart(10).padEnd(20)}
         ${new Date().toISOString().split('T')[0]}
`;

async function main() {
    console.log(chalk.cyan(banner))
    const yargsInstance = yargs(hideBin(process.argv))
        .usage(chalk.cyan('Usage: ./trans [application][.subtask] [options] [target]\n  Run without arguments to list available applications.'))
        .option('verbose', {
            alias: 'v',
            describe: chalk.yellow('Enable verbose output'),
            type: 'boolean'
        })
        .option('silent', {
            alias: 's',
            describe: chalk.yellow('Suppress all output'),
            type: 'boolean'
        })
        .option('message', {
            alias: 'm',
            describe: chalk.yellow('Input message as JSON'),
            type: 'string',
            coerce: JSON.parse
        })
        .option('web', {
            alias: 'w',
            describe: chalk.yellow('Start web interface'),
            type: 'boolean',
        })
        .option('port', {
            alias: 'p',
            describe: chalk.yellow('Port for web interface'),
            type: 'number',
            default: 3000
        })
        .command('$0 [application] [target]', chalk.green('runs the specified application\n\nExample: ./trans process.convert -m \'{"text": "hello"}\'\n'), (yargs) => {
            return yargs
                .positional('application', {
                    describe: chalk.yellow('the application to run')
                })
                .positional('target', {
                    describe: chalk.yellow('the target of the application')
                })
        }, async (argv) => {
            if (argv.web) {
                const webRunner = new WebRunner(applicationsDir, argv.port)
                webRunner.start()
                return
            }

            if (!argv.application) {
                console.log(chalk.cyan('Available applications:'))
                const apps = await commandUtils.listApplications()
                console.log(chalk.green(apps.join('\n')))
                yargsInstance.showHelp()
                return
            }

            await commandUtils.begin(argv.application, argv.target, argv.message, argv.verbose)
        })
        .help('h')
        .alias('h', 'help')

    await yargsInstance.argv
}

main().catch(console.error)

================
File: src/api/common/CommandUtils.js
================
import path from 'path'
import fs from 'fs/promises'
import logger from '../../utils/Logger.js'

import ApplicationManager from '../../core/ApplicationManager.js'

class CommandUtils {

    #appManager

    constructor() {
        this.#appManager = new ApplicationManager();
    }

    async begin(application, target, message = {}, verbose, silent) {

        var debugLevel = verbose ? "debug" : "info"
        logger.setLogLevel(debugLevel)

        logger.debug('\nCommandUtils.begin()')
        logger.debug('CommandUtils.begin, process.cwd() = ' + process.cwd())
        logger.debug('CommandUtils.begin, debugLevel = ' + debugLevel)
        logger.debug('CommandUtils.begin, application = ' + application)
        logger.debug('CommandUtils.begin, target = ' + target)
        logger.debug(`CommandUtils.begin, message = ${message}`)


        if (target && !target.startsWith('/')) {
            target = path.join(process.cwd(), target)
        }

        var { appName, appPath, subtask } = CommandUtils.splitName(application)


        logger.debug(`\n
    after split :
    appName = ${appName}
    appPath = ${appPath}
    subtask = ${subtask}
    target = ${target}`)



        await this.#appManager.initialize(appName, appPath, subtask, target)

        return await this.#appManager.start(message)
    }

    static splitName(fullPath) {
        logger.debug(`\nCommandUtils.splitName, fullPath  = ${fullPath}`)
        const parts = fullPath.split(path.sep)
        logger.debug(`\nCommandUtils.splitName, parts  = ${parts}`)
        var lastPart = parts[parts.length - 1]

        var task = false
        if (lastPart.includes('.')) {
            const split = lastPart.split('.')
            task = split[1]
            lastPart = split[0]
        }
        var appPath = parts.slice(0, parts.length - 1).join(path.sep)
        appPath = path.join(appPath, lastPart)



        logger.debug(`CommandUtils.splitName, appName:${lastPart}, appPath:${appPath}, task:${task},`)

        return { appName: lastPart, appPath: appPath, task: task }
    }

    async listApplications() {
        return await this.#appManager.listApplications()
    }


    static async parseOrLoadContext(contextArg) {
        logger.debug(`CommandUtils.parseOrLoadContext(), contextArg = ${contextArg}`)
        let message = {}
        try {
            message.payload = JSON.parse(contextArg)
        } catch (err) {
            logger.debug('*** Loading JSON from file...')
            const filePath = path.resolve(contextArg)
            const fileContent = await fs.readFile(filePath, 'utf8')
            message.payload = JSON.parse(fileContent)
        }
        return message
    }
}

export default CommandUtils

================
File: src/api/http/WebRunner.js
================
import express from 'express'

import ApplicationManager from '../../core/ApplicationManager.js'
import logger from '../../utils/Logger.js'

class WebRunner {
    constructor(appsDir, port = 7247) {
        this.appManager = new ApplicationManager(appsDir)

        this.app = express()
        this.port = port

        this.setupRoutes()
    }

    setupRoutes() {
        this.app.use(express.json())

        this.app.get('/applications', async (req, res) => {
            const apps = await this.appManager.listApplications()
            res.json(apps)
        })

        this.app.post('/run/:application', async (req, res) => {
            const { application } = req.params
            const { target, message } = req.body

            try {


                await this.appManager.initialize()

                const result = await this.appManager.run({
                    ...config,
                    message,
                    target
                })

                res.json(result)
            } catch (error) {
                logger.error('Error running application:', error)
                res.status(500).json({
                    success: false,
                    error: error.message
                })
            }
        })
    }

    start() {
        this.app.listen(this.port, () => {
            logger.log(`Web interface running on port ${this.port}`)
        })
    }
}

export default WebRunner

================
File: src/applications/file-pipeline/config.ttl
================
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix trn: <http://purl.org/stuff/transmissions/> .
# @prefix trn: <http://purl.org/stuff/transmissions/> .
@prefix trn: <http://purl.org/stuff/transmissions/> . # for custom terms & instances

trn:FilePipelineMap a trn:DataMap ;
    trn:sourceFile "input.txt" ;
    trn:destinationFile "output.txt" .

================
File: src/applications/file-pipeline/transmissions.ttl
================
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix trn: <http://purl.org/stuff/transmissions/> .
@prefix : <http://purl.org/stuff/transmissions/> . # for custom terms & instances

:file_pipeline a trn:Transmission ;
    trn:pipe (:s1 :s2 :s3 :s4) .

:s1 a :FileSource .
:s2 a :AppendProcess .
:s3 a :AppendProcess .
:s4 a :FileSink .

================
File: src/applications/string-pipeline/config.ttl
================
### NOT USED

@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix dc: <http://purl.org/dc/terms/> .
@prefix trn: <http://purl.org/stuff/transmissions/> .
@prefix : <http://purl.org/stuff/transmissions/> . # for custom terms & instances

:StringPipeline dc:title "Hello" .

================
File: src/applications/string-pipeline/transmissions.ttl
================
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix trn: <http://purl.org/stuff/transmissions/> .
@prefix : <http://purl.org/stuff/transmissions/> . # for custom terms & instances

:stringpipe a trn:Transmission ;
    trn:pipe (:s1 :s2 :s3 :s4) .

:s1 a :StringSource .
:s2 a :AppendProcess .
:s3 a :AppendProcess .
:s4 a :StringSink .

================
File: src/applications/test_fork/about.md
================
# Test Fork/Unfork

```
./run test_fork | grep 's2 a NOP'
```

should show the number of forks + 1 (for `message.done`)

```
./run test_fork | grep s1.s2.s10.s11.s12.s13
```

should show just one

================
File: src/applications/test_fork/config.ttl
================
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix trn: <http://purl.org/stuff/transmissions/> .
# @prefix trn: <http://purl.org/stuff/transmissions/> .
@prefix trn: <http://purl.org/stuff/transmissions/> . # for custom terms & instances

================
File: src/applications/test_fork/transmissions.ttl
================
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix trn: <http://purl.org/stuff/transmissions/> . # TODO make plural
@prefix : <http://purl.org/stuff/transmissions/> . # for custom terms & instances - TODO make one @services s:

#############################################################
# insert into pipe for debugging
:DE a :DeadEnd . # ends the current pipe quietly
:H  a :Halt . # kills everything
:SC a :ShowConfig . # verbose report, continues pipe
:SM a :ShowMessage . # verbose report, continues pipe
:N  a :NOP . # no operation (except for showing stage in pipe)
:UF a :Unfork . # collapses all pipes but one
#############################################################

:test_fork a :Transmission ;
   trn:contains :pipeA .

:pipeA a trn:Transmission ;
trn:pipe (:p10 :p20 :SM ) .

:p10 a :Fork .

# :s10 a :Unfork .
:p20 a :NOP .

================
File: src/engine/Application.js
================
class Application {
    constructor() {
        this.transmissions = new Map()
        this.config = null
        this.manifest = null
    }

    addTransmission(id, transmission) {
        this.transmissions.set(id, transmission)
    }
}

================
File: src/engine/Connector.js
================
import { EventEmitter } from 'events'
import logger from '../utils/Logger.js'
import footpath from '../utils/footpath.js'

class Connector extends EventEmitter {


    constructor(fromName, toName) {
        super()
        this.fromName = fromName
        this.toName = toName
    }

    connect(processors) {
        logger.log(`Connector.connect this.fromName = ${this.fromName} this.toName =  ${this.toName}`)
        let fromProcessor = processors[this.fromName]
        let toProcessor = processors[this.toName]

        if (!fromProcessor) {
            throw new Error(`\nMissing processor : ${this.fromName}, going to ${this.toName} \n(check for typos in transmissions.ttl)\n`)
        }
















        fromProcessor.on('message', async (message) => {
            var tags = fromProcessor.message?.tags ? ` [${fromProcessor.message.tags}] ` : ''
            toProcessor.tags = tags
            logger.log(`Running >>> : ${tags} ${toProcessor.constructor.name}`)
            await toProcessor.receive(message)
        })

    }


}

export default Connector

================
File: src/engine/Transmission.js
================
import logger from '../utils/Logger.js'
import Connector from './Connector.js'
import ns from '../utils/ns.js'

class Transmission {
  constructor() {
    this.processors = {}
    this.connectors = []

  }

  register(processorName, instance) {
    this.processors[processorName] = instance

  }

  get(processorName) {
    return this.processors[processorName]
  }

  connect(fromProcessorName, toProcessorName) {
    logger.log(`Transmission.connect from ${fromProcessorName} to ${fromProcessorName}`)
    let connector = new Connector(fromProcessorName, toProcessorName)
    this.connectors.push(connector)
    connector.connect(this.processors)
  }




  async process(message) {
    logger.log('\n+ ***** Execute Transmission : ' + this.label + ' <' + this.id + '>')
    const processorName = this.connectors[0]?.fromName || Object.keys(this.processors)[0]
    let processor = this.get(processorName)
    if (processor) {
      logger.log("| Running : " + processorName + " a " + processor.constructor.name)
      await processor.receive(message)
    } else {
      logger.error("No valid processor found to execute")
    }
  }






  toString() {
    let description = 'Transmission Structure:\n'


    description += 'Processors:\n'
    Object.keys(this.processors).forEach((processorName) => {


      description += `  - ${ns.shortName(processorName)} a ${this.processors[processorName]} \n`

    })









    description += 'Connectors:\n'
    this.connectors.forEach((connector, index) => {
      description += `  - Connector ${index + 1}: ${ns.shortName(connector.fromName)} -> ${ns.shortName(connector.toName)}\n`
    })

    return description
  }
}

export default Transmission

================
File: src/processors/base/AbstractProcessorFactory.js
================
import logger from '../../utils/Logger.js'


import SystemProcessorsFactory from '../system/SystemProcessorsFactory.js'
import TestProcessorsFactory from '../test/TestProcessorsFactory.js'
import FsProcessorsFactory from '../fs/FsProcessorsFactory.js'
import MarkupProcessorsFactory from '../markup/MarkupProcessorsFactory.js'
import UtilProcessorsFactory from '../util/UtilProcessorsFactory.js'
import TextProcessorsFactory from '../text/TextProcessorsFactory.js'
import ProtocolsProcessorsFactory from '../protocols/ProtocolsProcessorsFactory.js'
import RDFProcessorsFactory from '../rdf/RDFProcessorsFactory.js'
import PostcraftProcessorsFactory from '../postcraft/PostcraftProcessorsFactory.js'
import FlowProcessorsFactory from '../flow/FlowProcessorsFactory.js'
import StagingProcessorsFactory from '../staging/StagingProcessorsFactory.js'
import GitHubProcessorsFactory from '../github/GitHubProcessorsFactory.js'
import JSONProcessorsFactory from '../json/JSONProcessorsFactory.js'
import PackerProcessorsFactory from '../packer/PackerProcessorsFactory.js'



import UnsafeProcessorsFactory from '../unsafe/UnsafeProcessorsFactory.js'
import HttpProcessorsFactory from '../http/HttpProcessorsFactory.js'
import McpProcessorsFactory from '../mcp/McpProcessorsFactory.js'
import XmppProcessorsFactory from '../xmpp/XmppProcessorsFactory.js'

class AbstractProcessorFactory {




    static createProcessor(type, config) {
        logger.debug(`\nAbstractProcessorFactory.createProcessor : type.value = ${type.value}`)
        logger.debug(`AbstractProcessorFactory.createProcessor : config = ${config}`)
        var processor = UnsafeProcessorsFactory.createProcessor(type, config)
        if (processor) return processor
        var processor = HttpProcessorsFactory.createProcessor(type, config)
        if (processor) return processor
        var processor = McpProcessorsFactory.createProcessor(type, config)
        if (processor) return processor
        var processor = XmppProcessorsFactory.createProcessor(type, config)
        if (processor) return processor

        var processor = TestProcessorsFactory.createProcessor(type, config)
        if (processor) return processor
        var processor = UtilProcessorsFactory.createProcessor(type, config)
        if (processor) return processor

        processor = FsProcessorsFactory.createProcessor(type, config)
        if (processor) return processor

        processor = MarkupProcessorsFactory.createProcessor(type, config)
        if (processor) return processor

        processor = TextProcessorsFactory.createProcessor(type, config)
        if (processor) return processor

        processor = ProtocolsProcessorsFactory.createProcessor(type, config)
        if (processor) return processor

        processor = RDFProcessorsFactory.createProcessor(type, config)
        if (processor) return processor

        processor = PostcraftProcessorsFactory.createProcessor(type, config)
        if (processor) return processor

        processor = SystemProcessorsFactory.createProcessor(type, config)
        if (processor) return processor

        processor = FlowProcessorsFactory.createProcessor(type, config)
        if (processor) return processor

        processor = GitHubProcessorsFactory.createProcessor(type, config)
        if (processor) return processor

        processor = StagingProcessorsFactory.createProcessor(type, config)
        if (processor) return processor

        processor = JSONProcessorsFactory.createProcessor(type, config)
        if (processor) return processor

        var processor = PackerProcessorsFactory.createProcessor(type, config);
        if (processor) return processor;
    }
}

export default AbstractProcessorFactory

================
File: src/processors/base/Processor copy 2.js
================
import { EventEmitter } from 'events'
import grapoi from 'grapoi'
import logger from '../../utils/Logger.js'
import ns from '../../utils/ns.js'
import footpath from '../../utils/footpath.js'

class Processor extends EventEmitter {
    constructor(config) {
        super()
        this.config = config
        this.messageQueue = []
        this.processing = false
        this.outputs = []
    }

    getProperty(property, fallback) {
        logger.debug(`Processor.getProperty looking for ${property}`)
        logger.debug(`Processor.getProperty, this.node.value = ${this.node.value}`)

        const shortName = ns.getShortname(property)
        if (this.message && this.message[shortName]) {
            logger.debug(`Found in message: ${this.message[shortName]}`)
            return this.message[shortName]
        }

        const settingsValue = this.getPropertyFromSettings(property)
        if (settingsValue) {
            logger.debug(`Found in settings: ${settingsValue.value}`)
            return settingsValue.value
        }

        logger.debug(`Using fallback: ${fallback}`)
        return fallback
    }

    getPropertyFromSettings(property) {
        if (!this.config || !this.node) {
            logger.debug('Config or node missing')
            return undefined
        }

        try {
            const dataset = this.config
            const ptr = grapoi({ dataset, term: this.node })

            logger.debug(`Checking property ${property} on node ${this.node.value}`)
            let values = ptr.out(property)
            if (values.terms.length > 0) {
                logger.debug(`Found direct property value: ${values.term.value}`)
                return values.term
            }
            logger.debug('No direct property found')


            logger.debug(`Full dataset: ${[...dataset].map(q => `${q.subject.value} ${q.predicate.value} ${q.object.value}`).join('\n')}`)

            const settings = ptr.out(ns.trn.settings)
            logger.debug(`Settings query result: ${settings?.terms?.length} terms`)
            if (settings.terms.length > 0) {
                const settingsId = settings.term
                logger.debug(`Found settings reference: ${settingsId.value}`)

                const settingsPtr = grapoi({ dataset, term: settingsId })
                const settingsValues = settingsPtr.out(property)
                if (settingsValues.terms.length > 0) {
                    logger.debug(`Found settings property value: ${settingsValues.term.value}`)
                    return settingsValues.term
                }
                logger.debug('No property found in settings')
            }
            logger.debug('No settings reference found')
            return undefined

        } catch (err) {
            logger.debug(`Error getting property ${property}: ${err}`)
            return undefined
        }
    }

    async preProcess(message) {
        this.message = message
        logger.debug("Processor.preProcess")
    }

    async postProcess(message) {
        logger.debug("Processor.postProcess")
    }

    async receive(message) {
        await this.enqueue(message)
    }

    async enqueue(message) {
        this.messageQueue.push({ message })
        if (!this.processing) {
            this.executeQueue()
        }
    }

    async executeQueue() {
        this.processing = true
        while (this.messageQueue.length > 0) {
            let { message } = this.messageQueue.shift()
            message = structuredClone(message)
            this.addTag(message)

            await this.preProcess(message)
            await this.process(message)
            await this.postProcess(message)
        }
        this.processing = false
    }

    async process(message) {
        throw new Error('process method not implemented')
    }

    addTag(message) {
        const tag = this.getTag()
        if (!message.tags) {
            message.tags = tag
            return
        }
        message.tags = message.tags + '.' + tag
    }

    getTag() {
        return footpath.urlLastPart(this.id)
    }

    async emit(event, message) {
        await new Promise(resolve => {
            super.emit(event, message)
            resolve()
        })
        return message
    }

    getOutputs() {
        const results = this.outputs
        this.outputs = []
        return results
    }
}

export default Processor

================
File: src/processors/base/Processor copy 3.js
================
import { EventEmitter } from 'events'
import grapoi from 'grapoi'
import logger from '../../utils/Logger.js'
import ns from '../../utils/ns.js'
import footpath from '../../utils/footpath.js'

class Processor extends EventEmitter {
    constructor(config) {
        super()
        this.config = config
        this.messageQueue = []
        this.processing = false
        this.outputs = []
    }

    getProperty(property, fallback) {
        logger.debug(`Processor.getProperty looking for ${property}`)

        if (!this.config || !this.node) {
            logger.debug('No config or node available')
            return fallback
        }


        const settingsQuad = [...this.config.match(
            this.node,
            ns.trn.settings,
            null
        )][0]

        if (settingsQuad) {

            const propertyQuad = [...this.config.match(
                settingsQuad.object,
                property,
                null
            )][0]

            if (propertyQuad) {
                logger.debug(`Found property value: ${propertyQuad.object.value}`)
                return propertyQuad.object.value
            }
        }


        const directQuad = [...this.config.match(
            this.node,
            property,
            null
        )][0]

        if (directQuad) {
            logger.debug(`Found direct property value: ${directQuad.object.value}`)
            return directQuad.object.value
        }

        logger.debug(`No property found, using fallback: ${fallback}`)
        return fallback
    }

    async preProcess(message) {
        this.message = message
        logger.debug("Processor.preProcess")
    }

    async postProcess(message) {
        logger.debug("Processor.postProcess")
    }

    async receive(message) {
        await this.enqueue(message)
    }

    async enqueue(message) {
        this.messageQueue.push({ message })
        if (!this.processing) {
            this.executeQueue()
        }
    }

    async executeQueue() {
        this.processing = true
        while (this.messageQueue.length > 0) {
            let { message } = this.messageQueue.shift()
            message = structuredClone(message)
            this.addTag(message)

            await this.preProcess(message)
            await this.process(message)
            await this.postProcess(message)
        }
        this.processing = false
    }

    async process(message) {
        throw new Error('process method not implemented')
    }

    addTag(message) {
        const tag = this.getTag()
        if (!message.tags) {
            message.tags = tag
            return
        }
        message.tags = message.tags + '.' + tag
    }

    getTag() {
        return footpath.urlLastPart(this.id)
    }

    async emit(event, message) {
        await new Promise(resolve => {
            super.emit(event, message)
            resolve()
        })
        return message
    }

    getOutputs() {
        const results = this.outputs
        this.outputs = []
        return results
    }
}

export default Processor;

================
File: src/processors/base/Processor.js
================
import { EventEmitter } from 'events'
import logger from '../../utils/Logger.js'
import ns from '../../utils/ns.js'
import footpath from '../../utils/footpath.js'

class Processor extends EventEmitter {
    constructor(config) {
        super()
        this.config = config
        this.messageQueue = []
        this.processing = false
        this.outputs = []
    }

    getProperty(property, fallback) {
        try {
            logger.debug(`Processor.getProperty looking for ${property}`)

            if (!this.config || !this.node) {
                logger.debug('No config or node available')
                return fallback
            }

            if (!property) {
                logger.debug('Property parameter is required')
                return fallback
            }


            const directQuads = this.config.match(this.node, property, null)
            for (const quad of directQuads) {
                logger.debug(`Found direct property value: ${quad.object.value}`)
                return quad.object.value
            }


            const settingsQuads = this.config.match(this.node, ns.trn.settings, null)
            for (const settingsQuad of settingsQuads) {
                const settingsPropertyQuads = this.config.match(settingsQuad.object, property, null)
                for (const propertyQuad of settingsPropertyQuads) {
                    logger.debug(`Found settings property value: ${propertyQuad.object.value}`)
                    return propertyQuad.object.value
                }
            }

            logger.debug(`No property found, using fallback: ${fallback}`)
            return fallback

        } catch (error) {
            logger.error(`Property resolution failed: ${error.message}`)
            return fallback
        }
    }

    async preProcess(message) {
        this.message = message
        logger.debug("Processor.preProcess")
    }

    async postProcess(message) {
        logger.debug("Processor.postProcess")
    }

    async receive(message) {
        await this.enqueue(message)
    }

    async enqueue(message) {
        this.messageQueue.push({ message })
        if (!this.processing) {
            this.executeQueue()
        }
    }

    async executeQueue() {
        this.processing = true
        while (this.messageQueue.length > 0) {
            let { message } = this.messageQueue.shift()
            message = structuredClone(message)
            this.addTag(message)

            await this.preProcess(message)
            await this.process(message)
            await this.postProcess(message)
        }
        this.processing = false
    }

    async process(message) {
        throw new Error('process method not implemented')
    }

    addTag(message) {
        const tag = this.getTag()
        if (!message.tags) {
            message.tags = tag
            return
        }
        message.tags = message.tags + '.' + tag
    }

    getTag() {
        return footpath.urlLastPart(this.id)
    }

    async emit(event, message) {
        await new Promise(resolve => {
            super.emit(event, message)
            resolve()
        })
        return message
    }

    getOutputs() {
        const results = this.outputs
        this.outputs = []
        return results
    }
}

export default Processor

================
File: src/processors/base/ProcessorSettings.js
================
import logger from '../../utils/Logger.js'
import { EventEmitter } from 'events'
import rdf from 'rdf-ext'
import grapoi from 'grapoi'
import ns from '../../utils/ns.js'
import footpath from '../../utils/footpath.js'

class ProcessorSettings {

    constructor(config) {
        this.config = config
    }

    getValue(property, fallback) {
        logger.log(`IDDDDDDDDDDD ${this.id}`)
        logger.log(`getMyConfigNode() = ${this.getMyConfigNode()}`)
        const poi = this.getMyPoi()
        logger.log(`PPPPPPPPPPPPPP ${poi.out(property).term}`)
        logger.log(`PROPERTY = ${property}`)


        const shortName = ns.getShortname(property)

        this.showMyConfig()
        if (this.message[shortName]) return this.message[shortName]


        const maybe = this.getPropertyFromMyConfig(property)

        logger.log(`maybe = ${maybe}`)
        if (maybe) return maybe
        return fallback
    }
}
export default ProcessorSettings

================
File: src/processors/flow/DeadEnd.js
================
import logger from '../../utils/Logger.js'
import Processor from '../base/Processor.js'

class DeadEnd extends Processor {

    async process(message) {
        logger.log('DeadEnd at [' + message.tags + '] ' + this.getTag())
    }

}
export default DeadEnd

================
File: src/processors/flow/FlowProcessorsFactory.js
================
import logger from '../../utils/Logger.js'
import ns from '../../utils/ns.js'
import ForEach from './ForEach.js'
import Ping from './Ping.js'
import NOP from '../flow/NOP.js'
import DeadEnd from '../flow/DeadEnd.js'
import Halt from '../flow/Halt.js'
import Unfork from '../flow/Unfork.js'
import Fork from '../flow/Fork.js'

class FlowProcessorsFactory {
    static createProcessor(type, config) {
        if (type.equals(ns.trn.ForEach)) {
            logger.debug('FlowProcessorsFactory: Creating ForEach processor')
            return new ForEach(config)
        }
        if (type.equals(ns.trn.Ping)) {
            logger.debug('FlowProcessorsFactory: Creating Ping processor')
            return new Ping(config)
        }
        if (type.equals(ns.trn.NOP)) {
            return new NOP(config)
        }
        if (type.equals(ns.trn.DeadEnd)) {
            return new DeadEnd(config)
        }
        if (type.equals(ns.trn.Halt)) {
            return new Halt(config)
        }
        if (type.equals(ns.trn.Fork)) {
            return new Fork(config)
        }
        if (type.equals(ns.trn.Unfork)) {
            return new Unfork(config)
        }
        return false
    }
}

export default FlowProcessorsFactory

================
File: src/processors/flow/ForEach.js
================
import logger from '../../utils/Logger.js'
import Processor from '../base/Processor.js'

class ForEach extends Processor {
    constructor(config) {
        super(config)
    }

    async process(message) {

        logger.debug('ForEach execute method called')

        if (!message.foreach || !Array.isArray(message.foreach)) {
            logger.error('ForEach: Invalid or missing foreach array in message')
            message.foreach = ["testing-testing", "one", "two", "three"]

        }

        for (const item of message.foreach) {
            const clonedMessage = structuredClone(message)
            clonedMessage.currentItem = item
            delete clonedMessage.foreach

            logger.debug(`ForEach: Emitting message for item: ${item}`)
            this.emit('message', clonedMessage)
        }

        logger.debug('ForEach: Finished processing all items')
    }
}
export default ForEach

================
File: src/processors/flow/Fork.js
================
import logger from '../../utils/Logger.js'
import Processor from '../base/Processor.js'




class Fork extends Processor {

    constructor(config) {
        super(config)
    }

    async process(message) {

        const nForks = message.nForks || 2

        logger.debug('forks = ' + nForks)

        for (let i = 0; i < nForks; i++) {
            var messageClone = structuredClone(message)
            messageClone.forkN = i
            logger.debug('--- emit --- ' + i)
            this.emit('message', messageClone)
        }

        message.done = true

        return this.emit('message', message)

    }

}

export default Fork

================
File: src/processors/flow/Halt.js
================
import logger from '../../utils/Logger.js'
import Processor from '../base/Processor.js'

class Halt extends Processor {

    process(message) {
        logger.log('\n************************************************************************')
        logger.log('*** << Thou Hast Summoned HALT, the Mighty Stopper of All Things  >> ***')
        logger.log('*** <<                   ~~~ ALL IS GOOD ~~~                      >> ***')
        logger.log('*** <<                     Have a nice day!                       >> ***')
        logger.log('************************************************************************\n')
        logger.log('*** Transmission was : ' + message.tags)
        logger.log('*** Context now : ')
        logger.reveal(message)
        process.exit()
    }
}

export default Halt

================
File: src/processors/flow/NOP.js
================
import logger from '../../utils/Logger.js'
import Processor from '../base/Processor.js'
import ns from '../../utils/ns.js'

class NOP extends Processor {

    constructor(config) {
        super(config)
    }

    async process(message) {
        const done = message.done ? `DONE` : `NOT DONE`
        logger.log(`\nNOP at [${message.tags}] ${this.getTag()} (${done})`)

        return this.emit('message', message)
    }

    double(string) {
        return string + string
    }
}
export default NOP

================
File: src/processors/flow/Ping.js
================
import { Worker } from 'worker_threads';
import path from 'path';
import logger from '../../utils/Logger.js';
import Processor from '../base/Processor.js';
import ns from '../../utils/ns.js';

class Ping extends Processor {
    constructor(config) {
        super(config);
        this.worker = null;
        this.pingConfig = {
            interval: this.getPropertyFromMyConfig(ns.trn.interval) || 5000,
            count: this.getPropertyFromMyConfig(ns.trn.count) || 0,
            payload: this.getPropertyFromMyConfig(ns.trn.payload) || 'ping',
            killSignal: this.getPropertyFromMyConfig(ns.trn.killSignal) || 'STOP',
            retryAttempts: this.getPropertyFromMyConfig(ns.trn.retryAttempts) || 3,
            retryDelay: this.getPropertyFromMyConfig(ns.trn.retryDelay) || 1000
        };
    }

    async process(message) {
        try {

            if (message.kill === this.pingConfig.killSignal) {
                await this.shutdown();
                return this.emit('message', {
                    ...message,
                    pingStatus: 'stopped',
                    timestamp: Date.now()
                });
            }

            if (this.worker) {
                logger.warn('Ping worker already running, ignoring start request');
                return;
            }

            let retryCount = 0;
            const startWorker = async () => {
                try {
                    this.worker = new Worker(
                        path.join(process.cwd(), 'src/processors/flow/PingWorker.js')
                    );

                    this.worker.on('message', (msg) => {
                        switch (msg.type) {
                            case 'ping':
                                this.emit('message', {
                                    ...message,
                                    ping: {
                                        count: msg.count,
                                        timestamp: msg.timestamp,
                                        payload: msg.payload,
                                        status: 'running'
                                    }
                                });
                                break;
                            case 'complete':
                                this.emit('message', {
                                    ...message,
                                    pingComplete: true,
                                    timestamp: Date.now()
                                });
                                break;
                            case 'error':
                                this.handleWorkerError(msg.error, startWorker, retryCount);
                                break;
                        }
                    });

                    this.worker.on('error', (error) => {
                        this.handleWorkerError(error, startWorker, retryCount);
                    });

                    this.worker.on('exit', (code) => {
                        if (code !== 0) {
                            this.handleWorkerError(
                                new Error(`Worker stopped with exit code ${code}`),
                                startWorker,
                                retryCount
                            );
                        }
                        this.worker = null;
                    });

                    this.worker.postMessage({
                        type: 'start',
                        config: this.pingConfig
                    });

                } catch (error) {
                    this.handleWorkerError(error, startWorker, retryCount);
                }
            };

            await startWorker();

            return new Promise((resolve) => {
                this.worker.on('exit', () => {
                    resolve(message);
                });
            });

        } catch (error) {
            logger.error(`Failed to start ping processor: ${error}`);
            throw error;
        }
    }

    async handleWorkerError(error, retryFn, retryCount) {
        logger.error(`Ping worker error: ${error}`);

        if (retryCount < this.pingConfig.retryAttempts) {
            retryCount++;
            logger.info(`Retrying ping worker (attempt ${retryCount}/${this.pingConfig.retryAttempts})`);
            setTimeout(retryFn, this.pingConfig.retryDelay);
        } else {
            logger.error('Max retry attempts reached, stopping ping worker');
            this.emit('error', error);
            await this.shutdown();
        }
    }

    async shutdown() {
        if (this.worker) {
            this.worker.postMessage({ type: 'stop' });
            this.worker = null;
        }
    }
}

export default Ping;

================
File: src/processors/flow/Unfork.js
================
import logger from '../../utils/Logger.js'
import Processor from '../base/Processor.js'
import ns from '../../utils/ns.js'
import rdf from 'rdf-ext'
import grapoi from 'grapoi'
import DeadEnd from './DeadEnd.js'






class Unfork extends Processor {

    constructor(config) {
        super(config)







    }

    async process(message) {
        logger.setLogLevel("debug")
        logger.debug(`Unfork got message with done=${message.done}, tags=${message.tags}`);

        logger.debug('Unfork ----')
        if (message.done) {
            logger.debug(' - Unfork passing message >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')
            message.done = false









            return this.emit('message', message)
        } else {
            logger.debug(' - Unfork terminating pipe')
            return
        }
    }
}
export default Unfork

================
File: src/processors/util/CaptureAll.js
================
import logger from '../../utils/Logger.js'
import Processor from '../base/Processor.js'

class CaptureAll extends Processor {
    constructor(config) {

        if (!config.whiteboard || !Array.isArray(config.whiteboard)) {
            config.whiteboard = [];
        }
        super(config)

        if (CaptureAll.singleInstance) {
            return CaptureAll.singleInstance
        }
        CaptureAll.singleInstance = this
    }

    async process(message) {
        logger.log('CaptureAll at [' + message.tags + '] ' + this.getTag())
        this.config.whiteboard.push(message)
        return this.emit('message', message)
    }
}

export default CaptureAll

================
File: src/processors/util/SetMessage.js
================
import logger from '../../utils/Logger.js'
import Processor from '../base/Processor.js'
import GrapoiHelpers from '../../utils/GrapoiHelpers.js'
import ns from '../../utils/ns.js'
import rdf from 'rdf-ext'

class SetMessage extends Processor {

    constructor(config) {
        super(config)
        logger.log('SetMessage constructor')
    }

    async process(message) {
        logger.setLogLevel('debug')
        const setters = await this.getSetters(this.config, this.settings, ns.trn.setValue)
        for (let i = 0; i < setters.length; i++) {
            message[setters[i].key] = setters[i].value
        }
        return this.emit('message', message)
    }

    async getSetters(config, settings, term) {
        logger.debug(`***** config = ${config}`)
        logger.debug(`***** settings.value = ${settings.value}`)
        logger.debug(`***** term = ${term}`)
        const settersRDF = GrapoiHelpers.listToArray(config, settings, term)
        const dataset = this.config
        var setters = []
        for (let i = 0; i < settersRDF.length; i++) {
            let setter = settersRDF[i]
            let poi = rdf.grapoi({ dataset: dataset, term: setter })
            let key = poi.out(ns.trn.key).value
            let value = poi.out(ns.trn.value).value
            setters.push({ "key": key, "value": value })
        }
        return setters
    }
}

export default SetMessage

================
File: src/processors/util/ShowConfig.js
================
import logger from '../../utils/Logger.js'
import Processor from '../base/Processor.js'

class ShowConfig extends Processor {

    constructor(config) {
        super(config)
        this.verbose = false
    }

    async process(message) {



        if (this.verbose) logger.log("\n***  Show Config ***")


        logger.log("***************************")
        logger.log("***  Config")
        logger.reveal(this.config)
        logger.log("***************************")




        return this.emit('message', message)
    }
}

export default ShowConfig

================
File: src/processors/util/ShowMessage.js
================
import logger from '../../utils/Logger.js'
import Processor from '../base/Processor.js'

class ShowMessage extends Processor {

    constructor(config) {
        super(config)
        this.verbose = false
    }

    async process(message) {



        if (this.verbose) logger.log("\n***  Show Message ***")

        logger.log("***************************")
        logger.log("***  Message")
        logger.reveal(message)
        logger.log("***************************")




        return this.emit('message', message)
    }
}

export default ShowMessage

================
File: src/processors/util/ShowTransmission.js
================
import logger from '../../utils/Logger.js'
import Processor from '../base/Processor.js'

class ShowTransmission extends Processor {

    async process(message) {
        logger.log(this.transmission.toString())
        return this.emit('message', message)
    }
}

export default ShowTransmission

================
File: src/processors/util/Stash.js
================
import rdf from 'rdf-ext'
import { fromFile, toFile } from 'rdf-utils-fs'
import Processor from '../base/Processor.js'












class Stash extends Processor {





    constructor(config) {
        super(config)
    }






    async process(message) {
        const manifestFilename = rootDir + '/manifest.ttl'
        const stream = fromFile(manifestFilename)


        message.rootDir = rootDir
        message.dataset = await rdf.dataset().import(stream)
        return this.emit('message', message)
    }
}
export default Stash

================
File: src/processors/util/UtilProcessorsFactory.js
================
import logger from '../../utils/Logger.js'
import ns from '../../utils/ns.js'

import ShowMessage from './ShowMessage.js'
import ShowTransmission from './ShowTransmission.js'
import CaptureAll from './CaptureAll.js'
import ShowConfig from './ShowConfig.js'
import WhiteboardToMessage from './WhiteboardToMessage.js'
import SetMessage from './SetMessage.js'

class UtilProcessorsFactory {
    static createProcessor(type, config) {

        if (type.equals(ns.trn.ShowMessage)) {
            return new ShowMessage(config)
        }
        if (type.equals(ns.trn.ShowTransmission)) {
            return new ShowTransmission(config)
        }
        if (type.equals(ns.trn.CaptureAll)) {
            return new CaptureAll(config)
        }
        if (type.equals(ns.trn.ShowConfig)) {
            return new ShowConfig(config)
        }
        if (type.equals(ns.trn.WhiteboardToMessage)) {
            return new WhiteboardToMessage(config)
        }
        if (type.equals(ns.trn.SetMessage)) {
            return new SetMessage(config)
        }

        return false
    }
}
export default UtilProcessorsFactory

================
File: src/processors/util/WhiteboardToMessage.js
================
import logger from '../../utils/Logger.js'
import Processor from '../base/Processor.js'

class WhiteboardToMessage extends Processor {

    constructor(config) {
        super(config);
    }
    async process(message) {

        logger.log('WhiteboardToMessage at [' + message.tags + '] ' + this.getTag())

        const originalArray = this.config.whiteboard

        message.whiteboard = Object.keys(originalArray).reduce((acc, key) => {
            const value = originalArray[key];
            if (value !== undefined && value !== null) {
                Object.keys(value).forEach((prop) => {
                    if (!acc[prop]) {
                        acc[prop] = [];
                    }
                    acc[prop].push(value[prop]);
                });
            }
            return acc;
        }, {});

        return this.emit('message', message)
    }
}

export default WhiteboardToMessage

================
File: src/utils/footpath.js
================
import path from 'path'
import { fileURLToPath } from 'url'

import logger from './Logger.js'







let footpath = {}

footpath.resolve = function footpath(here, relative, start) {

    const loggy = false
    if (loggy) {
        logger.debug("\n*** start footpath.resolve ***")
        logger.debug("process.cwd() = " + process.cwd())
        logger.debug("here = " + here)
        logger.debug("relative = " + relative)
        logger.debug("start = " + start)
    }

    const __filename = fileURLToPath(here)
    const __dirname = path.dirname(__filename)
    const rootDir = path.resolve(__dirname, relative)
    const filePath = path.join(rootDir, start)

    if (loggy) {
        logger.debug("__filename = " + __filename)
        logger.debug("__dirname = " + __dirname)
        logger.debug("rootDir = " + rootDir)
        logger.debug("filePath = " + filePath)
        logger.debug("*** end footpath.resolve ***\n")
    }

    return filePath
}

footpath.urlLastPart = function footpath(url = 'http://example.org/not-a-url') {


    const urlObj = new URL(url);
    const hash = urlObj.hash;
    const path = urlObj.pathname;
    const lastPart = hash ? hash.replace(/^#/, '') : path.split('/').pop();
    // } catch {
    //  return 'not-a-url'

    return lastPart;
}

export default footpath

================
File: src/utils/GrapoiHelpers.js
================
import rdf from 'rdf-ext'
import grapoi from 'grapoi'
import { fromFile, toFile } from 'rdf-utils-fs'
import ns from './ns.js'
import logger from './Logger.js'



class GrapoiHelpers {


    static async readDataset(filename) {
        const stream = fromFile(filename)
        const dataset = await rdf.dataset().import(stream)
        return dataset
    }

    static async writeDataset(dataset, filename) {
        await toFile(dataset.toStream(), filename)
    }


    static listToArray(dataset, term, property) {
        const poi = rdf.grapoi({ dataset: dataset, term: term })
        const first = poi.out(property).term

        let p = rdf.grapoi({ dataset, term: first })
        let object = p.out(ns.rdf.first).term

        const result = [object]

        while (true) {
            let restHead = p.out(ns.rdf.rest).term
            let p2 = rdf.grapoi({ dataset, term: restHead })
            let object = p2.out(ns.rdf.first).term

            if (restHead.equals(ns.rdf.nil)) break
            result.push(object)
            p = rdf.grapoi({ dataset, term: restHead })
        }
        return result
    }





    static listObjects(dataset, subjectList, predicate) {
        const objects = []
        for (const subject of subjectList) {
            logger.log("subject = " + subject.value)
            let p = rdf.grapoi({ dataset, term: subject })
            let object = p.out(predicate).term
            logger.log("object = " + object.value)
            objects.push(object)
        }
        return objects
    }
}
export default GrapoiHelpers

================
File: src/utils/Logger.js
================
import log from 'loglevel';
import fs from 'fs';
import chalk from 'chalk';

const logger = {};


const LOG_STYLES = {
    "trace": chalk.yellow,
    "debug": chalk.red,
    "info": chalk.white,
    "warn": chalk.red.italic,
    "error": chalk.red.bold
};
const LOG_LEVELS = ["trace", "debug", "info", "warn", "error"];

logger.logfile = 'latest.log';
logger.currentLogLevel = "warn";

log.setLevel(logger.currentLogLevel);

logger.getLevel = () => log.getLevel();
logger.enableAll = () => log.enableAll();
logger.disableAll = () => log.disableAll();
logger.setDefaultLevel = (level) => log.setDefaultLevel(level);
logger.getLogger = (name) => {
    const namedLogger = log.getLogger(name);
    return wrapLogger(namedLogger, name);
};

logger.methodFactory = log.methodFactory;

logger.noConflict = () => log.noConflict();

function wrapLogger(baseLogger, name = 'root') {
    const wrapped = {};

    wrapped.log = function (msg, level = "info") {
        const timestamp = chalk.dim(`[${logger.timestampISO()}]`);
        const levelStyle = LOG_STYLES[level] || LOG_STYLES["info"];
        const levelTag = levelStyle(`[${level.toUpperCase()}]`);
        const nameTag = chalk.green(`[${name}]`);
        const message = levelStyle(msg);


        const consoleMessage = `${message}`;
        const fileMessage = `[${logger.timestampISO()}] [${level.toUpperCase()}] [${name}] - ${msg}`;

        baseLogger[level](consoleMessage);
        logger.appendLogToFile(fileMessage);
    };

    LOG_LEVELS.forEach(level => {
        wrapped[level] = (msg) => wrapped.log(msg, level);
    });

    wrapped.getLevel = () => baseLogger.getLevel();
    wrapped.setLevel = (level, persist) => baseLogger.setLevel(level, persist);
    wrapped.setDefaultLevel = (level) => baseLogger.setDefaultLevel(level);
    wrapped.enableAll = () => baseLogger.enableAll();
    wrapped.disableAll = () => baseLogger.disableAll();
    wrapped.methodFactory = baseLogger.methodFactory;
    wrapped.setMethodFactory = function (factory) {
        baseLogger.methodFactory = factory;
        baseLogger.rebuild();
    };

    return wrapped;
}

logger.appendLogToFile = function (message) {
    if (logger.logfile) {
        fs.appendFileSync(logger.logfile, message + '\n', 'utf8');
    }
}

logger.setLogLevel = function (logLevel = "warn", persist = true) {
    logger.currentLogLevel = logLevel;
    log.setLevel(logLevel, persist);
}

logger.timestampISO = function () {
    return new Date().toISOString();
}

logger.log = function (msg, level = "info") {
    const levelStyle = LOG_STYLES[level] || LOG_STYLES["info"];
    const message = levelStyle(msg);
    const consoleMessage = `${message}`;
    const fileMessage = `[${logger.timestampISO()}] [${level.toUpperCase()}] [root] - ${msg}`;
    try {



        log[level](consoleMessage);
        logger.appendLogToFile(fileMessage);
    } catch (err) {
        console.log(`wtf? ${err.message}`)
    }

}

logger.reveal = function (instance) {
    if (!instance) {
        logger.log('no instance defined', 'warn');
        return;
    }

    const serialized = {};
    logger.log('***    hidden keys :  ', 'debug');
    const loglevel = logger.getLevel()
    logger.setLogLevel('trace')

    for (const key in instance) {
        if (key === 'dataset') {
            logger.log('[[dataset found, skipping]]', 'debug');
            continue;
        }

        if (key.startsWith('_')) {
            logger.log(`       ${key}`, 'debug');
            continue;
        }

        if (instance.hasOwnProperty(key)) {
            let value = instance[key];
            if (value) {
                if (Buffer.isBuffer(value)) {
                    value = value.toString();
                }
                if (value.length > 100) {
                    try {
                        value = value.substring(0, 100) + '...';
                    } catch (e) {
                        value = value.slice(0, 99);
                    }
                }
                serialized[key] = value;
            } else {
                serialized[key] = '[no key]';
            }
        }
    }

    const props = JSON.stringify(serialized, null, 2);

    logger.log(`Instance of ${chalk.yellow(chalk.bold(instance.constructor.name))} with properties - \n${chalk.yellow(props)})`);
    logger.setLogLevel(loglevel)
}

LOG_LEVELS.forEach(level => {
    logger[level] = (msg) => logger.log(msg, level);
});

logger.poi = function exploreGrapoi(grapoi, predicates, objects, subjects) {
    console.log(chalk.bold('Properties of the Grapoi object:'));
    for (const prop in grapoi) {
        console.log(chalk.cyan(`\t${prop}: ${grapoi[prop]}`));
    }

    console.log(chalk.bold('\nPath:'));
    const path = grapoi.out(predicates, objects).in(predicates, subjects);
    for (const quad of path.quads()) {
        console.log(chalk.cyan(`\t${quad.predicate.value}: ${quad.object.value}`));
    }
}

function handleExit(options, exitCode) {
    if (options.cleanup) {

    }
    if (exitCode || exitCode === 0) console.log(exitCode);
    if (options.exit) process.exit();
}

process.on('exit', handleExit.bind(null, { cleanup: true }));
process.on('SIGINT', handleExit.bind(null, { exit: true }));
process.on('SIGUSR1', handleExit.bind(null, { exit: true }));
process.on('SIGUSR2', handleExit.bind(null, { exit: true }));
process.on('uncaughtException', handleExit.bind(null, { exit: true }));









export default logger;

================
File: src/utils/ns.js
================
import rdf from 'rdf-ext'

const ns = {
    rdf: rdf.namespace('http://www.w3.org/1999/02/22-rdf-syntax-ns#'),
    rdfs: rdf.namespace('http://www.w3.org/2000/01/rdf-schema#'),
    dc: rdf.namespace('http://purl.org/dc/terms/'),
    schema: rdf.namespace('http://schema.org/'),
    xsd: rdf.namespace('http://www.w3.org/2001/XMLSchema#'),
    trn: rdf.namespace('http://purl.org/stuff/transmissions/'),



}





ns.shortName = ns.getShortname = function (url) {

    if (!url) return
    url = url.toString()
    const lastSlashIndex = url.lastIndexOf('/');
    const lastHashIndex = url.lastIndexOf('#');
    const path = url.slice(lastSlashIndex + 1);
    return path.split('#')[0].split('?')[0];
}
export default ns

================
File: src/utils/t2j.js
================
import { Readable } from 'readable-stream'
import rdf from '@rdfjs/data-model'
import SerializerJsonld from '@rdfjs/serializer-jsonld'
import Serializer from '@rdfjs/serializer-turtle'
import N3Parser from '@rdfjs/parser-n3'
import { fromFile } from 'rdf-utils-fs'
import { toFile } from 'rdf-utils-fs'

const testTurtle = `
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix trm: <http://purl.org/stuff/transmission/> .
@prefix : <https://hyperdata.it/transmissions/> . # for custom terms & instances

:simplepipe a trm:TransmissionTransmission ;
    trm:pipe (:s1 :s2 :s3) .

:s1 a trm:StringSource .
:s2 a trm:AppendProcess .
:s3 a trm:StringSink .
`
export class Turtle2JSONLD {
    static async convert(turtle) {

        let parser = new N3Parser({ factory: rdf })



        const input = Readable.from(turtle)

        const output = parser.import(input)

        const serializerJsonld = new SerializerJsonld()
        const jsonStream = serializerJsonld.import(output)





        const outputJson = await Turtle2JSONLD.streamToString(jsonStream)
        return outputJson
    }

    static stringToStream(str) {
        const stream = new Readable();
        stream.push(str);
        stream.push(null);
        return stream;
    }

    static streamToString(stream) {
        const chunks = [];
        return new Promise((resolve, reject) => {
            stream.on('data', (chunk) => {
                chunks.push(Buffer.from(chunk))
                console.log('chunk:', chunk)
            }
            );
            stream.on('error', (err) => reject(err));
            stream.on('end', () => {
                const result = Buffer.concat(chunks).toString('utf8')
                resolve(result)
                console.log('****************** result:', result)
            });
        })
    }
}



const testJson = await Turtle2JSONLD.convert(testTurtle)
console.log('àààààààààààààààààààààà')
console.log(testJson)

================
File: src/utils/test_runner.js
================
import fs from 'fs';
import path from 'path';

const testFiles = fs.readdirSync(__dirname).filter(file => file.startsWith('test_'));

testFiles.forEach(testFile => {
    console.log(`Running ${testFile}`);
    require(path.join(__dirname, testFile));
});

================
File: package.json
================
{
  "type": "module",
  "version": "1.0.0",
  "description": "Transmissions",
  "name": "transmissions",
  "scripts": {
    "test": "jasmine --config=jasmine.json --reporter=tests/helpers/reporter.js",
    "cov": "nyc -a --include=src --reporter=lcov npm run test",
    "docs": "jsdoc -c jsdoc.json",
    "build": "webpack --mode=production --node-env=production",
    "build:dev": "webpack --mode=development",
    "build:prod": "webpack --mode=production --node-env=production",
    "rp": "node --no-warnings $(which repomix) -c repomix.config-small.json . && node --no-warnings $(which repomix) -c repomix.config-large.json .",
    "watch": "webpack --watch",
    "serve": "webpack serve"
  },
  "nyc": {
    "report-dir": "spec/coverage",
    "exclude": [
      "spec/**/*"
    ]
  },
  "devDependencies": {
    "@babel/core": "^7.23.7",
    "@babel/preset-env": "^7.23.8",
    "autoprefixer": "^10.4.17",
    "babel-loader": "^9.1.3",
    "chai": "^5.0.3",
    "css-loader": "^6.9.1",
    "html-webpack-plugin": "^5.6.0",
    "jasmine": "^5.1.0",
    "jasmine-browser-runner": "^2.3.0",
    "jasmine-core": "^5.1.1",
    "jasmine-spec-reporter": "^7.0.0",
    "jsdoc": "^4.0.2",
    "mini-css-extract-plugin": "^2.7.7",
    "nyc": "^17.1.0",
    "postcss": "^8.4.33",
    "postcss-loader": "^8.0.0",
    "prettier": "^3.2.4",
    "style-loader": "^3.3.4",
    "webpack": "^5.90.0",
    "webpack-cli": "^5.1.4",
    "webpack-dev-server": "^4.15.1",
    "workbox-webpack-plugin": "^7.0.0"
  },
  "dependencies": {
    "@dotenvx/dotenvx": "^1.14.2",
    "@rdfjs/formats": "^4.0.0",
    "@rdfjs/parser-n3": "^2.0.2",
    "axios": "^1.6.8",
    "cheerio": "^1.0.0-rc.12",
    "d3": "^7.9.0",
    "ignore": "^7.0.0",
    "jsdom": "^25.0.0",
    "lodash": "^4.17.21",
    "loglevel": "^1.9.2",
    "marked": "^12.0.1",
    "marked-code-format": "^1.1.6",
    "marked-custom-heading-id": "^2.0.10",
    "marked-footnote": "^1.2.4",
    "markmap-lib": "^0.17.0",
    "markmap-render": "^0.17.0",
    "markmap-toolbar": "^0.17.0",
    "markmap-view": "^0.17.0",
    "nunjucks": "^3.2.4",
    "queue": "^7.0.0",
    "rdf-ext": "^2.5.2",
    "rdf-utils-fs": "^3.0.0",
    "repomix": "^0.2.12",
    "string-to-stream": "^3.0.1",
    "yargs": "^17.7.2"
  }
}

================
File: README.md
================
# transmissions

After _No Code_ and _Lo Code_ comes _Marginally Less Code_

**Transmissions** is a micro-framework intended to simplify construction of small pipeliney data processing applications in JavaScript (assuming you are already familiar with JavaScript and RDF).

The code is in active development, ie. **not stable**, subject to arbitrary changes.

A bit like `make` or a `package.json` builder. But much harder work (and fun).

Applications are defined in several places, the bits of interest are eg. Postcraft's [transmissions.ttl](https://github.com/danja/transmissions/blob/main/src/applications/postcraft/transmissions.ttl) and [services.ttl](https://github.com/danja/transmissions/blob/main/src/applications/postcraft/services.ttl).
The former defines the flow, the latter config of the services (under [src/services](https://github.com/danja/transmissions/tree/main/src/services)). The runtime instance of the application is given in the target [manifest.ttl](https://github.com/danja/postcraft/blob/main/danny.ayers.name/manifest.ttl).

### Installation etc.

This is not ready yet. But if you really must...

Make a fresh dir. Clone this repo and [Postcraft](https://github.com/danja/postcraft) into it.

```
cd transmissions
npm i
```

This may or may not work :

```
npm run test
```

Then if you do :

```
./trans postcraft /home/danny/github-danny/postcraft/danny.ayers.name
```

it may build a site (my blog - this is dogfooding to the max) under `public/home`

```
./trans
```

on its own should list the applications available. Most of these won't work, the code has been shapeshifting a lot.

### Status

**2024-09-02** Getting used as a serrrrriously over-engineered, feature-lacking static site builder, proof of concept is [Postcraft](https://github.com/danja/postcraft), as evinced by my [blog](https://danny.ayers.name/) (where, for now at least you will find update on this). But it mostly works as intended. Docs lagging. But now I have a documentation engine...

Documentation will be lagging behind code, be incomplete and out of date.

**2024-03-24** : a couple of simple data processing pipelines working and wired up as Jasmine e2e tests in place; started to develop actually useful pipelines for [foaf-archive](https://github.com/danja/foaf-archive) project

## Motivation

This was prompted by something of a ~~perfect storm~~ serendipitous convergence of ideas, requirements and environment.

- I had the realization that much of the software I want to write in the near future has the same basic high level **architecture** : pipeline-like, ie. a series of steps each of which transform data from one form into another ([Wikipedia](<https://en.wikipedia.org/wiki/Pipeline_(software)>)).
- **Pipelines** are approachable using concepts from Design Patterns like [Dependency Injection](https://en.wikipedia.org/wiki/Dependency_injection), [Inversion of control](https://en.wikipedia.org/wiki/Inversion_of_control) etc. A key benefit of such patterns is that, because the components are loosely coupled, they can largely be developed in isolation as small standalone units before integration into a larger application.
- **Large Language Models** currently struggle with large codebases and complex architectures (mostly due to [context window](https://en.wikipedia.org/wiki/Large_language_model#Prompt_engineering,_attention_mechanism,_and_context_window) limitations). But they are very good at building small, simple, self-contained units of code.

reused in different contexts.

_I'm writing this with GitHub Copilot enabled for markdown, which can be helpful, but sometimes it goes off on one... After the first point above it offered :_

```
This is true of a blog engine, a personal knowledge management system, a chatbot, a mail archive miner, a web scraper, a data visualizer, a data importer/exporter, a data transformer, a data validator, a data filter, a data aggregator, a data splitter, a data joiner, a data normalizer, a data summarizer, a data classifier, a data indexer, a data search engine, a data storage system, a data retrieval system, a data synchronization system, a data backup system, a data migration system, a data versioning system, a data sharing system, a data access control system, a data privacy system, a data security system, a data integrity system, a data quality system, a data governance system, a data provenance system, a data lineage system, a data lifecycle system, a data archiving system, a data retention system, a data deletion system, a data recovery system, a data discovery system, a data exploration system, a data analysis system, a data visualization system, a data reporting system, a data monitoring system, a data alerting system, a data forecasting system, a data prediction system, a data recommendation system, a data personalization system, a data optimization system, a data simulation system, a data modeling system, a data inference system, a data learning system, a data reasoning system, a data decision system, a data planning system, a data execution system, a data monitoring system, a data feedback system, a data control system, a data automation system, a data orchestration system, a data integration system, a data federation system, a data interoperability system, a data exchange system, a data transformation system, a data migration system, a data synchronization system, a data replication system, a data federation system, a data virtualization system, a data streaming system, a data batch system, a data real-time system, a data near-real-time system, a data historical system, a data temporal system, a data spatial system, a data geospatial system, a data network system, a data graph system, a data tree system, a data list system, a data set system, a data table system, a data document system, a data record system, a data entity system, a data attribute system, a data value system, a data type system, a data format system, a data encoding system, a data serialization
```

_... which is a little over the top, but it's a fair list of things that might be helped by a micro-framework like this. Remarkably the first 5 are pretty much my immediate intended uses for this._

**Docs below need updating**

for later :

The [Community Solid Server](https://github.com/CommunitySolidServer/CommunitySolidServer) uses [Components.js](https://componentsjs.readthedocs.io/en/latest/) to specify how modules and components need to be wired together at runtime. Components.js is a dependency injection framework for JavaScript applications.

## What it is

A low-level system for data processing pipelines/networks. Wherever convenient functionality will be defined declaratively with JSON-LD configuration files.

Dependency injection is used internally to allow loose coupling of components.

## What it isn't

There are several sophisticated frameworks for building interfaces between software applications and creating data processing networks. NodeRed, NoFlo etc. This is not one of them. This is much more basic and bare bones, down in the details.

See also [David Booth](https://github.com/dbooth-boston)'s [RDF Pipeline Framework](https://github.com/rdf-pipeline)

_I do eventually want to use this with NodeRed or whatever, but the entities created by transmissions will be at the level of nodes in such networks, not the network itself._

## Motivation

I'm in the process of writing yet another blog engine (Postcraft). I've also started working on a playground for interconnecting intelligent agents in an XMPP multiuser chat environment (Kia). I'm also revising a system for managing a personal knowledge base in the world of LLMs (HKMS). These all share functionality around connectivity to external data/messaging systems and internal data transformation. Might as well write this bit once only, and avoid thinking about software architecture more than I have to.

### Goals

To facilate :

- rapid development of small applications
- reuse of components in a loosely-couple environment
- versatility

### Soft Goals

- performance - low on the list
- scalability - ditto
- security - ditto
